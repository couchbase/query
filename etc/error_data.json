[
  {
    "code": 1000,
    "ErrorCode": "E_SERVICE_READONLY",
    "description": "The server or request is read-only and cannot accept this write statement.",
    "causes": [
      "When a request is read-only statements that write data are not permitted.  A statement may be read-only by being submitted to the REST enpoint using the GET method or by setting the \"readonly\" request parameter.  Read-only requests may PREPARE statements, including write statements when the \"auto_execute\" request parameter is not true."
    ],
    "actions": [
      "Use POST to submit write statements and ensure the \"readonly\" request parameter is not set or is set to false."
    ],
    "isUser": true
  },
  {
    "code": 1010,
    "ErrorCode": "E_SERVICE_HTTP_UNSUPPORTED_METHOD",
    "description": "Unsupported http method:[METHOD]",
    "causes": [
      "The service endpoint supports only GET & POST HTTP methods.  All other HTTP methods are not supported."
    ],
    "actions": [
      "Use a supported method to submit requests."
    ],
    "isUser": true
  },
  {
    "code": 1020,
    "ErrorCode": "E_SERVICE_NOT_IMPLEMENTED",
    "description": "[feature] [value] not implemented",
    "causes": [
      "The noted feature/value combination is reserved but is not implemented."
    ],
    "actions": [
      "Use only supported feature/value combinations."
    ],
    "isUser": true
  },
  {
    "code": 1030,
    "ErrorCode": "E_SERVICE_UNRECOGNIZED_VALUE",
    "description": "Unknown [parameter] value: [value]",
    "causes": [
      "The value supplied for the noted parameter is not recognised."
    ],
    "actions": [
      "Ensure the value supplied is  a supported value in the required format for the request parameter noted."
    ],
    "isUser": true
  },
  {
    "code": 1040,
    "ErrorCode": "E_SERVICE_BAD_VALUE",
    "description": "Error processing [message]",
    "causes": [
      "There was an error in processing as detailed in the message.  For example, a non-numeric string value passed as the value for a request parameter that is expected to be numeric."
    ],
    "actions": [
      "Where there error is derived from user-controlled data, correct the data."
    ]
  },
  {
    "code": 1050,
    "ErrorCode": "E_SERVICE_MISSING_VALUE",
    "description": "No [parameter] value",
    "causes": [
      "A value was not supplied for the required parameter."
    ],
    "actions": [
      "Provide valid values for all required parameters.  For example, ensure a user and password are supplied for all requests and a scan_vector is supplied for requests using AT_PLUS consistency level."
    ],
    "isUser": true
  },
  {
    "code": 1060,
    "ErrorCode": "E_SERVICE_MULTIPLE_VALUES",
    "description": "Multiple values for [feature]",
    "causes": [
      "1) namedArgument: each named argument passed in the request string must be unique, example bad request: /query/service?statement=SELECT $name;&$name=\"a\"&$name=\"b\",\n\"errors\":[\n{\n\"code\": 1060,\n\"msg\": \"Multiple values for 'name'.\"\n}\n]",
      "2) multiple statements( PREPARE/DML statements/ DDL statements) , example bad request: query/service?statement=SELECT $name;&$name=\"a\"&statement=CREATE INDEX defix ON default(a);",
      "3) user has passed both scan_vector & scan_vectors parameter.",
      "4) user has both auto_execute(request_level setting) and auto_prepare(service_level or request_level) set to true.",
      "5) when passing namedargument through a POST request body, user has a repeat for a particular namedArgumet\n    example: \nPOST /query/service?statement=SELECT%2520%2540key%253B&%2524name=%2522a%2522 HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nContent-Length: 38\nContent-Type: application/json\nHost: 127.0.0.1:9499\n{\n  \"@key\":\"secret\",\n  \"@key\":\"NOPE\"\n}\n\n\"errors\":[\n{\n\"code\": 1060,\n\"msg\": \"Multiple values for @key.\"\n}\n]",
      "6) URL form: multiple values for a request header field",
      "7) request query string has multiple values for a request level setting, example: /query/service?statement=SELECT 1;&auto_execute=true&auto_execute=2"
    ],
    "actions": [
      "1) ensure all namedargument parameters ($[identifier] or @[identifier]) are unique",
      "2) have only one statement request parameter, execute the other statement in a new request.",
      "3) when using scan_vector cannot have scan_vectors parameter, either scan_vector(for a single keyspace query) or scan_vectors(query with multiple keyspaces). In other words cannot have both. Typical usage is with scan_consistency set to AT_PLUS to insure index is upto date with datastore.",
      "4) doesn't make sense to have both auto_execute and auto_prepare.",
      "5) whenever passing namedArgs through a json request body, ensure they are all unique. Unlikely case as only form value we take is authorization? ( that is caught by another error)",
      "6) ensure all request parameters  https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html#_request_parameters passed are unique "
    ],
    "isUser": true
  },
  {
    "code": 1065,
    "ErrorCode": "E_SERVICE_UNRECOGNIZED_PARAMETER",
    "description": "Unrecognized parameter in request: [parameter]",
    "causes": [
      "1) request URL string has an unrecognized request parameter.",
      "2) request body has an unrecognized parameter.(again the request level parameters)\n\nexample: query/service?statement=SELECT 1;&notvalidreqparam=3\n\"errors\":[\n{\n\"code\": 1065,\n\"msg\": \"Unrecognized parameter in request: notvalidreqparam\"\n}\n]"
    ],
    "actions": [
      "ensure when passing request parameters either through URL string or request body, ensure it is from the listed setting here https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html#_request_parameters \n"
    ],
    "isUser": true
  },
  {
    "code": 1070,
    "ErrorCode": "E_SERVICE_TYPE_MISMATCH",
    "description": "[feature] has to be of type [expected]",
    "causes": [
      "1) when parsing input for scan_vector as full_scan vector: a) Expected array of 1024 entries( entry [vbseqno[NUMBER], vbucketuuid[string]) but got fewer entries, b) entry expected is an array of length 2, but got something else.",
      "2) scan_vector pararmeter is expected to be array(full_scan vector) or map[string][entry] (sparse vector)",
      "3) \"args\" request parameter is expected to be an array.",
      "4) \"creds\" request parameter is expected to be array of {user, pass}",
      "5) following request parameters are expected to have a string value: durability_level, atrcollection, format, compression, endcoding, query_context, txid, statement, timeout, kvtimeout, namespace, loglevel, usereplica, duration_style, client_context_id, txtimeout",
      "6) following request parameters are expected to have tristate value: true/false/none\nusefts, sort_projection, controls, signature, auto_prepare, auto_execute, usecbo, tximplicit, preserve_expiry, readonly, metrics, pretty."
    ],
    "actions": [
      "1) use cbstat for this getting vbucket_uuid and vbucket_seqno-> https://docs.couchbase.com/server/7.1/cli/cbstats/cbstats-vbucket-seqno.html#example",
      "2) Scan vectors have two forms: Full scan vector: an array of [value, guard] entries, giving an entry for every vBucket in the system.\nSparse scan vectors: an object providing entries for specific vBuckets, mapping a vBucket number (a string) to each [value, guard] entry.",
      "3) \"args\" request parameter must be something like [\"abc\", 31].",
      "4) \"creds\" request parameter must be something like [ { \"user\" : \"local:bucket-name\", \"pass\" : \"password\" }, { \"user\" : \"admin:admin-name\", \"pass\" : \"password\" } ].",
      "5) change value to allowed string , link to documentation https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html#_request_parameters",
      "6) change value to a tristate value, link to documentation https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html#_request_parameters "
    ],
    "isUser": true
  },
  {
    "code": 1080,
    "ErrorCode": "E_SERVICE_TIMEOUT",
    "description": "Timeout [duration] exceeded",
    "causes": [
      "request level timeout has been hit, hence the request is timedout"
    ],
    "actions": [
      "change \"timeout\" request parameter to a higher value"
    ],
    "isUser": true
  },
  {
    "code": 1090,
    "ErrorCode": "E_SERVICE_INVALID_VALUE",
    "description": "[parameter] = [value] is invalid. [message]",
    "causes": [
      "The named paramer's value is invalid for the reason noted in the message."
    ],
    "actions": [
      "Set the parameter to a valid value.  For example, don't set or set \"readonly\" to true when submitting a request using the GET method."
    ],
    "isUser": true
  },
  {
    "code": 1100,
    "ErrorCode": "E_SERVICE_INVALID_JSON",
    "description": "Invalid JSON in results",
    "causes": [
      "error in logic to write the error to the output buffer(usually stdout), actual query processing has completed only errored out while try to write out the results."
    ],
    "actions": [
      "please contact support"
    ],
    "isUser": false
  },
  {
    "code": 1110,
    "ErrorCode": "E_SERVICE_CLIENTID",
    "description": "forbidden character (\\\\ or \\\") in client_context_id",
    "causes": [
      "request has client_context_id set to a value that has \" or \\ which is disallowed as it is not vaild json character"
    ],
    "actions": [
      "change your client_context_id to something that doesn't have the characters \" or \\"
    ],
    "isUser": true
  },
  {
    "code": 1120,
    "ErrorCode": "E_SERVICE_MEDIA_TYPE",
    "description": "Unsupported media type:[mediaType]",
    "causes": [
      "allowed value for Accept: request header is not */* or \"application/json\", we only support response of json / xml for now"
    ],
    "actions": [
      "change \"accept\" header field to \"application/json\""
    ],
    "isUser": true
  },
  {
    "code": 1130,
    "ErrorCode": "E_SERVICE_HTTP_REQ",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 1140,
    "ErrorCode": "E_SERVICE_SCAN_VECTOR_BAD_LENGTH",
    "description": "Array [scan_entry] should be of length 2",
    "causes": [
      "when passing entries in the scan_vector or scan_vectors parameter-> entry must be [value:vbucket_seqno, guard:vbucket_uuid]. This applies for both fullscan vector and sparse scan vector."
    ],
    "actions": [
      "correct the scan entry in your scan vector to [vbucket_seqno:JSON-number, vbucket_uuid:string]"
    ],
    "isUser": true
  },
  {
    "code": 1150,
    "ErrorCode": "E_SERVICE_SCAN_VECTOR_BAD_SEQUENCE_NUMBER",
    "description": "Bad sequence number [vbucket_seqno input]. Expected an unsigned 64-bit integer.",
    "causes": [
      "entry in the scan_vector parameter is a not an unsigned-integer."
    ],
    "actions": [
      "correct vbsequence number , maybe use cbstat tool for this https://docs.couchbase.com/server/7.1/cli/cbstats/cbstats-vbucket-seqno.html#example "
    ],
    "isUser": true
  },
  {
    "code": 1155,
    "ErrorCode": "E_SERVICE_SCAN_VECTOR_BADUUID",
    "description": "Bad UUID [vbucket_uuid]. Expected a string.",
    "causes": [
      "scan_vector has an entry with [vbucket_seqno, vbucket_uuid]-> uuid as non-string value"
    ],
    "actions": [
      "correct the vbuuid, maybe use cbstat tool for this https://docs.couchbase.com/server/7.1/cli/cbstats/cbstats-vbucket-seqno.html#example "
    ],
    "isUser": true
  },
  {
    "code": 1160,
    "ErrorCode": "E_SERVICE_DECODE_NIL",
    "description": "Failed to decode nil value.",
    "causes": [
      "server got a nil request body. 1) for POST /admin/settings 2) POST /admin/clusters 3) POST /admin/clusters/{clusters}/nodes"
    ],
    "actions": [
      "retry request with a non-nil request body, "
    ],
    "isUser": true
  },
  {
    "code": 1170,
    "ErrorCode": "E_SERVICE_HTTP_METHOD",
    "description": "Unsupported method [request-method]",
    "causes": [
      "endpoint you are trying to send your request to doesn't support the request method specified"
    ],
    "actions": [
      "documentation link for N1QL API support https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html "
    ],
    "isUser": true
  },
  {
    "code": 1180,
    "ErrorCode": "E_SERVICE_SHUTTING_DOWN",
    "description": "INTERNAL USE",
    "causes": [
      "1) redundant shutdown request from orchestrator during removal rebalance during service shutdown,",
      "2) if partial graceful shutdown feature is not supported any request to service during shutdown is errored out with this error during service shutdown"
    ],
    "actions": []
  },
  {
    "code": 1181,
    "ErrorCode": "E_SERVICE_SHUT_DOWN",
    "description": "INTERNAL USE",
    "causes": [
      "1) redundant shutdown request from orchestrator during removal rebalabce after service has shutdown,",
      "2) if partial graceful shutdown is not supported any request after shutdown is errored out with this error during service shutdown."
    ],
    "actions": []
  },
  {
    "code": 1182,
    "ErrorCode": "E_SERVICE_UNAVAILABLE",
    "description": "Service cannot handle requests",
    "causes": [
      "/admin/ping endpoint to determine if server is healthy. That is neither unbounded queue(this is for request with scan_consistency = not_bounded) nor plus queue(request scan_consistency is at_plus/request_plus/statement_plus) is full and cannot respond to anymore requests, this is because the queueCount(number of request in the runninung queue) is greater the fullqueue(running queue capacity)."
    ],
    "actions": [
      "Try checking in active_requests(SELECT * FROM system:active_requests) and optionally check for scan_consistency, for eg:  WHERE scan_consistency=\"unbounded\". \nWait till the number of documents in active requests comedown."
    ],
    "isUser": false
  },
  {
    "code": 1191,
    "ErrorCode": "E_SERVICE_USER_REQUEST_EXCEEDED",
    "description": "UNUSED- pending changes from ns_server for free-tier(from commit message)",
    "causes": [],
    "actions": []
  },
  {
    "code": 1192,
    "ErrorCode": "E_SERVICE_USER_REQUEST_RATE_EXCEEDED",
    "description": "UNUSED- pending changes from ns_server for free-tier(from commit message)",
    "causes": [],
    "actions": []
  },
  {
    "code": 1193,
    "ErrorCode": "E_SERVICE_USER_REQUEST_SIZE_EXCEEDED",
    "description": "UNUSED- pending changes from ns_server for free-tier(from commit message)",
    "causes": [],
    "actions": []
  },
  {
    "code": 1194,
    "ErrorCode": "E_SERVICE_USER_RESULT_SIZE_EXCEEDED",
    "description": "UNUSED- pending changes from ns_server for free-tier(from commit message)",
    "causes": [],
    "actions": []
  },
  {
    "code": 1195,
    "ErrorCode": "E_REQUEST_ERROR_LIMIT",
    "description": "Request execution aborted as the number of errors raised has reached the maximum permitted.",
    "causes": [
      "Possible occurence indicates errors in DML statements(DELETE /INSERT /UPDATE/ UPSERT) on a keyspace. This maybe due to CASmismatch at the document level due to concurrent modification request."
    ],
    "actions": [
      "The error limit is configurable per request level by using the \"error_limit\" request parameter. Change it to a higher value."
    ],
    "isUser": false
  },
  {
    "code": 1196,
    "ErrorCode": "E_SERVICE_TENANT_THROTTLED",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 1197,
    "ErrorCode": "E_SERVICE_TENANT_MISSING",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 1198,
    "ErrorCode": "E_SERVICE_TENANT_NOT_AUTHORIZED",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 1199,
    "ErrorCode": "E_SERVICE_TENANT_REJECTED",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 1200,
    "ErrorCode": "E_SERVICE_TENANT_NOT_FOUND",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 1201,
    "ErrorCode": "E_SERVICE_REQUEST_QUEUE_FULL",
    "description": "Request queue full",
    "causes": [
      "the request is stopped as the request queue is full, note that we maintain 2 separate queues for unbounded requests and plus requests."
    ],
    "actions": [
      "Try checking in active_requests(SELECT * FROM system:active_requests) and optionally check for scan_consistency, for eg:  WHERE scan_consistency=\"unbounded\". \nWait till the number of documents in active requests comedown."
    ],
    "isUser": false
  },
  {
    "code": 1202,
    "ErrorCode": "E_SERVICE_NO_CLIENT",
    "description": "Client disconnected",
    "causes": [
      "Server aborts servicing a request if a client has aborted the request. This is done when client closes its connection(disconnects / cancel request)"
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": true
  },
  {
    "code": 2000,
    "ErrorCode": "E_ADMIN_CONNECTION",
    "description": "Error connecting to  [msg]",
    "causes": [
      "1) When failing to connect to configstore, this error is logged(not returned).",
      "2) GET /admin/config internally tries to get poolServices from /pool/default/nodeServices",
      "3) GET /admin/clusters/{clusters}/nodes/{node} & GET /admin/clusters/{clusters}/nodes internally tries to get handle of the couchbase configstore connection but fails, that is when we raise this error."
    ],
    "actions": [
      ""
    ]
  },
  {
    "code": 2001,
    "ErrorCode": "E_ADMIN_START",
    "description": "Error accounting manager: Fail to open sigar.",
    "causes": [
      "1) while initailizing Accounting store on query-service startup we have encountered an error while opening handle to account for system stats"
    ],
    "actions": [
      "1) Contact Support"
    ],
    "isUser": false
  },
  {
    "code": 2010,
    "ErrorCode": "E_ADMIN_INVALIDURL",
    "description": "Invalid [component] URL: [URL]",
    "causes": [
      "1) during startup Logger URL is invalid, 2) accounting store URL is invalid, 3) configstore URL is invalid"
    ],
    "actions": [
      "1) URL prefix for logger-> golog / builtin / file / null , 2) URL scheme/protocol for accounting store-> gometrics: , 3) URL scheme/protocol for configstore-> http: , if encountered on source build https://github.com/couchbase/tlm trying changing URL to supported format, else if contact support."
    ],
    "isUser": false
  },
  {
    "code": 2020,
    "ErrorCode": "E_ADMIN_DECODING",
    "description": "Error in JSON decoding",
    "causes": [
      "failed to decode Basic authorization 1) when trying to profile using /debug/pprof/ or /debug/pprof/profile endpoint. 2) Similarly for /debug/pprof/block , /debug/pprof/goroutine , /debug/pprof/threadcreate, /debug/pprof/heap, /debug/pprof/mutex 3) when trying to request /admin/settings endpoint.\n\nFailed to write api's returned object to the http response stream , for all admin -api's https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/admin.html"
    ],
    "actions": [
      "Contact Support"
    ]
  },
  {
    "code": 2030,
    "ErrorCode": "E_ADMIN_ENCODING",
    "description": "Error in JSON encoding - Only raised under zookeeper clustering",
    "causes": [],
    "actions": []
  },
  {
    "code": 2031,
    "ErrorCode": "E_ADMIN_UNKNOWN_SETTING",
    "description": "Unknown setting: [setting]",
    "causes": [
      "POST request to /admin/settings to change node level settings https://docs.couchbase.com/server/current/settings/query-settings.html has a setting in the request body which is not recognized.\n\nExample: request: POST /admin/settings HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nContent-Length: 18\nContent-Type: application/json\nHost: 127.0.0.1:9499\n{\n  \"cleanup\": 1\n}\n\nresponse:\n{\n\"_level\": \"exception\",\n\"caller\": \"set_params:405\",\n\"code\": 2031,\n\"key\": \"admin.unknown_setting\",\n\"message\": \"Unknown setting: cleanup\"\n}"
    ],
    "actions": [
      "Find the allowed settings here https://docs.couchbase.com/server/current/settings/query-settings.html , and correct the unrecognized setting "
    ],
    "isUser": true
  },
  {
    "code": 2032,
    "ErrorCode": "E_ADMIN_SETTING_TYPE",
    "description": "Incorrect value for setting",
    "causes": [
      "1) POST request to /admin/settings endpoint, request body has valid settings as key but value for one of them is not the allowed type. For example loglevel setting expects string but we have passed a number\nrequest:\nPOST /admin/settings HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nContent-Length: 18\nContent-Type: application/json\nHost: 127.0.0.1:9499\n{\n  \"loglevel\":1\n}\n\n\nresponse:\nHTTP/1.1 500 Internal Server Error\nContent-Type: application/json\nDate: Tue, 21 Nov 2023 09:23:44 GMT\nContent-Length: 155\n{\"_level\":\"exception\",\"caller\":\"set_params:409\",\"code\":2032,\"key\":\"admin.setting_type_error\",\"message\":\"Incorrect value '1' (int64) for setting: loglevel\"}",
      "2) \"completed\" setting allows tagged set https://docs.couchbase.com/server/current/manage/monitor/monitoring-n1ql-query.html#tagged-sets which expects a string as value but user has passed a non-string value.",
      "3) \"completed\" setting expects an object",
      "4) \"atrcollection\" setting expects a string that is a valid n1ql path( bucket / bucket.scope.collection / namespace:bucket.scope.collection )"
    ],
    "actions": [
      "Find the allowed settings here https://docs.couchbase.com/server/current/settings/query-settings.html  , and correct the setting the mismatched the value. "
    ],
    "isUser": true
  },
  {
    "code": 2040,
    "ErrorCode": "E_ADMIN_GET_CLUSTER",
    "description": "Error retrieving cluster ",
    "causes": [
      "1) for the enpoints /admin/clusters/{cluster}  , /admin/clusters/{cluster}/nodes & /admin/clusters/{cluster}/nodes/{node}, no cluster by the name provided by the path parameter exists in the config store.",
      "2) when user tries to GET admin/config , invalid response from /pools/{poolname} to get pool data or /pools/{poolname}/nodeServices to get services data, usually the poolName passed is \"default\"."
    ],
    "actions": [
      "1) provide a valid cluster name",
      "2) please contact support, or try GET /pools/default endpoint at 8091 port(orchestrator process) to confirm if it is a query issue and not a cluster-wide issue."
    ],
    "isUser": true
  },
  {
    "code": 2050,
    "ErrorCode": "E_ADMIN_ADD_CLUSTER",
    "description": "Error adding cluster - Only raised under zookeeper clustering",
    "causes": [],
    "actions": []
  },
  {
    "code": 2060,
    "ErrorCode": "E_ADMIN_REMOVE_CLUSTER",
    "description": "Error removing cluster - Only raised under zookeeper clustering",
    "causes": [],
    "actions": []
  },
  {
    "code": 2070,
    "ErrorCode": "E_ADMIN_GET_NODE",
    "description": "Error retrieving node ",
    "causes": [
      "1) user has tried to query( SELECT * / SELECT COUNT(*) ) system:nodes keyspace which internally gets node/topology( information from /pools/default/nodeServices endpoint, but response doesn't include mgmt port(management port). Which is typically 8091.",
      "2) user has set GET /admin/config , and we try to return SQLclustering topolgy information such as service ip-address and \"queryEndpoint\" , \"adminEndpoint\", \"querySecure\", \"adminSecure\" URIs. But again /pools/default or /pools/default/nodeServices endpoint return erroreous response maybe adminConnection error, etc.",
      "3) /admin/clusters/{clusters}/nodes endpoint failed to gather nodes information for the pool {cluster} from configstore. Similar scenario may occur for /admin/clusters/{clusters}/nodes?uuid=<uuid>"
    ],
    "actions": [
      "the orchestrator(ns_server) process's endpoint /pools/default & /pools/default/nodeServices"
    ],
    "isUser": true
  },
  {
    "code": 2080,
    "ErrorCode": "E_ADMIN_NO_NODE",
    "description": "No such node <message>",
    "causes": [
      "1) admin/config , admin/clusters/{cluster}/nodes , admin/clusters/{cluster}/nodes/{node} endpoint internally lookup node information from /pool/default/nodeServices (orchestrator endpoint) and use that to get config from the sql clustering manager. But node name from /pools/default/nodeServices doesn't match one from the config store."
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": true
  },
  {
    "code": 2090,
    "ErrorCode": "E_ADMIN_ADD_NODE",
    "description": "Error adding node  - Only raised under zookeeper clustering",
    "causes": [],
    "actions": []
  },
  {
    "code": 2100,
    "ErrorCode": "E_ADMIN_REMOVE_NODE",
    "description": "Error removing node -  Only raised under zookeeper clustering",
    "causes": [],
    "actions": []
  },
  {
    "code": 2110,
    "ErrorCode": "E_ADMIN_MAKE_METRIC",
    "description": "Error creating metric -> internal for testing purpose, as we use GetOrRegister() instead of Register() for metrics in the accounting package",
    "causes": [],
    "actions": []
  },
  {
    "code": 2120,
    "ErrorCode": "E_ADMIN_AUTH",
    "description": "Error authorizing against cluster",
    "causes": [
      "1) authentication (not authorization) for a request->  user provided credentials( either 1. Basic Auth, 2. Auth Header/Token, 3. Certificates, 4. Creds query parameter), provided credentials don't match authenticated user credentials on the datastore auth handler(usually cbauth).",
      "2) request with no auth credentials",
      "3) when trying to read or write settins to /admin/settings endpoint, user must have cluster.settings!read privilege if GET , else POST then cluster.settings!write."
    ],
    "actions": [
      "Please ensure your users credential(username:password is authenticated) , if not contact support.\nIf an admin-authorization give the user the respective persmission. doc reference here https://docs.couchbase.com/server/7.1/manage/manage-security/manage-users-and-roles.html , ideally a full-admin / cluster-admin would be sufficient for most admin related authorization"
    ],
    "isUser": true
  },
  {
    "code": 2130,
    "ErrorCode": "E_ADMIN_ENDPOINT",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 2140,
    "ErrorCode": "E_ADMIN_SSL_NOT_ENABLED",
    "description": "server is not ssl enabled",
    "causes": [
      "user has sent a  POST /admin/ssl_cert but the service endpoint doesn't support https."
    ],
    "actions": []
  },
  {
    "code": 2150,
    "ErrorCode": "E_ADMIN_CREDS",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 2160,
    "ErrorCode": "E_COMPLETED_QUALIFIER_EXISTS",
    "description": "Completed requests qualifier already set: [qualifier name]",
    "causes": [
      "user has tried to add a qualifier using the completed object in POST request to /admin/settings but the qualifier is already been set before."
    ],
    "actions": [
      "to update a qualifier, don't use '+' prefix -> for eg: curl http://localhost:8093/admin/settings -u Administrator:password \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"completed\": {\"user\": \"marco\"}\n\ndocumentation link to logging qualifiers https://docs.couchbase.com/server/current/manage/monitor/monitoring-n1ql-query.html#logging-qualifiers "
    ],
    "isUser": true
  },
  {
    "code": 2170,
    "ErrorCode": "E_COMPLETED_QUALIFIER_UNKNOWN",
    "description": "Completed requests qualifier unknown: [qualifier name]",
    "causes": [
      "user has tried to add a qualifier that is not recognized by the server in the completed object as a part of the POST request to /admin/settings. \n\nfor eg:\nPOST /admin/settings HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nContent-Length: 16\nHost: 127.0.0.1:9499\n{\n\"users\":\"GA\"\n}\n\nHTTP/1.1 500 Internal Server Error\nContent-Type: application/json\nDate: Wed, 22 Nov 2023 11:17:08 GMT\nContent-Length: 125\n{\"_level\":\"exception\",\"caller\":\"set_params:405\",\"code\":2031,\"key\":\"admin.unknown_setting\",\"message\":\"Unknown setting: users\"}"
    ],
    "actions": [
      "list of valid logging qualifiers https://docs.couchbase.com/server/current/manage/monitor/monitoring-n1ql-query.html#logging-qualifiers "
    ],
    "isUser": true
  },
  {
    "code": 2180,
    "ErrorCode": "E_COMPLETED_QUALIFIER_NOT_FOUND",
    "description": "Completed requests qualifier not set: [qualifier name]",
    "causes": [
      "1) removing a previously unset logging qualifier, eg:\nPOST /admin/settings HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nContent-Length: 35\nHost: 127.0.0.1:9499\n{\n\"completed\": {\"-user\": \"marco\"}\n}\n\nHTTP/1.1 500 Internal Server Error\nContent-Type: application/json\nDate: Wed, 22 Nov 2023 11:39:30 GMT\nContent-Length: 174\n{\"_level\":\"exception\",\"caller\":\"completed_requests:304\",\"code\":2180,\"key\":\"admin.accounting.completed.not_found\",\"message\":\"Completed requests qualifier not set: user marco\"}"
    ],
    "actions": [
      "GET /admin/settings, \nlook at the completed field for existing qualifiers, when removing the value must match.\n\nfor eg: \nfrom the response\n\"completed\":[\n{\n\"client\": \"172.1.2.3\",\n\"tag\": \"both_user_and_error\"\n},\n{\n\"aborted\": null,\n\"client\": \"172.1.2.2\",\n\"seqscan_keys\": 10000,\n\"threshold\": 1000,\n\"user\": \"parco\"\n}\n\nto remove client:\n{\"completed\": {\"-client\":\"172.1.2.2\"}}\n"
    ],
    "isUser": true
  },
  {
    "code": 2190,
    "ErrorCode": "E_COMPLETED_QUALIFIER_NOT_UNIQUE",
    "description": "Non-unique completed requests qualifier [qualifier] cannot be updated",
    "causes": [
      "user request to /admin/settings includes a completed object that is trying to update non-unique qualifier( error, client, user, context)\nfor eg:\nPOST /admin/settings HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nContent-Length: 31\nContent-Type: application/json\nHost: 127.0.0.1:9499\n{\"completed\": {\"user\":\"parco\"}}\n\nHTTP/1.1 500 Internal Server Error\nContent-Type: application/json\nDate: Wed, 22 Nov 2023 11:49:53 GMT\nContent-Length: 192\n{\"_level\":\"exception\",\"caller\":\"completed_requests:294\",\"code\":2190,\"key\":\"admin.accounting.completed.not_unique\",\"message\":\"Non-unique completed requests qualifier 'user' cannot be updated.\"}"
    ],
    "actions": [
      "can only update unique qualifiers-> threshold , aborted\n\nfor others remove the qualifier with '-' prefix \nand add with a new value using '+' prefix\n\nsomething like, \n/admin/settings :{\"completed\": {\"-user\":\"marco\"}} \n/admin/settings :{\"completed\": {\"+user\":\"donald\"}}"
    ],
    "isUser": true
  },
  {
    "code": 2200,
    "ErrorCode": "E_COMPLETED_QUALIFIER_INVALID_ARGUMENT",
    "description": "Completed requests qualifier [qualifier name] cannot accept argument  [user-input]",
    "causes": [
      "The scenario here is that when adding a request logging qualifier in a request to /admin/settings , the expected type for the logging qualifier doesn't match the input type.\n\nfor eg: user expects string but you have passed a number\nPOST /admin/settings HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nContent-Length: 26\nContent-Type: application/json\nHost: 127.0.0.1:9499\n{\"completed\": {\"+user\":1}}\n\nHTTP/1.1 500 Internal Server Error\nContent-Type: application/json\nDate: Thu, 23 Nov 2023 06:47:53 GMT\nContent-Length: 184\n{\"_level\":\"exception\",\"caller\":\"completed_requests:861\",\"code\":2200,\"key\":\"admin.accounting.completed.invalid\",\"message\":\"Completed requests qualifier error cannot accept argument  1\"}"
    ],
    "actions": [
      "expected input for the request qualifiers \nuser-> string\nthreshold -> number\ncontext -> string\nclient -> string"
    ],
    "isUser": true
  },
  {
    "code": 2201,
    "ErrorCode": "E_COMPLETED_BAD_MAX_SIZE",
    "description": "UNUSED- but logic is to avoid adding in the plan by limiting the max plan size allowed to be logged. https://review.couchbase.org/c/query/+/194204 ",
    "causes": [],
    "actions": []
  },
  {
    "code": 2210,
    "ErrorCode": "E_ADMIN_BAD_SERVICE_PORT",
    "description": "Invalid service port: [portnumber]",
    "causes": [
      "on startup we set config store options( http_address, https_address) but invalid portno is passed for the configstore address, that is a number<0."
    ],
    "actions": [
      "contact support if running cbserver from a binary, if you have a src build, for the -configstore flag has a valid port number(typically http-8093, https-18093) for query service."
    ],
    "isUser": false
  },
  {
    "code": 2220,
    "ErrorCode": "E_ADMIN_BODY",
    "description": "LEGACY-  Error getting request body",
    "causes": [
      "/admin/prepareds/{name} endpoint allows PUT request with request body as encoded plan to setup a correspnding prepared statement for the plan passed. But something went wrong in reading the request body sent."
    ],
    "actions": [
      "contact support"
    ],
    "isUser": true
  },
  {
    "code": 2230,
    "ErrorCode": "E_ADMIN_FFDC",
    "description": "FFDC invocation failed.",
    "causes": [
      "POST /admin/ffdc to start \"manual\" ffdc(first fault data capture) is done before the allowed interval between consequtive attempts to start the invoation. The default interval time is 10sec.\nFor eg: consequtive request before 10seconds pass from the first request\nPOST /admin/ffdc HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nContent-Length: 0\nContent-Type: application/json\nHost: 127.0.0.1:9499\n\nHTTP/1.1 500 Internal Server Error\nContent-Type: application/json\nDate: Thu, 23 Nov 2023 09:05:47 GMT\nContent-Length: 225\n{\"_level\":\"exception\",\"caller\":\"admin_accounting_endpoint:2475\",\"cause\":{\"message\":\"Ensure sufficient interval between invocations.\",\"seconds_before_next\":6},\"code\":2230,\"key\":\"admin.ffdc\",\"message\":\"FFDC invocation failed.\"}"
    ],
    "actions": [
      "wait for 10sec before starting ffdc "
    ],
    "isUser": true
  },
  {
    "code": 2240,
    "ErrorCode": "E_ADMIN_LOG",
    "description": "Error accessing log",
    "causes": [
      "GET request to /admin/log/{file} failed as 1) {file} doesn't exist in log-path 2) {file} was deleted whilst being read."
    ],
    "actions": [
      "Ensure the log file being accessed exists for the duration of the request."
    ],
    "isUser": true
  },
  {
    "code": 3000,
    "ErrorCode": "E_PARSE_SYNTAX",
    "description": "Indicates a syntax error occurred during parsing.  The error details will be contained in the cause field.",
    "causes": [
      "A syntax error is present in a statement being parsed."
    ],
    "actions": []
  },
  {
    "code": 3005,
    "ErrorCode": "E_ERROR_CONTEXT",
    "description": "Generic error-> that lets the user know where(line and column cursor) his query is syntactically wrong",
    "causes": [
      "During the Parsing phase, the tokens from the scanner are reduced to a particluar parser rule(Grammar) but for the particular use case of"
    ],
    "actions": [
      "some examples: 1) query= SELECT 1 FROM `default`, 1 USE KEYS \"a\"; error:\"FROM Expression cannot have USE KEYS or USE INDEX (near line 1, column 26).\", what is message is saying is that if FROM term is not a collection/bucket cannot have USE KEYS or USE INDEX CLAUSE(s).  The safe bet would be to ask on https://www.couchbase.com/forums/ under \"n1ql\" or \"query\" tag"
    ],
    "isUser": true
  },
  {
    "code": 3006,
    "ErrorCode": "E_PARSE_INVALID_ESCAPE_SEQUENCE",
    "description": "invalid escape sequence",
    "causes": [
      "An invalid escape sequence was encountered whilst processing a string value."
    ],
    "actions": [
      "Refer to the documentation for valid string escape sequences"
    ],
    "isUser": true
  },
  {
    "code": 3007,
    "ErrorCode": "E_PARSE_INVALID_STRING",
    "description": "An invalid string was encounterd.",
    "causes": [
      "An opening quotation mark defining a string was encountered without any further characters.  All strings must be properly quoted."
    ],
    "actions": []
  },
  {
    "code": 3080,
    "ErrorCode": "E_AMBIGUOUS_REFERENCE",
    "description": "Ambiguous reference to field",
    "causes": [
      "Query's project field is ambiguous. Note we are schemaless so this scenario comes to play only in 2 cases. 1) no keyspace but projection field: SELECT k; error:[\n  {\n    \"code\": 3080,\n    \"column\": 8,\n    \"line\": 1,\n    \"msg\": \"Ambiguous reference to field 'k' (near line 1, column 8).\",\n    \"query\": \"SELECT k;\"\n  }\n],  2) join query but projection does't indicate which keyspace to look at SELECT k FROM {\"a\":1} a, {\"b\":1} b WHERE a.a=b.b; error:[\n  {\n    \"code\": 3080,\n    \"column\": 8,\n    \"line\": 1,\n    \"msg\": \"Ambiguous reference to field 'k' (near line 1, column 8).\",\n    \"query\": \"SELECT k FROM {\\\"a\\\":1} a, {\\\"b\\\":1} b WHERE a.a=b.b;\"\n  }\n]. Just to note the schemaless point SELECT a.k FROM {\"a\":1} a, {\"b\":1} b WHERE a.a=b.b; returns empty result without error as keyspace a doesn't have a document with `k` field after join."
    ],
    "actions": [
      "if 1) please recheck if the query without keyspace is what you meant. 2) the projection field must have the source keyspace attached (Formalized by hand) in case Join"
    ],
    "isUser": true
  },
  {
    "code": 3081,
    "ErrorCode": "E_DUPLICATE_VARIABLE",
    "description": "Duplicate variable, already in the scope as allowed identifier",
    "causes": [
      "1) When using LET CLAUSE and have variables with same name-> SELECT t1.airportname, t1.geo.lat, t1.geo.lon, t1.city, t1.type\nFROM `travel-sample`.inventory.airport t1\nLET min_lat = 71, min_lat = ABS(t1.geo.lon)*4+1;\nWHERE WHERE t1.geo.lat > min_lat\nAND t1.geo.lat < max_lat; error: msg\": \"Duplicate variable: 'min_lat' already in scope (near line 3, column 19).\",  2) When using WITH Clause, 2 or more ctes have the same name WITH a AS (SELECT 1), a AS (SELECT 2) SELECT 1; error: \"msg\": \"Duplicate WITH clause alias 'a' (near line 1, column 23)\""
    ],
    "actions": [
      "Rename your duplicate LET variable or duplicate CTE"
    ],
    "isUser": true
  },
  {
    "code": 3082,
    "ErrorCode": "E_FORMALIZER_INTERNAL",
    "description": "Formalizer internal error",
    "causes": [
      "This is raised in particular for a case where encoded_plan is used for subquery and subquery is marked as correlated, for eg: PREPARE test AS SELECT d1.a FROM `default` d1 WHERE d1.a in (SELECT RAW d2.a FROM default d2 WHERE d2.a=d1.a)\n;  Note in the plan:-> {\n                      \"#operator\": \"Filter\",\n                      \"condition\": \"(cover ((`d1`.`a`)) in correlated (select raw cover ((`d2`.`a`)) from `default`:`default` as `d2` where (cover ((`d2`.`a`)) = cover ((`d1`.`a`)))))\",\n                      \"optimizer_estimates\": {\n                        \"cardinality\": 1000.9999999999998,\n                        \"cost\": 751.1415658002394,\n                        \"fr_cost\": 12.738403162637601,\n                        \"size\": 105\n                      }\n                    }. By some magic someone has gone into your node and changed  where (cover ((`d2`.`a`)) = cover ((`d1`.`a`) to  where (cover ((`d2`.`a`)) = cover ((`d1`.`b`). You expect the error that unexpected correlated reference d2.b is not allowed."
    ],
    "actions": [
      "Your solution to is reprepare your original query and use the new prepare"
    ],
    "isUser": true
  },
  {
    "code": 3083,
    "ErrorCode": "E_PARSE_INVALID_INPUT",
    "description": "missing closing quote",
    "causes": [
      "1) when trying to parse a string expression, didn't find closing quote \" eg: SELECT a.* FROM {\"a\":\"} a;  , eg: SELECT a.* FROM {\"a\":\"\\\"} a; (Misuse of escaping \\)"
    ],
    "actions": [
      "Correct the usage by adding closing quote at the appropriate place, or ask on ask on https://www.couchbase.com/forums/ under \"n1ql\" or \"query\" tag "
    ],
    "isUser": true
  },
  {
    "code": 3100,
    "ErrorCode": "E_SEMANTICS",
    "description": "Wrapper error-> please check cause for actual error message",
    "causes": [],
    "actions": []
  },
  {
    "code": 3110,
    "ErrorCode": "E_JOIN_NEST_NO_JOIN_HINT",
    "description": "cannot have join hint (USE HASH or USE NL)",
    "causes": [
      "This is raised when user uses Lookup Join https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/join.html#lookup-join-clause , as the working of lookup join solely depends on ON KEYS Clause, so at the semantic layer we disallow join hint (USE HASH/ USE NL) , USE KEYS, USE INDEX. Also the case for LOOKUP NEST"
    ],
    "actions": [
      "Prefer ANSI or INDEX JOIN for join HINTS/ Use KEYS / USE INDEX HINTS"
    ],
    "isUser": true
  },
  {
    "code": 3120,
    "ErrorCode": "E_JOIN_NEST_NO_USE_KEYS",
    "description": "cannot have USE KEYS",
    "causes": [
      ",,"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 3130,
    "ErrorCode": "E_JOIN_NEST_NO_USE_INDEX",
    "description": "cannot have USE INDEX",
    "causes": [
      ",,"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 3150,
    "ErrorCode": "E_MERGE_INSERT_NO_KEY",
    "description": "MERGE with ON KEY clause cannot have document key specification in INSERT action.",
    "causes": [
      "User has used LOOKUP MERGE https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#lookup-merge , WHEN USING INSERT as LOOKUP-MERGE-ACTION, You cannoy pass key specification. Example of a wrong query MERGE INTO hotel t\nUSING [\n  {\"id\":\"2172211\", \"vacancy\": true},\n  {\"id\":\"2173111\", \"vacancy\": true}\n] source\nON KEY \"hotel_\"|| source.id\nWHEN NOT MATCHED THEN\n  INSERT(id, {\"id\":source.id, \"vacancy\":source.vacancy, \"new\":true});    The correct query would be to change the insert clause->  INSERT {\"id\":source.id, \"vacancy\":source.vacancy, \"new\":true};"
    ],
    "actions": [
      "Change your INSERT Clause as per LOOKUP-MERGE-INSERT https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#lookup-merge-insert , take a look at this example for inspiration https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#examples EXAMPLE 7"
    ],
    "isUser": true
  },
  {
    "code": 3160,
    "ErrorCode": "E_MERGE_INSERT_MISSING_KEY",
    "description": "MERGE with ON clause must have document key specification in INSERT action",
    "causes": [
      "USer has used ANSI MERGE https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#ansi-merge , WHEN USING INSERT as  ANSI-MERGE-ACTION , Need to pass key in INSERT Clause. Example of a wrong query MERGE INTO airport AS target\nUSING [\n  {\"iata\":\"DSA\", \"name\": \"Doncaster Sheffield Airport\"},\n  {\"iata\":\"VLY\", \"name\": \"Anglesey Airport / Maes Awyr M\u00f4n\"}\n] AS source\nON target.faa = source.iata\nWHEN MATCHED THEN\n  UPDATE SET target.old_name = target.airportname,\n             target.airportname = source.name,\n             target.updated = true\nWHEN NOT MATCHED THEN\n  INSERT {\"faa\": source.iata,\n                 \"airportname\": source.name,\n                 \"type\": \"airport\",\n                 \"inserted\": true} \nRETURNING *;  The correct query would be to change the insert clause-> INSERT (KEY UUID(),\n          VALUE {\"faa\": source.iata,\n                 \"airportname\": source.name,\n                 \"type\": \"airport\",\n                 \"inserted\": true} )"
    ],
    "actions": [
      "Change your INSERT CLause as per ANSI-MERGE-INSERT https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#ansi-merge , take a look at this example for inspiration https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#examples EXAMPLE 4 "
    ],
    "isUser": true
  },
  {
    "code": 3170,
    "ErrorCode": "E_MERGE_MISSING_SOURCE",
    "description": "MERGE is missing source.- DEAD CODE as caught by parser ??",
    "causes": [],
    "actions": []
  },
  {
    "code": 3180,
    "ErrorCode": "E_MERGE_NO_INDEX_HINT",
    "description": "MERGE with ON KEY clause cannot have USE INDEX hint specified on target.",
    "causes": [
      "Cannot pass index hints on target keyspace for LOOKUP-MERGE.  Example bad query MERGE INTO hotel t USE INDEX (def_inventory_hotel_city  USING GSI)\nUSING [\n  {\"id\":\"2172211\", \"vacancy\": true},\n  {\"id\":\"2173111\", \"vacancy\": true}\n] source\nON KEY \"hotel_\"|| source.id\nWHEN NOT MATCHED THEN\n  INSERT {\"id\":source.id, \"vacancy\":source.vacancy, \"new\":true}; -> remove USE INDEX CLAUSE"
    ],
    "actions": [
      "Switch to ANSI MERGE if you want to use USE INDEX CLAUSE https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#ansi-merge "
    ]
  },
  {
    "code": 3190,
    "ErrorCode": "E_MERGE_NO_JOIN_HINT",
    "description": "MERGE with ON KEY clause cannot have join hint specified on source.",
    "causes": [
      "Cannot pass JOIN HINTS( USE HASH(BUILD) / USE HASH(PROBE) / USE NL) for LOOKUP-MERGE, as underlying JOIN is LOOKUP-JOIN. Example bad query MERGE INTO hotel t \nUSING [\n  {\"id\":\"2172211\", \"vacancy\": true},\n  {\"id\":\"2173111\", \"vacancy\": true}\n] source USE HASH(PROBE)\nON KEY \"hotel_\"|| source.id\nWHEN NOT MATCHED THEN\n  INSERT {\"id\":source.id, \"vacancy\":source.vacancy, \"new\":true}; -> if you want to use Nested loop join or Hash join shift to ANSI MERGE (NOTE: for NL need to have appropriate index)"
    ],
    "actions": [
      "Switch to ANSI MERGE if you want to use JOIN HINTS(USE NL/USE HASH) https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#ansi-merge "
    ]
  },
  {
    "code": 3200,
    "ErrorCode": "E_MIXED_JOIN",
    "description": "When you have more than 1 JOIN Clause-> 1) Cannot mix NON-ANSI syntax with ANSI syntax, i.e left of ANSI JOIN/NEST is NON-ANSI(LOOKUP/INDEX ) JOIN/NEST, 2) CANNOT mix ANSI syntax with NON-ANSI syntax, i.e left of NON-ANSI(LOOKUP/INDEX) JOIN/NEST is ANSI JOIN/NEST. To put simply if starting with INDEX JOIN/NEST any use of JOINS after this must also be NON-ANSI (LOOKUP/INDEX), if starting with ANSI JOIN any use of JOINS after this MUST also be ANSI. Same goes for NEST",
    "causes": [
      "examples of bad query: SELECT e.employee_name, d.department_name, p.project_name\nFROM `employees` AS e\nJOIN `departments` AS d ON e.department_id = META(d).id\nJOIN `projects` AS p ON KEYS META(d).id. -> We are combining ANSI JOIN and LOOKUP JOIN here"
    ],
    "actions": [
      "JOIN documentation for ypur reference to reform your query https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/join.html#section_ek1_jnx_1db or use couchbaseiq in capella"
    ]
  },
  {
    "code": 3220,
    "ErrorCode": "E_WINDOW_SEMANTIC",
    "description": "For Specific Aggregates we don't support usage of 1.Aggregate Quantifier DISTINCT , 2. NULL modifier  https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/windowfun.html#nulls-treatment is not allowed, 3. FROM modifier https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/windowfun.html#nthval-from  is not allowed, 4. for some window function FILTER CLAUSE is not allowed https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/aggregatefun.html#filter-clause , 5. window functions require OVER CLAUSE, regular usage is not allowed",
    "causes": [
      "1) NOT SURE OF ANY AGGREGATE THAT DISALLOWS DISTINCT as is or over a WINDOW??",
      "2) NULLS treatment is allowed only for Window functions https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/windowfun.html , and not for aggegrate functions https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/aggregatefun.html used as window function.",
      "3) FROm modifier is only allowed in case of NTH_VALUE function https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/windowfun.html#fn-window-nth-value . Reason behind this is \"semantically\" nulls checking is not possible in aggregate functions and order-for-rank([FROM LAST|FROM FIRST]) doesn't make sense for any function except NTH_VALUE()"
    ],
    "actions": [
      "Please correct the usage by removing the Clause that is breaking the semantic check. Or ask at couchbase forums for further help"
    ]
  },
  {
    "code": 3230,
    "ErrorCode": "E_ENTERPRISE_FEATURE",
    "description": "The feature accessed by the STATEMENT user has tried to execute is an enterprise level feature.",
    "causes": [
      "1) Window Functions supported only in EE",
      "2) ADVISE statement and ADVISOR() function is only supported in EE",
      "3) UPDATE STATISTICS STATEMENT is not supported in EE as cost-based-optimizer is not available"
    ],
    "actions": []
  },
  {
    "code": 3250,
    "ErrorCode": "E_ADVISE_UNSUPPORTED_STMT",
    "description": "Advise supports SELECT, MERGE, UPDATE and DELETE statements only.",
    "causes": [
      "Pretty self-sufficient error message but incase you wanted to know-> ADVISE DOESN'T SUPPORT 1. UPSERT, 2. UPDATE STATISTICS , 3. START TRANSACTION, 4. COMMIT, 5. ROLLBACK [SAVE_POINT] , 5. SET TRANSACTION ISOLATION, 6. DROP SCOPE, 7. CREATE SCOPE, 8. SAVEPOINT , 9. REVOKE ROLE, 10. GRANT ROLE, 11. INSERT, 12. INFER, 13. CREATE PRIMARY INDEX, 13. DROP INDEX, 14. CREATE INDEX, 15. BUILD INDEX, 16. ALTER INDEX, 17. EXECUTE FUNCTION, 18. DROP FUNCTION, 19. CREATE FUNCTION, 20. EXPLAIN, 21. EXPLAIN FUNCTION, 22. EXECUTE, 23. DROP COLLECTION, 24. CREATE COLLECTION, 25. ADVISE"
    ],
    "actions": [
      "ADVISE documentation for your reference https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advise.html "
    ]
  },
  {
    "code": 3255,
    "ErrorCode": "E_ADVISOR_PROJ_ONLY",
    "description": "Advisor function is only allowed in projection clause",
    "causes": [
      "Cannot USE ADIVISOR(..) function in FROM/WHERE CLAUSE. As doesn't make sense to use semantically."
    ],
    "actions": [
      "Typical usage SELECT AVISOR([statement/array]) https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html  "
    ]
  },
  {
    "code": 3256,
    "ErrorCode": "E_ADVISOR_NO_FROM",
    "description": "FROM clause is not allowed when Advisor function is present in projection clause.",
    "causes": [
      "Cannot have FROM CLAUSE when using ADVISOR() in projection. Again for semantic reasons."
    ],
    "actions": [
      "Typical usage SELECT AVISOR([statement/array]) https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html   "
    ]
  },
  {
    "code": 3260,
    "ErrorCode": "E_MHDP_ONLY_FEATURE",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 3261,
    "ErrorCode": "E_MISSING_USE_KEYS",
    "description": "term must have USE KEYS",
    "causes": [
      "user has passed keyspace using named/positional parameter for UPDATE/DELETE statement. Example: \\set -$d `default`;  DELETE FROM $d as d USE KEYS [\"key::00d9be61-0905-41a2-9c9d-cb67dd310d04\"]; , but without USE KEYS this is a bad query eg: DELETE FROM $d as d;  In a similar fashion same holds true for UPDATE when passing keyspace as named/positional param something like UPDATE [name-param] as [alias] USE KEYS [..] SET/UNSET CLAUSE-WHERE CLAUSE-LIMIT CLAUSE-RETURNING CLAUSE."
    ],
    "actions": [
      "If the reason behind hiding the keyspace term using named/positional is not significant replace with the keyspace-term[bucket.scope.collection] to avoid USE KEYS clause."
    ]
  },
  {
    "code": 3262,
    "ErrorCode": "E_HAS_USE_INDEXES",
    "description": "term should not have USE INDEX",
    "causes": [
      "user has passed keyspace term using named/positional parameter for UPDATE/DELETE statement. And has USE INDEX subclause, this is the root of this is error. Semantically we disallow USE INDEX clause as positional/named parameters are dynamic."
    ],
    "actions": [
      "If the reason behind hiding the keyspace term using named/positional is not significant replace with the keyspace-term[bucket.scope.collection] and have USE INDEX clause."
    ]
  },
  {
    "code": 3270,
    "ErrorCode": "E_UPDATE_STAT_INVALID_INDEX_TYPE",
    "description": "UPDATE STATISTICS (ANALYZE) supports GSI indexes only for INDEX option.",
    "causes": [
      "user may have tried to run UPDATE STATISTICS for index other than GSI as the provider. Example bad query: UPDATE STATISTICS FOR INDEX test ON `travel-sample`.`inventory`.`landmark` USING FTS;"
    ],
    "actions": [
      "Currently CBO is only supported for GSI indexes."
    ]
  },
  {
    "code": 3271,
    "ErrorCode": "E_UPDATE_STAT_INDEX_ALL_COLLECTION_ONLY",
    "description": "INDEX ALL option for UPDATE STATISTICS (ANALYZE) can only be used for a collection.",
    "causes": [
      "INDEX ALL clause expects keyspace_ref specified to be a collection. Example bad query: UPDATE STATISTICS FOR `travel-sample` INDEX ALL; cannot update statistics for all indexes on travel-sample bucket, but can collect statistics for all indexes of a collection, example: UPDATE STATISTICS FOR `travel-sample`.inventory.airport INDEX ALL;"
    ],
    "actions": [
      "Change keyspace_ref term to a path that points to a collection."
    ]
  },
  {
    "code": 3272,
    "ErrorCode": "E_UPDATE_STAT_SELF_NOTALLOWED",
    "description": "\"UPDATE STATISTICS of 'self' is not allowed\"",
    "causes": [
      "user tried a UPDATE STATISTICS for index expression https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/statistics-expressions.html query, with one of the index expression as \"SELF\", which is semantically ruled out as it is not a valid index expression. Example bad query: UPDATE STATISTICS FOR hotel(city, country, free_breakfast, SELF); Correct usage of SELF is in SELECT SELF / RETURN SELF constructs."
    ],
    "actions": [
      "remove SELF keyword from the index expressions list. Reference for ypur help https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/statistics-expressions.html#index-expr "
    ]
  },
  {
    "code": 3280,
    "ErrorCode": "E_CREATE_INDEX_NOT_INDEXABLE",
    "description": "index key expression is not indexable",
    "causes": [
      "CREATE INDEX statement , index keys expression cannot be a constant or the passed expression is flagged as not indexable. For a run through of this scenario assume we have `default` collection with documents like {\"a\":[number]} , some bad index definitions: 1) CREATE INDEX def_idx ON default(SIN(60)); Expression SIN(60)'s value is predetermined. 2) CREATE INDEX def_idx ON default(INFER_VALUE(a)); the function INFER_VALUE() is not indexable. Some good examples 1) CREATE INDEX def_idx ON default(a); 2) CREATE INDEX def_idx(SIN(a));"
    ],
    "actions": [
      "change the index key definition to an expression that fits your original purpose and is indexable. SQL++ expressions for your reference https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/index.html#N1QL_Expressions , or array expression for array indexing https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/indexing-arrays.html#array-expr "
    ]
  },
  {
    "code": 3281,
    "ErrorCode": "E_CREATE_INDEX_ATTRIBUTE_MISSING",
    "description": "MISSING attribute not allowed (Only allowed with gsi leading key).",
    "causes": [
      "1) if using FLATTEN_KEYS construct only 1st argument can have INCLUDE MISSING",
      "2) if not a gsi INDEX , definition allows INCLUDE MISSING only for leading key."
    ],
    "actions": []
  },
  {
    "code": 3282,
    "ErrorCode": "E_CREATE_INDEX_ATTRIBUTE",
    "description": "index key attributes are not allowed for array indexing when using FLATTEN_KEYS()",
    "causes": [
      "[ INCLUDE MISSING ]/ [ ASC/DESC ] index key attributes are disallowed when using ARRAY index keys using FLATTEN_KEYS(..), example bad query CREATE INDEX ixf_sched_missing\nON route\n(DISTINCT ARRAY FLATTEN_KEYS(v.utc INCLUDE MISSING, v.day) FOR v IN schedule END INCLUDE MISSING);"
    ],
    "actions": [
      "NOTE: expressions passed to FLATTEN_KEYS() can use index-key attributes but not the actual array-index expression."
    ]
  },
  {
    "code": 3283,
    "ErrorCode": "E_FLATTEN_KEYS",
    "description": "flatten_keys(...) is not allowed in this context",
    "causes": [
      "FLATTEN_KEYS function is only allowed in 1) CREATE INDEX 2) UPDATE STATISTICS 3) Not surrounded by a function , example bad query: CREATE INDEX ixf_sched\n  ON route\n  (ALL ARRAY GREATEST(FLATTEN_KEYS(s.day DESC, s.flight), 100) FOR s IN schedule END,\n  sourceairport, destinationairport, stops);  Here GREATEST function wraps FLATTEN_KEYS which is semantically disallowed. 4) No recursive calls , example bad query: CREATE INDEX ixf_sched\n  ON route\n  (ALL ARRAY GREATEST(FLATTEN_KEYS(s.day DESC, FLATTEN_KEYS(s.flight))) FOR s IN schedule END,\n  sourceairport, destinationairport, stops); Recursive usage is semanticantically incorrect."
    ],
    "actions": [
      "rethink if your query needs FLATTEN_KEYS function, also to summarize semantic checks -> 1. not surrounded by any other function,  2. no recursive calls "
    ]
  },
  {
    "code": 3284,
    "ErrorCode": "E_ALL_DISTINCT_NOT_ALLOWED",
    "description": "ALL/DISTINCT is only allowed in CREATE INDEX & UPDATE STATISTICS statements. -> NOT CALLED as parser rules never reduce to expression.all for any other case except CREATE INDEX & UPDATE STATISTICS using all_expr rule",
    "causes": [],
    "actions": []
  },
  {
    "code": 3285,
    "ErrorCode": "E_CREATE_INDEX_SELF_NOTALLOWED",
    "description": "Index of SELF is not allowed as a index key",
    "causes": [
      "SELF keyword cannot be used as a index key. Example bad query CREATE INDEX temp_def_idx ON default(SELF, a);"
    ],
    "actions": [
      "Remove SELF as index key, if you want an index on each document in the collection you could use the meta function https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/metafun.html#meta  , the meta().id key is covered by any index on the keyspace which covers the document key. This approach can be used if this is the angle you where thinking of."
    ]
  },
  {
    "code": 3286,
    "ErrorCode": "E_INDEX_NOT_ALLOWED",
    "description": "PRIMARY INDEX is not allowed using FTS",
    "causes": [
      "CREATE PRIMARY INDEX ON [keyspace] USING FTS, is semantically not allowed."
    ],
    "actions": [
      "Change to gsi as your provider.(USING GSI)"
    ]
  },
  {
    "code": 3290,
    "ErrorCode": "E_JOIN_HINT_FIRST_FROM_TERM",
    "description": "Join hint (USE HASH or USE NL) cannot be specified on the first from term",
    "causes": [
      "Legacy USE HASH: https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/join.html#use-hash-hint  / USE NL hints: https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/join.html#use-nl-hint  are not allowed for the first from term in the join tree. Example bad query: SELECT a.airportname, r.airline\nFROM airport a USE HASH(probe)\nJOIN route r \nON a.faa = r.sourceairport\nWHERE a.city = \"San Francisco\";"
    ],
    "actions": [
      "Assuming you have cbo(cost-based-optimizer) on, we allow join enumeration. Now new relation style join hints can be used to provide join hints on any term in the join tree including first keyspace term. Example usage of this construct: SELECT /*+ USE_HASH(a) */\n       a.airportname, r.airline\nFROM airport a\nJOIN route r\nON a.faa = r.sourceairport\nWHERE a.city = \"San Francisco\";  documentation link for your reference: https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/optimizer-hints.html "
    ]
  },
  {
    "code": 3300,
    "ErrorCode": "E_RECURSIVE_WITH_SEMANTIC",
    "description": "recursive_with semantics: [cause]",
    "causes": [
      "1) We semantically disallow certain constructs when using Recursive CTEs. To be in accordance to the sql standard and also follow linearly recursive definition approach.\nLinear recursive, to put simply just keep joining newly generated Ancestor documents with Parent.",
      "2) disallow order by/ limit / offset Clause in subquery definition for the CTE.\nOrder By/ LIMIT / OFFSET all are applied on the entire result set thus making it unclear how to apply the during each iteration. Order/LIMIT/OFFSET are part to the entire select(both anchor & recursive) which if seen during formalization we error out.\n WITH RECURSIVE empHierar AS (SELECT e.*, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.*, empHierar.lvl+1 as lvl FROM employees e1 JOIN empHierar ON empHierar.employee_id = e1.manager_id ORDER BY employee_name) SELECT * FROM empHierar;\n{\n    \"requestID\": \"46d6646d-e12f-4ab6-8950-1905626ecace\",\n    \"errors\": [\n        {\n            \"code\": 3300,\n            \"msg\": \"recursive_with semantics: Order/Limit/Offset not allowed\"\n        }\n    ],\n\nWITH RECURSIVE empHierar AS (SELECT e.*, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.*, empHierar.lvl+1 as lvl FROM employees e1 JOIN empHierar ON empHierar.employee_id = e1.manager_id LIMIT 3) SELECT * FROM empHierar;\n{\n    \"requestID\": \"cd899dce-66d3-4f81-a09d-de9806dce1fc\",\n    \"errors\": [\n        {\n            \"code\": 3300,\n            \"msg\": \"recursive_with semantics: Order/Limit/Offset not allowed\"\n        }\n    ],\n \nWITH RECURSIVE empHierar AS (SELECT e.*, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.*, empHierar.lvl+1 as lvl FROM employees e1 JOIN empHierar ON empHierar.employee_id = e1.manager_id OFFSET 3) SELECT * FROM empHierar;\n{\n    \"requestID\": \"ad2b5cec-5831-4846-af19-96390fb01ced\",\n    \"errors\": [\n        {\n            \"code\": 3300,\n            \"msg\": \"recursive_with semantics: Order/Limit/Offset not allowed\"\n        }\n    ],",
      "3) Aggregates/Window functions are not allowed, -> both anchor as well as recursive clause\nThe reason for this restriction is related to the way recursive CTEs are processed. The recursive term is essentially executed repeatedly until no more rows are returned. If you introduce an aggregate within the recursive term, it becomes unclear how the aggregation should be applied during each iteration. Aggregations are typically applied after all rows have been retrieved, making their usage within a recursive context less straightforward.\n WITH RECURSIVE cte AS (SELECT COUNT(*) AS CountAll FROM landmark) SELECT * FROM cte;\n{\n    \"requestID\": \"4385c979-6062-4f85-8298-176a12093fbd\",\n    \"errors\": [\n        {\n            \"code\": 3300,\n            \"msg\": \"recursive_with semantics: Aggregates/Window functions are not allowed\"\n        }\n    ],",
      "4) Groupby is not allowed -> both in anchor as well as recursive clause\nWhen you introduce GROUP BY in the recursive term, it creates ambiguity in terms of how to group the results at each iteration. The grouping operation is typically applied to the entire result set, and it's not clear how the grouping should be handled during each step of the recursion.\nWITH RECURSIVE empHierar AS (SELECT e.*, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.*, empHierar.lvl+1 as lvl FROM employees e1 JOIN empHierar ON empHierar.employee_id = e1.manager_id GROUP BY e1.manager_id) SELECT * FROM empHierar;\n{\n    \"requestID\": \"7909e4fa-6c0f-402c-b60f-bf24c38ef1bb\",\n    \"errors\": [\n        {\n            \"code\": 3300,\n            \"msg\": \"recursive_with semantics: Grouping is not allowed\"\n        }\n    ],",
      "5) DISTINCT is not allowed in PROJECTION. As it doesn't make sense on how to account for DISTINCT Projection terms across iteration, \n WITH RECURSIVE empHierar AS (SELECT DISTINCT e.employee_id, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.employee_id, empHierar.lvl+1 as lvl FROM employees e1 JOIN empHierar ON empHierar.employee_id = e1.manager_id) SELECT * FROM empHierar;\n{\n    \"requestID\": \"7df8a033-876c-4567-8fd9-0fc4f971571c\",\n    \"errors\": [\n        {\n            \"code\": 3300,\n            \"msg\": \"recursive_with semantics: Distinct not allowed\"\n        }\n    ],"
    ],
    "actions": [
      "Don't make use of\n1) Order/Limit/Offset on the CTE definition\n2) group by neither permitted in anchor nor recursive\n3) distinct clause on projection terms is not allowed in both anchor and recursive clause.\n4) Aggregates/window functions are not allowed as well again for both anchor and recursive clause."
    ],
    "isUser": true
  },
  {
    "code": 3301,
    "ErrorCode": "E_ANCHOR_RECURSIVE_REF",
    "description": "Anchor Clause cannot have recursive reference in FROM Expression : [recursive_alias]",
    "causes": [
      "During formalization of WITH Clause , if recursive and also subquery-SELECT has both UNION/UNION-ALL.\nWe split the SELECT on UNION/UNION-ALL -> to produce anchor and recursive clause.\n\nSemantically disallow recursive reference in Anchor's FROM Clause.\n WITH RECURSIVE empHierar AS (SELECT * FROM empHierar UNION SELECT 1) SELECT * FROM empHierar;\n{\n    \"requestID\": \"322b79a1-85b6-4522-a420-09129bdb9c4b\",\n    \"errors\": [\n        {\n            \"code\": 3301,\n            \"msg\": \"Anchor Clause cannot have recursive reference in FROM expression: empHierar\"\n        }\n    ],"
    ],
    "actions": [
      "Can't have recursive refernce in anchor as it isn't a defined expression yet, surely this not what you were trying todo."
    ],
    "isUser": true
  },
  {
    "code": 3302,
    "ErrorCode": "E_MORE_THAN_ONE_RECURSIVE_REF",
    "description": "recursive ref:[recursive cte-alias] must not appear more than once in the FROM clause",
    "causes": [
      "As we follow linear recursive sql standard for Recursive withs, \n1) We semantically disallow SELF JOIN for the recursive alias, as uing self-join with the recursive alias directly within the recursive clause could lead to ambiguity in terms of which instance of the CTE is being referred to during each iteration\n\n> WITH RECURSIVE empHierar AS (SELECT e.employee_id, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.employee_id, empHierar.lvl+1 as lvl FROM employees e1 JOIN empHierar h1 ON eh1.employee_id = e1.manager_id JOIN empHierar h2 ON h2.employee_name=h1.employee_name ) SELECT * FROM empHierar;\n{\n    \"requestID\": \"0626fda3-c8a7-4682-94b0-1f6502eab134\",\n    \"errors\": [\n        {\n            \"code\": 3302,\n            \"msg\": \"recursive ref:empHierar must not appear more than once in the FROM clause\"\n        }\n    ]"
    ],
    "actions": [
      "Multiple usage of recursive reference in the FROM clause is not supported, please rethink the query or ask on forums"
    ],
    "isUser": true
  },
  {
    "code": 3303,
    "ErrorCode": "E_CONFIG_INVALID_OPTION",
    "description": "Invalid config option ",
    "causes": [
      "Only \"levels\", \"documents\" are valid config options for the options clause\n\n WITH RECURSIVE empHierar AS (SELECT e.employee_id, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.employee_id, h1.lvl+1 as lvl FROM employees e1 JOIN empHierar h1 ON h1.employee_id = e1.manager_id ) OPTIONS {\"not-valid\":1} SELECT * FROM empHierar;\n{\n    \"requestID\": \"750d744b-70c6-4395-851a-2ca9c4644807\",\n    \"signature\": {\n        \"*\": \"*\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 3303,\n            \"msg\": \"Invalid config option not-valid\",\n            \"reason\": {\n                \"invalid_option\": \"not-valid\"\n            }\n        }\n    ],"
    ],
    "actions": [
      "Allowed config options are:\n\"levels\"-   Exit after level N.\n\"documents\" -  Exit after accumulating N documents."
    ],
    "isUser": true
  },
  {
    "code": 3304,
    "ErrorCode": "E_RECURSION_UNSUPPORTED",
    "description": "recursive_with_unsupported: [reason]",
    "causes": [
      "1) OUTER JOIN not supported, as may lead \n WITH RECURSIVE empHierar AS (SELECT e.employee_id, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.employee_id, h1.lvl+1 as lvl FROM employees e1 LEFT OUTER JOIN empHierar h1 ON h1.employee_id = e1.manager_id ) OPTIONS {\"not-valid\":1} SELECT * FROM empHierar;\n{\n    \"requestID\": \"bd4f39a2-42a2-4005-abae-f67aae3be504\",\n    \"errors\": [\n        {\n            \"code\": 3304,\n            \"msg\": \"recursive_with_unsupported: OUTER JOIN\",\n            \"reason\": \"may lead to potential infinite recursion\"\n        }\n    ],\nreason for this lies in how the outer join condition affects the way rows are matched during each iteration of the recursion",
      "2) recursive NEST is unsupported for now\n WITH RECURSIVE empHierar AS (SELECT e.employee_id, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.employee_id, h1.lvl+1 as lvl FROM employees e1 NEST travellers t ON t.name = e1.manager_id ) OPTIONS {\"not-valid\":1} SELECT * FROM empHierar;\n{\n    \"requestID\": \"73dc1eaf-62bd-4419-b53a-aa5ee510b25c\",\n    \"errors\": [\n        {\n            \"code\": 3304,\n            \"msg\": \"recursive_with_unsupported: NEST\",\n            \"reason\": \"`default`:`employees` as `e1` nest `default`:`travellers` as `t` on ((`t`.`name`) = (`e1`.`manager_id`))\"\n        }\n    ],",
      "3) recursive UNNEST is not supported for now\n WITH RECURSIVE empHierar AS (SELECT e.employee_id, 0 as lvl FROM employees e WHERE e.manager_id IS MISSING UNION SELECT e1.employee_id, h1.lvl+1 as lvl, dept FROM employees e1 UNNEST e1.dept as dept ) OPTIONS {\"not-valid\":1} SELECT * FROM empHierar;\n{\n    \"requestID\": \"0494a309-b0d4-41d2-9a32-56b32862a8ed\",\n    \"errors\": [\n        {\n            \"code\": 3304,\n            \"msg\": \"recursive_with_unsupported: UNNEST\",\n            \"reason\": \"`default`:`employees` as `e1` unnest (`e1`.`dept`) as `dept`\"\n        }\n    ],"
    ],
    "actions": [
      "1) only use INNER JOIN (which is the default for Ansi, Lookup & Index join)",
      "2) recursive NESTing is unsupported for now, reach out to support if you think it is a good feature to have.",
      "3) recursive UNNESTing is unsupported for now, reach out to support if you think it is a good feature to have."
    ],
    "isUser": true
  },
  {
    "code": 4000,
    "ErrorCode": "E_PLAN",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 4001,
    "ErrorCode": "E_REPREPARE",
    "description": "reprepare_error",
    "causes": [
      "When trying to get prepared from the preparedcache if the entry is not found on the local machine, the prepared statement cache is primed from another query node. We do not use the plan as is straight away as we cannot trust anything received over the network. We verify the plan, we check for the uid for each keyspace involved in the plan operator.  Also, check if metadata for the indexers & keyspaces involved is same as the one one in the encoded plan. If the before mentioned verify & metadata check return false. We reprepare the text-statement. And while repreparing either 1) parsing the statement failed,  2) building the plan failed  3) encoding the plan to store in the preparedcache entry failed"
    ],
    "actions": [
      "The prepared entry is likely to be corrupt. One way to go about this would be to prepare the statement under a new name."
    ],
    "isUser": false
  },
  {
    "code": 4010,
    "ErrorCode": "E_NO_TERM_NAME",
    "description": "From Term must have a name or alias.",
    "causes": [
      "root of the issue here is when passing terms in FROM clause, the formalizer runs through the terms for the easy of projection operator. When constructing from_term using a keyspace/collection, without an alias the path is taken for eg: `travel-sample`inventory.airport -> path=airport. Thus projection airport.id now knows how to pull out the value for field id from the scope. But when using a from expression term, eg: [{\n  \"id\": 1254}] without an explicit alias, The formalizer would fail to annotate the projection terms thus we error out during formalization of the expression term if no alias is passed. This applies for joins/nest as well. Example bad query: SELECT id\nFROM [{\n  \"id\": 1254,\n  \"type\": \"airport\",\n}];"
    ],
    "actions": [
      "add an alias for each expression term used in FROM Clause. Don't forget to annotate your projection terms with the same alias. The correct query for the bad example in causes: SELECT a.id\nFROM [{\n  \"id\": 1254,\n  \"type\": \"airport\"\n}] a;"
    ]
  },
  {
    "code": 4020,
    "ErrorCode": "E_DUPLICATE_ALIAS",
    "description": "Duplicate alias ",
    "causes": [
      "user is expected alias from terms in a distinguishable manner,i.e all of them are unique. Possible causes 1) same alias in JOIN-> SELECT r.airportname, r.airline\nFROM airport r\nJOIN route r\nON r.faa = r.sourceairport\nWHERE r.city = \"San Francisco\"; 2) Similarly for NEST https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/nest.html  3) UNNEST https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/unnest.html 4) FROM term has same alias as WITH term, example bad query: WITH a AS (SELECT 1 as r) SELECT a.r as r1, a.r as r2 FROM a, [{\"r\":2}] a; NOTE: from term can keyspace/expression/subquery, 4) MERGE source and target have same alias, example bad query: MERGE INTO hotel t\nUSING [\n  {\"id\":\"21728\", \"vacancy\": true},\n  {\"id\":\"21730\", \"vacancy\": true}\n] t\nON meta(t).id = \"hotel_\" || t.id\nWHEN MATCHED THEN ..."
    ],
    "actions": [
      "Rename the alias used so it is unique."
    ]
  },
  {
    "code": 4021,
    "ErrorCode": "E_DUPLICATE_WITH_ALIAS",
    "description": "Duplicate WITH alias reference",
    "causes": [
      "WITH clause terms or cte(common table expression) have the same alias. This is is disallowed during formalization as it creates ambiguity , example bad query: WITH a AS (SELECT 1 as r), a AS (SELECT 2 as r) SELECT a.r as r1 FROM a;"
    ],
    "actions": [
      "Rename the alis used for the cte that is a duplicate"
    ]
  },
  {
    "code": 4025,
    "ErrorCode": "E_UNKNOWN_FOR",
    "description": "Unknow alias in : ON KEY [expr] FOR [alias]. ",
    "causes": [
      "This error is raised when using IndexJoins where the ON KEY ... FOR ... Clause has an alias that was not previously seen by the formalizer. Typically the FOR includes the left side of join and user has made a mistake in refering to the same alias, example bad query: SELECT * FROM airline\n  JOIN route\n  ON KEY route.airlineid FOR air\nWHERE airline.icao = \"SWA\";  Here inplace of \"air\" the formalizer expects \"airline\""
    ],
    "actions": [
      "Use the correct alias for ON KEY ... FOR ... Clause. Find the documentation here https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/join.html#index-join-clause for your reference."
    ]
  },
  {
    "code": 4030,
    "ErrorCode": "E_SUBQUERY_MISSING_KEYS",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 4035,
    "ErrorCode": "E_SUBQUERY_MISSING_INDEX",
    "description": "No secondary index available for keyspace, in correlated subquery",
    "causes": [
      "The keyspace in from clause of a correlated subquery: has more than 1000documents so at planning time we raise error as in production without a secondary index the query would be slow due to the underlying cartesian product. Example bad query:  SELECT airportname FROM `travel-sample`.inventory.airport AS outerAirport WHERE ( SELECT COUNT(*) FROM `travel-sample`.inventory.route AS innerRoute WHERE innerRoute.sourceairportid = outerAirport.id ) > 50;\\n error:  {\n            \"code\": 5370,\n            \"msg\": \"Unable to run subquery - cause: Correlated subquery's keyspace (innerRoute) cannot have more than 1000 documents without appropriate secondary index\"\n        },\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating filter\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"context:1132\",\n                \"code\": 5370,\n                \"icause\": \"Correlated subquery's keyspace (innerRoute) cannot have more than 1000 documents without appropriate secondary index\",\n                \"key\": \"execution.subquery.build\",\n                \"message\": \"Unable to run subquery\"\n            }\n        }"
    ],
    "actions": [
      "Create relevant index for the predicate(key) that makes the subquery correlated. For our bad example: CREATE INDEX adv_sourceairportid ON `travel-sample`.`inventory`.`route`(`sourceairportid` INCLUDE MISSING)"
    ],
    "isUser": true
  },
  {
    "code": 4036,
    "ErrorCode": "E_SUBQUERY_PRIMARY_DOCS_EXCEEDED",
    "description": "Correlated subquery's keyspace [keyspace] cannot have more than 100 documents without appropriate secondary index",
    "causes": [
      "Similar to joins correlated subquery needed secondary index for performance reasons,\n\nSELECT a FROM default d1 WHERE EXISTS (SELECT a FROM default d2 WHERE d1.a=d2.a);\n[\n  {\n    \"code\": 5370,\n    \"msg\": \"Unable to run subquery - cause: Correlated subquery's keyspace (d2) cannot have more than 1000 documents without appropriate secondary index\"\n  },\n  {\n    \"code\": 5010,\n    \"msg\": \"Error evaluating filter\",\n    \"reason\": {\n      \"_level\": \"exception\",\n      \"caller\": \"context:1154\",\n      \"code\": 5370,\n      \"icause\": \"Correlated subquery's keyspace (d2) cannot have more than 1000 documents without appropriate secondary index\",\n      \"key\": \"execution.subquery.build\",\n      \"message\": \"Unable to run subquery\"\n    }\n  }\n]"
    ],
    "actions": [
      "CREATE INDEX for the keyspace in the correlated subquery"
    ],
    "isUser": true
  },
  {
    "code": 4040,
    "ErrorCode": "E_NO_SUCH_PREPARED",
    "description": "No such prepared statement:",
    "causes": [
      "1) User has requested sent a DELETE request to /query/service/admin/prepareds/\\{pname\\} to delete the pname entry from the prepared cache, but got a bad response as no such prepared entry with name \\{pname\\} is found. 2) query run : EXECUTE {pname} ; but pname doesn't exist in the prepared cache. 3) user may have prepared a statement with a different query context, and execute with another query context -> this fails the getPrepared logic."
    ],
    "actions": [
      "run SELECT * FROM system:prepareds; this will tell you all the prepareds you have(across nodes) , notice name and queryContext fields."
    ],
    "isUser": true
  },
  {
    "code": 4050,
    "ErrorCode": "E_UNRECOGNIZED_PREPARED",
    "description": "JSON unmarshalling error",
    "causes": [
      "On startup cbq-engine/query service tries to prime prepared entries from other nodes that have query service running, after received the entry(which contains encoded plan), we decode the encoded plan. But logic to decode fails on the data(encoded plan ) received."
    ],
    "actions": [
      "likely corrupt encoded plan/ prepared statement, start fresh prepare the statement under a new name"
    ],
    "isUser": false
  },
  {
    "code": 4060,
    "ErrorCode": "E_PREPARED_NAME",
    "description": "Unable to add name:[preparedname], duplicate name: [preparedname]",
    "causes": [
      "User has ran PREPARE [pname] as [stmt], but entry for [pname] already exists with a different text i.e statement, so cannot add."
    ],
    "actions": [
      "use SELECT  statement FROM system:prepareds WHERE name=[pname], only if that statement matches you are allowed to manually  try for a reprepare. Else the simple solution here would be to just use a different name"
    ],
    "isUser": true
  },
  {
    "code": 4070,
    "ErrorCode": "E_PREPARED_DECODING",
    "description": "Unable to decode prepared statement",
    "causes": [
      "decode has 3 steps: 1) going from encoded prepared statement first decode 2) decompress 3) unmarshal prepared bytes to prepared algebra struct. If any of the steps mentioned earlier fail while priming the cache we raise this error"
    ],
    "actions": [
      "likely corrupt encoded plan/ prepared statement, start fresh prepare the statement under a new name"
    ],
    "isUser": false
  },
  {
    "code": 4080,
    "ErrorCode": "E_PREPARED_ENCODING_MISMATCH",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 4090,
    "ErrorCode": "E_ENCODING_NAME_MISMATCH",
    "description": "Mismatching name in encoded plan",
    "causes": [
      "When trying to prime prepared entires from other nodes, encoding plan and name mapping doesn't match on the current node when comparing with the remote entry that is when this error is raised"
    ],
    "actions": [
      "DELETE the entry and prepare again."
    ],
    "isUser": false
  },
  {
    "code": 4091,
    "ErrorCode": "E_ENCODING_CONTEXT_MISMATCH",
    "description": "Mismatching query_context in encoded plan",
    "causes": [],
    "actions": []
  },
  {
    "code": 4092,
    "ErrorCode": "E_PREDEFINED_PREPARED_NAME",
    "description": "Prepared name [predefinedname] is predefined (reserved).",
    "causes": [
      " __get, __insert, __upsert, __update, __delete names are not allowed as this are used for cache warmup and not allowed to be used by the user."
    ],
    "actions": [
      "pick a different name other than  __get, __insert, __upsert, __update, __delete"
    ],
    "isUser": true
  },
  {
    "code": 4100,
    "ErrorCode": "E_NO_INDEX_JOIN",
    "description": "No index available for right hand side join term, in index join construct",
    "causes": [
      "INDEX JOIN , specifies usage of ON KEY [right-hand-side term's key] FOR [left-hand-side term] . This matches the index key(foriegn key) of right hand side term with left-hand-side terms document key(primary key). With this mentioned, this error is raised when there is not index available for right-hand-side term.  Example bad query:  cbq> SELECT * FROM `travel-sample`.inventory.airline JOIN `travel-sample`.inventory.route ON KEY route.airlineid FOR airline WHERE airline.icao = \"SWA\";\n{\n    \"requestID\": \"a50f012b-691c-4a66-8be3-02d0fa84f0eb\",\n    \"errors\": [\n        {\n            \"code\": 4100,\n            \"msg\": \"No index available for join term route\"\n        }\n    ],\n    \"status\": \"fatal\",\n    \"metrics\": {\n        \"elapsedTime\": \"794.458\u00b5s\",\n        \"executionTime\": \"726.583\u00b5s\",\n        \"resultCount\": 0,\n        \"resultSize\": 0,\n        \"serviceLoad\": 2,\n        \"errorCount\": 1\n    }\n}\nPoint to note: Sequential Scan feature is not enabled."
    ],
    "actions": [
      "CREATE suitable index for right-hand-side term when using IndexJoin construct. Index Avisor link https://docs.couchbase.com/server/current/guides/index-advisor.html#advice-single for your reference. To correct our bad example we can create index like so, CREATE INDEX route_airlineid ON route(airlineid);"
    ],
    "isUser": true
  },
  {
    "code": 4110,
    "ErrorCode": "E_USE_KEYS_USE_INDEXES",
    "description": "From Expression Term cannot have USE KEYS or USE INDEX Clause",
    "causes": [
      "As the error message suggests it doesn't make sense for USE KEYS/USE INDEX so we error out during formalization. Example bad queries: SELECT a.id FROM {\"id\":1} a USE KEYS [\"a_1\"];  SELECT a.id FROM {\"id\":1} a USE INDEX(def_idx USING GSI);"
    ],
    "actions": [
      "Usage of from expression may have been for testing purpose on your part, replace with actual keyspaceterm(collection). Or use cbimport to transfer the expression's documents to a bucket(USE KEYS) and create suitable index(for USE INDEX)"
    ]
  },
  {
    "code": 4120,
    "ErrorCode": "E_NO_PRIMARY_INDEX",
    "description": "No index available on keyspace, use CREATE PRIMARY INDEX on [keyspace]",
    "causes": [
      "When running SELECT/UPDATE/DELETE queries, during planning we first build the scan operator, except when using USE KEYS CLAUSE for UPDATE/DELETE statements. For which we look at the keyspace term and predicates(if any) to pick the most suitable index. At worst case we resort to primary index if no secondary index is present. But in your case you neither have a secondary index nor a primary index on your keyspace to build the scan operator for the query. Example bad query (no gsi index on airline collection) : SELECT * FROM `travel-sample`.inventory.airline;\n{\n    \"requestID\": \"99bec664-b1c6-4818-a5e7-f6b61c2e491e\",\n    \"errors\": [\n        {\n            \"code\": 4000,\n            \"msg\": \"No index available on keyspace `default`:`travel-sample`.`inventory`.`airline` that matches your query. Use CREATE PRIMARY INDEX ON `default`:`travel-sample`.`inventory`.`airline` to create a primary index, or check that your expected index is online.\"\n        }\n    ],\n    \"status\": \"fatal\",\n    \"metrics\": {\n        \"elapsedTime\": \"829\u00b5s\",\n        \"executionTime\": \"690.5\u00b5s\",\n        \"resultCount\": 0,\n        \"resultSize\": 0,\n        \"serviceLoad\": 2,\n        \"errorCount\": 1\n    }\n} , Note: in production using PRIMARY INDEX is not advisable but while developing/figuring out your query for your problem it is ok to use. Also this error wouldn't be raised if sequential scan feature is on."
    ],
    "actions": [
      "to mitigate the error, simply create the primary index: CREATE PRIMARY INDEX ON [keyspace]; "
    ]
  },
  {
    "code": 4125,
    "ErrorCode": "E_PRIMARY_INDEX_OFFLINE",
    "description": "Primary index [indexname] not online.",
    "causes": [
      "1) When running SELECT/UPDATE/DELETE queries, during planning we first build the scan operator, except when using USE KEYS CLAUSE for UPDATE/DELETE statements. For which we look at the keyspace term and predicates(if any) to pick the most suitable index. At worst case we resort to primary index if no secondary index is present. But in your case you have a primary index which hasn't been built yet. In other words the index is offline. \n\nExample : \n1) CREATE PRIMARY INDEX idx_landmark_primary\n  ON landmark\n  USING GSI\n  WITH {\"defer_build\":true};",
      "2) SELECT * FROM landmark LIMIT 1;\n{\n    \"requestID\": \"dfd6ba86-1c16-48b9-9a87-529d160e2d35\",\n    \"errors\": [\n        {\n            \"code\" :4000,        \n           \"msg\":\"Primary index idx_landmark_primary not online.\"        \n           \"query\":\"SELECT * FROM landmark LIMIT 1;\"\n        }\n    ],"
    ],
    "actions": [
      "Solution: Build the index-> BUILD INDEX ON landmark(idx_landmark_primary) USING GSI;"
    ],
    "isUser": true
  },
  {
    "code": 4130,
    "ErrorCode": "E_LIST_SUBQUERIES",
    "description": "Error listing subqueries. NEVER RAISED as the expression subquery lister logic never returns error while traversing any of the expression types",
    "causes": [
      "code paths involved:-> subquery Privileges & building subquery"
    ],
    "actions": []
  },
  {
    "code": 4210,
    "ErrorCode": "E_NOT_GROUP_KEY_OR_AGG",
    "description": "Expression in Projection Clause must depend only on group keys or aggregates.",
    "causes": [
      "The projection term is not an equivalent to any of the group keys , i.e MAX(country) is an equivalent of `country` but `city` is not an equivalent of `country`. Example bad query: \nSELECT country, name FROM landmark GROUP BY country;\n{\n    \"requestID\": \"8a043403-a0ce-4e66-8515-c529f0717d62\",\n    \"errors\": [\n        {\n            \"code\": 4210,\n            \"column\": 17,\n            \"line\": 1,\n            \"msg\": \"Expression (`landmark`.`name`) (near line 1, column 17) must depend only on group keys or aggregates.\"\n        }\n    ],"
    ],
    "actions": [
      "Reframe your query to use only projection that are \"equivalentTo\" a group key, Or modify query to use GROUP AS clause to make all other fields available, but doing so will lose the index pushdown benefit you might have got earlier."
    ],
    "isUser": true
  },
  {
    "code": 4300,
    "ErrorCode": "E_INDEX_ALREADY_EXISTS",
    "description": "The index already exists. ",
    "causes": [
      "Index with same name already exists. That is when we raise this error. Example bad query: (same index already created) CREATE PRIMARY INDEX idx_landmark_primary ON landmark;"
    ],
    "actions": [
      "A way to avoid the error, is to add the IF NOT EXISTS Clause, this doesn't make the request to create index fatal. example: CREATE PRIMARY INDEX IF NOT EXISTS idx_landmark_primary ON landmark;"
    ],
    "isUser": true
  },
  {
    "code": 4310,
    "ErrorCode": "E_AMBIGUOUS_META",
    "description": "meta() / search_meta() / search_score() in query with multiple FROM terms requires an argument",
    "causes": [
      "functions meta() / search_meta() / search_score require argument of keyspace alias when query involves more than 1 keyspace term, as during formalization of the function expression, is ambiguous as we are not sure which keyspace do we want to evaluate the function on. Example bad query: SELECT meta() FROM landmark, route r WHERE r.sourceairport = \"TLV\" LIMIT 100;"
    ],
    "actions": [
      "change the call to accept the keyspace alias as an argument, so for the example bad query to get metadata for route keyspace -> SELECT meta(r) FROM landmark, route r WHERE r.sourceairport = \"TLV\" LIMIT 100;"
    ],
    "isUser": true
  },
  {
    "code": 4320,
    "ErrorCode": "E_INDEXER_DESC_COLLATION",
    "description": "DESC option is not supported by the indexer.",
    "causes": [
      "Currently only gsi's indexAPI 1 doesn't support DESC option on index keys"
    ],
    "actions": [
      "upgrade to higher version of indexing service that supports DESC options on index keys"
    ]
  },
  {
    "code": 4321,
    "ErrorCode": "E_PLAN_INTERNAL",
    "description": "error raised during planning when things are not going as planned by the builder( NEED TO GO THROUGH EVERY code path)",
    "causes": [],
    "actions": []
  },
  {
    "code": 4322,
    "ErrorCode": "E_ALTER_INDEX",
    "description": "ALTER INDEX not supported",
    "causes": [
      "ALTER INDEX statement is supported only from (gsi)indexer API3 onwards"
    ],
    "actions": [
      "upgrade to a higher version of indexing service "
    ]
  },
  {
    "code": 4323,
    "ErrorCode": "E_PLAN_NO_PLACEHOLDER",
    "description": "Unable to reproduce -> use named/pos param as keyspace term ",
    "causes": [],
    "actions": []
  },
  {
    "code": 4330,
    "ErrorCode": "E_NO_ANSI_JOIN",
    "description": "No index available for ANSI [JOIN/NEST] term [keyspace-alias]",
    "causes": [
      "ANSI JOIN/NEST require suitable secondary index for the keyspace terms involved. Unless join is 1) primaryJoin (Joining on primary key meta().id) , 2) nestedloop primary scan( only for keyspaces with less than 1000 documents) , 3) if hash join is being considered if ON CLAUSE or JOIN predicate is an equality predicate, 4) keyspace used is from system scope"
    ],
    "actions": [
      "CREATE a suitable index secondary index, link to index advisor https://docs.couchbase.com/server/current/guides/index-advisor.html#advice-single "
    ],
    "isUser": true
  },
  {
    "code": 4340,
    "ErrorCode": "E_PARTITION_INDEX_NOT_SUPPORTED",
    "description": "PARTITION index is not supported by indexer.",
    "causes": [
      "Index Partitioning https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/index-partitioning.html clause in CREATE INDEX statement ( PARTITION BY HASH ([exprs] ) )is supported from Indexer API3 onwards"
    ],
    "actions": [
      "upgrade to a higher version of indexing service "
    ]
  },
  {
    "code": 4400,
    "ErrorCode": "E_ENCODED_PLAN_NOT_ALLOWED",
    "description": "Encoded plan use is not allowed in serverless mode.",
    "causes": [],
    "actions": []
  },
  {
    "code": 4600,
    "ErrorCode": "E_CBO",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 4610,
    "ErrorCode": "E_INDEX_STAT",
    "description": "Invalid index statistics for index [index_name] : [state_name]",
    "causes": [
      "internal error in ready index stats from index storage api for cbo logic"
    ],
    "actions": [
      "contact support"
    ],
    "isUser": false
  },
  {
    "code": 5001,
    "ErrorCode": "E_EXECUTION_PANIC",
    "description": "golang panic in source",
    "causes": [
      "when there is a panic in runtime we recover and abort the request while logging the panic and also return the same as a response.\n2 points where we might panic-> within the execution of an operator or when servicing the request.\n\nReasons:\n1. nil pointer dereference\n2. index out of range\n3. closing a closed channel\n4. send on a closed channel, etc"
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 5002,
    "ErrorCode": "E_EXECUTION_INTERNAL",
    "description": "Execution internal error: ",
    "causes": [],
    "actions": []
  },
  {
    "code": 5003,
    "ErrorCode": "E_EXECUTION_PARAMETER",
    "description": "Execution parameter error: [reason]",
    "causes": [
      "1) cannot have USING Clause and named parameters when using EXECUTE statement.\n    for eg:\n    GET /query/service?statement=EXECUTE p1 USING {\"name\":\"me\"};&$name=1\n\n{\n\"requestID\": \"74cb2d68-55d9-416c-b049-0a6287cf59c0\",\n\"errors\": [{\"code\":5003,\"msg\":\"Execution parameter error: cannot have both USING clause and request parameters\"}],\n\"status\": \"fatal\",\n\"metrics\": {\"elapsedTime\": \"854.667\u00b5s\",\"executionTime\": \"800.5\u00b5s\",\"resultCount\": 0,\"resultSize\": 0,\"serviceLoad\": 2,\"errorCount\": 1}\n}",
      "2) EXECUTE <prepare_name> USING <expr>;\n  USING Clause is expected to be static, i.e either an array or an object. But not any other expression types\n for eg: a subquery expression is not static\n EXECUTE p1 USING {\"name\":(SELECT * FROM default)};\n{\n\"requestID\": \"8a1863d4-23c9-4a6c-b755-8fde09abe0cc\",\n\"errors\": [{\"code\":5003,\"msg\":\"Execution parameter error: USING clause does not evaluate to static values\"}],\n\"status\": \"fatal\",\n\"metrics\": {\"elapsedTime\": \"340.333\u00b5s\",\"executionTime\": \"310.5\u00b5s\",\"resultCount\": 0,\"resultSize\": 0,\"serviceLoad\": 2,\"errorCount\": 1}\n}"
    ],
    "actions": [
      "1) either USING or request paremeter as named_arguments , not both.",
      "2) USING Clause -> expression typically expects array construct (positional parameters: [1,2,3]) or object construct ( with fieldnames as namedparameter and field value as it's value, {\"name\":\"nobody\"})"
    ],
    "isUser": true
  },
  {
    "code": 5004,
    "ErrorCode": "E_PARSING",
    "description": "Expression parsing: [expression] failed",
    "causes": [
      "User has EXCLUDE clause in the projection.\n\nEXCLUDE clause passed uses string based referencing, but when trying to parse raw string(or comma split string term) we get an error as the string is not a valid expression."
    ],
    "actions": [
      "Please change the string passed to a valid expression.\n\nAs a way to debug use\nSELECT <expr> FROM <any-keyspace>; // if it errors here it will error in Exclude Clause too."
    ],
    "isUser": true
  },
  {
    "code": 5006,
    "ErrorCode": "E_EXECUTION_KEY_VALIDATION",
    "description": "Out of key validation space.",
    "causes": [
      "When upserting/inserting to ensure we aren't updating the same key more than once. There is a skip keys mechanism in place to ensure we avoid halloween problems, but if the available free system memory doesn't satisfy minimun requirement(134217728 bytes)  to track incoming keys for skip mechanism we error out with this error regardless of if the insert/upsert is Value based or Select based."
    ],
    "actions": [
      "simplest solution: reduce insert original insert into 2 statements.\n\nor: one could play around with the pipeline_batch https://docs.couchbase.com/server/current/settings/query-settings.html#pipeline_batch_req  & max_parallelism settings https://docs.couchbase.com/server/current/settings/query-settings.html#max_parallelism_req  so the operator can take advantage of that to reduce number of documents batched together."
    ],
    "isUser": false
  },
  {
    "code": 5007,
    "ErrorCode": "E_EXECUTION_CURL",
    "description": "Error executing CURL function",
    "causes": [
      "1) No host in request URL.\n[\n  {\n    \"code\": 5010,\n    \"msg\": \"Error evaluating projection\",\n    \"reason\": {\n      \"_level\": \"exception\",\n      \"caller\": \"func_curl:190\",\n      \"cause\": {\n        \"error\": \"No host in request URL.\"\n      },\n      \"code\": 5007,\n      \"key\": \"execution.curl\",\n      \"message\": \"Error executing CURL function\"\n    }\n  }\n]",
      "2) /diag/eval prefix path is restricted\n SELECT CURL(\"http://127.0.0.1:9000/diag/eval\", {\"user\":\"Administrator:password\"});\n{\n    \"requestID\": \"b78e9958-8b61-469c-94a9-b81435834198\",\n    \"signature\": {\n        \"$1\": \"object\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"func_curl:191\",\n                \"cause\": {\n                    \"error\": \"Access restricted - http://127.0.0.1:9000/diag/eval.\"\n                },\n                \"code\": 5007,\n                \"key\": \"execution.curl\",\n                \"message\": \"Error executing CURL function\"\n            }\n        }\n    ],",
      "3) options header-> expects string array.\nSELECT CURL(\"http://127.0.0.1:9000/pools\", {\"header\":[1,\"Authorization:Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\"]});\n\"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"func_curl:191\",\n                \"cause\": {\n                    \"error\": \"Incorrect type for header option 1 in CURL. Header option should be a string value or an array of strings.  \"\n                },\n                \"code\": 5007,\n                \"key\": \"execution.curl\",\n                \"message\": \"Error executing CURL function\"\n            }\n        }\n    ],",
      "4) expect get options value to be boolean\ncbq> SELECT CURL(\"http://127.0.0.1:9000/pools\", {\"get\":\"YES\"});\n{\n    \"requestID\": \"af3dc78e-3d52-4386-b0f5-bd8ac80457ff\",\n    \"signature\": {\n        \"$1\": \"object\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"func_curl:191\",\n                \"cause\": {\n                    \"error\": \"Incorrect type for get option in CURL \"\n                },\n                \"code\": 5007,\n                \"key\": \"execution.curl\",\n                \"message\": \"Error executing CURL function\"\n            }\n        }\n    ],",
      "5) Only GET and POST requests are supported, option request must be \"GET\" or \"POST\"\ncbq> SELECT CURL(\"http://127.0.0.1:9000/pools\", {\"request\":\"PUT\"});\n{\n    \"requestID\": \"e35e9486-7a58-4f2b-b7f0-d9c27fb0c1f1\",\n    \"signature\": {\n        \"$1\": \"object\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"func_curl:191\",\n                \"cause\": {\n                    \"error\": \"CURL only supports GET and POST requests. \"\n                },\n                \"code\": 5007,\n                \"key\": \"execution.curl\",\n                \"message\": \"Error executing CURL function\"\n            }\n        }\n    ]",
      "6) Timeout error\ncbq> SELECT CURL(\"https://httpbin.org/delay/10\", {\"max-time\":5});\n{\n    \"requestID\": \"86a41638-a017-466a-b752-65c11ed97486\",\n    \"signature\": {\n        \"$1\": \"object\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"func_curl:191\",\n                \"cause\": {\n                    \"error\": \"curl: Timeout was reached\"\n                },\n                \"code\": 5007,\n                \"key\": \"execution.curl\",\n                \"message\": \"Error executing CURL function\"\n            }\n        }\n    ]",
      "7) hostname is not in allowed URLs (or) is in the disallowed URLs\ncbq> SELECT CURL(\"http://127.0.0.1:9000/pools\");\n{\n    \"requestID\": \"9fc94bba-7385-443b-9fd6-18bf404e2dbf\",\n    \"signature\": {\n        \"$1\": \"object\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"func_curl:191\",\n                \"cause\": {\n                    \"error\": \"The end point http://127.0.0.1:9000/pools is not permitted.  List allowed end points in the configuration.\"\n                },\n                \"code\": 5007,\n                \"key\": \"execution.curl\",\n                \"message\": \"Error executing CURL function\"\n            }\n        }\n    ],"
    ],
    "actions": [
      "1) only allow http or https scheme",
      "2) expect hostname in the URL:\nExample: www.example.com\nThe host identifies the domain name or IP address of the server where the resource is located",
      "3) diag/eval is restricted as we don't want to allow users execute arbitarary code on the server.",
      "4) headers option: must be a string(\"[header]:[value\") or array of strings",
      "5) set max-time and connect-timeout to a value that avoids the timeout:)",
      "6) add URL in the allowed list https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/curl.html#curl-access-list"
    ],
    "isUser": true
  },
  {
    "code": 5008,
    "ErrorCode": "E_EXECUTION_STATEMENT_STOPPED",
    "description": "Execution of statement has been stopped.",
    "causes": [
      "When the outer query is stopped any query's started by the udf call in the outer query must also be stopped this error is raised.\n\nFor eg:\nudf library->\nfunction dummy(a,b) {\n  var q = SELECT * FROM `test`;\n  var res = [];\n  for(const doc of q) {\n      res.push(doc);\n  }\n  \n  return res;\n}\n\n\nfunction-def->\nCREATE FUNCTION dummy(lat, lon)\n  LANGUAGE JAVASCRIPT AS \"dummy\" AT \"dummy\";\n\nouter query:\nSELECT * FROM `travel-sample`.inventory.route r WHERE r.airport in dummy(1,2);,\n\ncancel the query via ui."
    ],
    "actions": [
      "Letting the outer query finish would result in this error never being raised."
    ],
    "isUser": true
  },
  {
    "code": 5010,
    "ErrorCode": "E_EVALUATION_ABORT",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 5011,
    "ErrorCode": "E_EVALUATION",
    "description": "",
    "causes": [
      "for"
    ],
    "actions": []
  },
  {
    "code": 5015,
    "ErrorCode": "E_EXPLAIN",
    "description": "EXPLAIN: Error marshaling JSON.",
    "causes": [
      "Error when in marshalling plan. MarshalJson() method for a particular operator might be the cause."
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 5017,
    "ErrorCode": "E_EXPLAIN_FUNCTION",
    "description": "EXPLAIN FUNCTION: [reason]",
    "causes": [
      "1) When running EXPLAIN FUNCTION <func_name>",
      "2) after getting query plans used in inline udfs / javascript udfs. There was an error when marshalling the plans.\n2) after getting statement strings from the evaluator , we error out during when we are building the plan for the statement strings received, this may be due to i) failing to parse to a valid algebra node ii) if we have a transaction started, i.e we are executing in the context of a transaction , error is raised for all statements not supported during a transaction. iii) incorrect semantics in the statement. iv) failed building plan from the algebra statement we got from parsing."
    ],
    "actions": [
      "Amend your usage by understanding from the causes where EXPLAIN FUNCTION can't be used."
    ],
    "isUser": true
  },
  {
    "code": 5020,
    "ErrorCode": "E_GROUP_UPDATE",
    "description": "Error updating initial GROUP value/ intermediate GROUP value/ final GROUP value",
    "causes": [
      "User has a query with GROUP BY Clause and aggregates ,\n\nWhile computing aggregates the execution logic is dividied into 3 operators, 1) GroupInit , 2) GroupIntermediate, 3) GroupFinal\neg: query: SELECT city, COUNT(name)\nFROM `grouptestsmall`\nGROUP BY city;\nGroupInit\n* Collect group keys (city)\n* seed default value for the aggregate ( for count()-> 0)\n* cumulate initial per item in the group for the aggregate ( for count(name) where city=\"A\" add 1 for every item that has city=\"A\" to the aggregate value)\n\nGroupIntermediate\n* Typically used to merge the partial results in a multinode setup\n\nGroupFinal\n* throw out final cumulated value per group. ({\"city\": \"A\", \"count\":100} , if 100 docs with city as \"A\")\n\nthe error is raised when\n1) incorrect seed ( default value for the aggregate)\n2) incorrect partial value ( Count() aggregate expects Number but got string)"
    ],
    "actions": [
      "Contact support, error in the logic of group aggregation updates. This is a bug!"
    ],
    "isUser": false
  },
  {
    "code": 5030,
    "ErrorCode": "E_INVALID_VALUE",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 5031,
    "ErrorCode": "E_INVALID_EXPRESSION",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 5032,
    "ErrorCode": "E_UNSUPPORTED_EXPRESSION",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 5035,
    "ErrorCode": "E_RANGE",
    "description": "Out of range evaluating [term]",
    "causes": [
      "1) Builtin functions that support range operations have their capacity ceiling as maxint32(2147483647).",
      "2) SELECT DATE_RANGE_STR(\"0001-01-01\", \"9999-12-31\", \"minute\");\n[\n  {\n    \"code\": 5010,\n    \"msg\": \"Error evaluating projection\",\n    \"reason\": {\n      \"_level\": \"exception\",\n      \"caller\": \"func_date:1213\",\n      \"code\": 5035,\n      \"key\": \"execution.range_error\",\n      \"message\": \"Out of range evaluating DATE_RANGE_STR().\"\n    }\n  }\n]",
      "3) SELECT ARRAY_REPEAT(\"a\",2147483648);\n[\n  {\n    \"code\": 5010,\n    \"msg\": \"Error evaluating projection\",\n    \"reason\": {\n      \"_level\": \"exception\",\n      \"caller\": \"func_array:1813\",\n      \"code\": 5035,\n      \"key\": \"execution.range_error\",\n      \"message\": \"Out of range evaluating ARRAY_REPEAT().\"\n    }\n  }\n]",
      "4) SELECT ARRAY_RANGE(0, 2147483648) AS gen_array_range;\n[\n  {\n    \"code\": 5010,\n    \"msg\": \"Error evaluating projection\",\n    \"reason\": {\n      \"_level\": \"exception\",\n      \"caller\": \"func_array:1634\",\n      \"code\": 5035,\n      \"key\": \"execution.range_error\",\n      \"message\": \"Out of range evaluating ARRAY_RANGE().\"\n    }\n  }\n]",
      "5) SELECT DATE_RANGE_MILLIS(1672531200, 5967734400, \"millisecond\"); // 2023-01-01 to 2159-02-10 milliseconds\n[\n  {\n    \"code\": 5010,\n    \"msg\": \"Error evaluating projection\",\n    \"reason\": {\n      \"_level\": \"exception\",\n      \"caller\": \"func_date:1405\",\n      \"code\": 5035,\n      \"key\": \"execution.range_error\",\n      \"message\": \"Out of range evaluating DATE_RANGE_MILLIS().\"\n    }\n  }\n]",
      "6) SELECT REPEAT(\"A\", 2147483648);\n[\n  {\n    \"code\": 5010,\n    \"msg\": \"Error evaluating projection\",\n    \"reason\": {\n      \"_level\": \"exception\",\n      \"caller\": \"func_str:482\",\n      \"code\": 5035,\n      \"key\": \"execution.range_error\",\n      \"message\": \"Out of range evaluating REPEAT().\"\n    }\n  }\n]"
    ],
    "actions": [
      "TRUE"
    ]
  },
  {
    "code": 5036,
    "ErrorCode": "W_DIVIDE_BY_ZERO",
    "description": "",
    "causes": [
      "1) division by zero leads to a warning and \"null\" as the result, where underlying finction are \"DIV\" or \"IDIV\" and the 2nd operand in 0.",
      "2) cbq> SELECT 1/0;\n{\n    \"requestID\": \"c746a7d9-1d4d-46d2-a4ae-a2bc64fc7ea1\",\n    \"signature\": {\n        \"$1\": \"number\"\n    },\n    \"results\": [\n    {\n        \"$1\": null\n    }\n    ],\n    \"warnings\": [\n        {\n            \"code\": 5036,\n            \"msg\": \"Division by 0.\"\n        }\n    ],",
      "3) cbq> SELECT DIV(1,0);\n{\n    \"requestID\": \"825dad4b-46c7-45c7-8407-fd686fef8a93\",\n    \"signature\": {\n        \"$1\": \"number\"\n    },\n    \"results\": [\n    {\n        \"$1\": null\n    }\n    ],\n    \"warnings\": [\n        {\n            \"code\": 5036,\n            \"msg\": \"Division by 0.\"\n        }\n    ],",
      "4) cbq> SELECT IDIV(1,0);\n{\n    \"requestID\": \"1cf852c0-838c-4cc1-9bc6-11a40679ec9d\",\n    \"signature\": {\n        \"$1\": \"number\"\n    },\n    \"results\": [\n    {\n        \"$1\": null\n    }\n    ],\n    \"warnings\": [\n        {\n            \"code\": 5036,\n            \"msg\": \"Division by 0.\"\n        }\n    ],"
    ],
    "actions": [
      "2nd operand can be anythong expect 0 , this way we avoid the warning."
    ],
    "isUser": true
  },
  {
    "code": 5040,
    "ErrorCode": "E_DUPLICATE_FINAL_GROUP",
    "description": "Duplicate Final Group.",
    "causes": [
      "Group by is done by 3 operators\n1. group initial\ncumulate aggregate per group key\n\n2. group intermediate\nmerge(from  partial cumulatives that have the same key)\n\n3. group final\nsend the final cumulative values to the next operator.\n\nBut here something went wrong in groupIntermediate \nas in the groupfinal operator we receive the same group key again, i.e they haven't been merged in the intermediate group operator"
    ],
    "actions": [
      "Contact support , this might be a bug!"
    ],
    "isUser": false
  },
  {
    "code": 5050,
    "ErrorCode": "E_INSERT_KEY",
    "description": "No INSERT key for [document]",
    "causes": [
      "User has run INSERT ... VALUES statement https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/insert.html#insert-values \n\nBut the annotated value sent to sendInsertoperator doesn't have a \"key\" attachment that is set in the ValueScan operator.\nThis means something has gone wrong when sending the annotated value(with the new \"key\" & \"value\" attachment) from valueScan operator over the operator's valueexchange queue."
    ],
    "actions": [
      "Contact support , this might be a bug, as code is present for fail-safe purpose!"
    ],
    "isUser": false
  },
  {
    "code": 5060,
    "ErrorCode": "E_INSERT_VALUE",
    "description": "No INSERT value for [document]",
    "causes": [
      "User has run INSERT ... SELECT statement https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/insert.html#insert-select \n\nBut the annotated value sent to sendInsertoperator doesn't have a \"value\" attachment that is set in the ValueScan operator.\nThis means something has gone wrong when sending the annotated value(with the new \"key\" & \"value\" attachment) from valueScan operator over the the operator's valueexchange queue."
    ],
    "actions": [
      "Contact support , this might be a bug, as code is present for fail-safe purpose!"
    ],
    "isUser": false
  },
  {
    "code": 5070,
    "ErrorCode": "E_INSERT_KEY_TYPE",
    "description": "Cannot INSERT non-string key [key-passed-value] of type [key-passed-type]",
    "causes": [
      "1) The key for a document must always be a string, this applies to\n1) INSERT ...VALUE statement https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/insert.html#insert-values :\n \nINSERT INTO `travel-sample`.inventory.airline ( KEY, VALUE ) VALUES ( 1, { \"id\": \"01\", \"type\": \"airline\"} ) RETURNING META().id as docid, *;\n\n{\n    \"requestID\": \"d5c66327-63a8-431e-a6d7-f49e0da46341\",\n    \"signature\": {\n        \"docid\": \"json\",\n        \"*\": \"*\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5070,\n            \"msg\": \"Cannot INSERT non-string key 1 of type value.intValue.\"\n        }\n    ]",
      "2) MERGE ... WHEN NOT MATCHED INSERT\ncbq> MERGE INTO `travel-sample`.inventory.airport AS target USING [ {\"iata\":\"DSA\", \"name\": \"Doncaster Sheffield Airport\"}, {\"iata\":\"VLY\", \"name\": \"Anglesey Airport / Maes Awyr M\u00f4n\"} ] AS source ON target.faa = source.iata WHEN NOT MATCHED THEN INSERT (KEY 1+to_number(UUID()), VALUE {\"faa\": source.iata, \"airportname\": source.name, \"type\": \"airport\", \"inserted\": true}, OPTIONS {\"expiration\": 7*24*60*60} );\n{\n    \"requestID\": \"f74adb33-bdec-401c-8bd5-bee2b6071cb2\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5070,\n            \"msg\": \"Cannot INSERT non-string key null of type *value.nullValue.\"\n        }\n    ],"
    ],
    "actions": [
      "Ensure the exression for KEY in INSERT ... VALUE is always producing a string( that is unique obviously )."
    ],
    "isUser": true
  },
  {
    "code": 5071,
    "ErrorCode": "E_INSERT_OPTIONS_TYPE",
    "description": "Cannot INSERT non-OBJECT options [options-object-input] of type [options-object-input-Type]",
    "causes": [
      "Both for INSERT .. VALUES https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/insert.html#values-clause \nand INSERT SELECT https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/insert.html#insert-select \n\nOptions passed is expected to be a object with \"expiration\" being the only recognized options field that takes document expiration time as a number (seconds)\n\nExample bad query:\n INSERT INTO `travel-sample`.inventory.airline (KEY, VALUE, OPTIONS) VALUES ( \"airline::ttl\", { \"callsign\": \"Temporary\", \"country\" : \"USA\", \"type\" : \"airline\" }, \"HEELE\");\n\n{\n    \"requestID\": \"925ce38b-1576-4d96-800e-227d6ed9e60f\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5071,\n            \"msg\": \"Cannot INSERT non-OBJECT options \\\"HEELE\\\" of type value.stringValue.\"\n        }\n    ]"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 5072,
    "ErrorCode": "E_UPSERT_KEY",
    "description": " No UPSERT key for [annotated value ]",
    "causes": [
      "User has run UPSERT ... VALUES statement https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/upsert.html#insert-values  \nBut the annotated value sent to sendUpsert operator doesn't have a \"key\" attachment that is set in the ValueScan operator. \nThis means something has gone wrong when sending the annotated value(with the new \"key\" & \"value\" attachment) from valueScan operator over the operator's valueexchange queue."
    ],
    "actions": [
      "Contact support, this is a bug as code here is for fail-safe purpose "
    ],
    "isUser": false
  },
  {
    "code": 5073,
    "ErrorCode": "E_UPSERT_KEY_ALREADY_MUTATED",
    "description": "Cannot act on the same key multiple times in an UPSERT statement",
    "causes": [
      "we track keys to not mutate the same keys more than once under skip key mechanism.\n\nexample bad query:\nUPSERT INTO landmark (KEY, VALUE)\nVALUES (\"upsert-1\", { \"name\": \"The Minster Inn\", \"type\": \"landmark-pub\"}),\n(\"upsert-1\", {\"name\": \"The Black Swan\", \"type\": \"landmark-pub\"})\nRETURNING VALUE name;\n[\n  {\n    \"code\": 5073,\n    \"msg\": \"Cannot act on the same key multiple times in an UPSERT statement.\",\n    \"reason\": {\n      \"key\": \"upsert-1\",\n      \"keyspace\": \"default:travel-sample.inventory.landmark\"\n    }\n  }\n]"
    ],
    "actions": [
      "Ensure upsert pairs have key as a unique string"
    ],
    "isUser": true
  },
  {
    "code": 5075,
    "ErrorCode": "E_UPSERT_VALUE",
    "description": "No UPSERT value for [annotated value]",
    "causes": [
      "User has run UPSERT ... SELECT statement https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/upsert.html#insert-select \nBut the annotated value sent to sendUpsert operator doesn't have a \"key\" attachment that is set in the ValueScan operator. \nThis means something has gone wrong when sending the annotated value(with the new \"key\" & \"value\" attachment) from valueScan operator over the operator's valueexchange queue."
    ],
    "actions": [
      "Contact support, this is a bug as code here is for fail-safe purpose "
    ],
    "isUser": false
  },
  {
    "code": 5078,
    "ErrorCode": "E_UPSERT_KEY_TYPE",
    "description": "Cannot UPSERT non-string key [key-value-passed] of type [key-passed-type].",
    "causes": [
      "Both for UPSERT .. VALUES https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/upsert.html#insert-values \nand UPSERT SELECT https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/upsert.html#insert-select  \n\nOptions passed is expected to be a object with \"expiration\" being the only recognized options field that takes document expiration time as a number (seconds)\n\nExample bad query:\n INSERT INTO `travel-sample`.inventory.airline (KEY, VALUE, OPTIONS) VALUES ( \"airline::ttl\", { \"callsign\": \"Temporary\", \"country\" : \"USA\", \"type\" : \"airline\" }, \"HEELE\");\n\n{\n    \"requestID\": \"925ce38b-1576-4d96-800e-227d6ed9e60f\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5071,\n            \"msg\": \"Cannot INSERT non-OBJECT options \\\"HEELE\\\" of type value.stringValue.\"\n        }\n    ]"
    ],
    "actions": [
      "As couchbase only supports document-keys of string type, always use KEY expression in upsert statement to produce a string string value( which is unique).\nfor eg: builtin uuid() function."
    ],
    "isUser": true
  },
  {
    "code": 5079,
    "ErrorCode": "E_UPSERT_OPTIONS_TYPE",
    "description": "UNUSED never raised",
    "causes": [],
    "actions": []
  },
  {
    "code": 5080,
    "ErrorCode": "E_DELETE_ALIAS_MISSING",
    "description": "DELETE alias [keyspace-alias] not found in item [annotated value]",
    "causes": [
      "fail-safe code , error should ideally never occur\n\nThis is to catch the case where the previous operator( Scan op) has not setfield for the item being passed with the keyspace_ref's alias."
    ],
    "actions": [
      "Contact Support! this is a bug"
    ],
    "isUser": false
  },
  {
    "code": 5090,
    "ErrorCode": "E_DELETE_ALIAS_METADATA",
    "description": "DELETE alias [keyspace-alias] has no metadata in item.",
    "causes": [
      "fail-safe code , error should ideally never occur\n\nThis is to catch the case where the previous operator( Scan op), has passed an item whose value for the fieldname as keyspace-alias has no metadata, i.e not an annotated value(couchbase document abstraction for the query service)."
    ],
    "actions": [
      "Contact Support! this is a bug"
    ],
    "isUser": false
  },
  {
    "code": 5100,
    "ErrorCode": "E_UPDATE_ALIAS_MISSING",
    "description": "UPDATE alias [keyspace-alias] not found in item",
    "causes": [
      "fail-safe code,  error should ideally never occur\n\nThis is to catch the case where the previous operator( Scan op/ keyscan) has not setfield for the item being passed with the keyspace_ref's alias."
    ],
    "actions": [
      "Contact Support! this is a bug"
    ],
    "isUser": false
  },
  {
    "code": 5110,
    "ErrorCode": "E_UPDATE_ALIAS_METADATA",
    "description": "UPDATE alias [keyspace-alias] has no metadata in item.",
    "causes": [
      "fail-safe code , error should ideally never occur\n\nThis is to catch the case where the previous operator( Scan op), has passed an item whose value for the fieldname as keyspace-alias has no metadata, i.e not an annotated value(couchbase document abstraction for the query service)."
    ],
    "actions": [
      "Contact Support! this is a bug"
    ],
    "isUser": false
  },
  {
    "code": 5120,
    "ErrorCode": "E_UPDATE_MISSING_CLONE",
    "description": "Missing UPDATE clone.",
    "causes": [
      "fail-safe code, error should ideally never occur\n\nThis is to catch the case where the clone operator has not set the \"clone\" attachment in the item so set operator can modify the clone-annotated value."
    ],
    "actions": [
      "Contact Support! this is a bug"
    ],
    "isUser": false
  },
  {
    "code": 5180,
    "ErrorCode": "E_UNNEST_INVALID_POSITION",
    "description": "Invalid UNNEST position of type [pos_type]",
    "causes": [
      "fail-safe code, error should ideally never occur\n\nUser has used UNNEST_POS function https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/metafun.html#unnest-pos  ,\nfor eg: SELECT UNNEST_POS(u) AS upos, u FROM [{\"a1\":[10,9,4]}] AS d UNNEST d.a1 AS u; \n\nThis is to catch invalid 'unnest_position' attachment in the item set by unnest operator. Expected to be of integer type."
    ],
    "actions": [
      "Contact Support! this is a bug\n"
    ],
    "isUser": false
  },
  {
    "code": 5190,
    "ErrorCode": "E_SCAN_VECTOR_TOO_MANY_SCANNED_BUCKETS",
    "description": "The scan_vector parameter should not be used for queries accessing more than one keyspace.  Use scan_vectors instead. Keyspaces: [buckets...]",
    "causes": [
      "The client has specified scan_vector as a part of the request parameter https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html \nbut query has more than one keyspace, hence we error out.\n\nexample bad request:\nGET query/service?statement=SELECT default.*, grouptestsmall.* FROM default, grouptestsmall ;&scan_vector=[[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],[0, \"abc\"],.....]\n\n{\n\"requestID\": \"5bbcee19-ce52-422c-bfbf-f6bd8327e95f\",\n\"errors\":[\n{\n\"code\": 5190,\n\"msg\": \"The scan_vector parameter should not be used for queries accessing more than one keyspace. Use scan_vectors instead. Keyspaces: [  default:default default:grouptestsmall]\"\n},\n{\n\"code\": 5001,\n\"msg\": \"Panic: runtime error: invalid memory address or nil pointer dereference\"\n}\n],"
    ],
    "actions": [
      "scan_vectors map must be supplied by client when quering on more than one keyspace, doc reference https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html#test "
    ],
    "isUser": true
  },
  {
    "code": 5201,
    "ErrorCode": "E_DYNAMIC_AUTH",
    "description": "Dynamic auth error",
    "causes": [
      "Particular case when the FROM Clause has positional/named parameter with USE KEYS clause\n\nBut there was an error in doing a privilege check on the expression passed as a named/positional parameter\n\nFor eg: \nhttp://127.0.0.1:9499/query/service?statement=SELECT d.a FROM $a d USE KEYS [\"key::002a1616-aca9-4c2f-ad87-277d5845bb5a\"]&$p=\"default\"\n{\n\"requestID\": \"3eee8a00-f1b1-488e-a119-a4d0b8853b0a\",\n\"signature\": {\"a\":\"json\"},\n\"results\": [\n],\n\"errors\": [{\"code\":5201,\"msg\":\"Dynamic auth error\",\"reason\":{}}],\n\"status\": \"fatal\",\n\"metrics\": {\"elapsedTime\": \"23.718125ms\",\"executionTime\": \"2.075125ms\",\"resultCount\": 0,\"resultSize\": 0,\"serviceLoad\": 2,\"errorCount\": 1}\n}\n\nPossible causes:\n1) positional / named parameter is not defined as part of the request parameter."
    ],
    "actions": [
      "1) make sure the from clause used defined positional/named parameter"
    ],
    "isUser": true
  },
  {
    "code": 5202,
    "ErrorCode": "E_TRANSACTIONAL_AUTH",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 5210,
    "ErrorCode": "E_USER_NOT_FOUND",
    "description": "Unable to find user",
    "causes": [
      "Internally the execution of GRANT ROLE, gets current users information from /settings/rbac/users endpoint https://docs.couchbase.com/server/current/manage/manage-security/manage-users-and-roles.html#get-user-information-with-the-rest-api \nbut the user received from query doesn't match any user in the usersinformation given by the datastore.\n\nFor eg:\nGET /settings/rbac/users  \n[\n    {\n        \"id\": \"jan\",\n        \"domain\": \"local\",\n        \"roles\": [\n        ],\n        \"groups\": [\n        ],\n        \"external_groups\": [\n        ],\n        \"name\": \"\",\n        \"uuid\": \"f3f8e9ac-94be-4a0c-aa7c-02fac6c51721\",\n        \"password_change_date\": \"2023-11-22T15:13:03.000Z\"\n    }\n]\n\nOnly user is Jan\n\nBut we ran query-> GRANT Replication Admin, Query External Access TO cchaplan, jgleason;\n[\n  {\n    \"code\": 5210,\n    \"msg\": \"Unable to find user local:cchaplan.\",\n    \"reason\": {\n      \"user\": \"local:cchaplan\"\n    }\n  },\n  {\n    \"code\": 5210,\n    \"msg\": \"Unable to find user local:jgleason.\",\n    \"reason\": {\n      \"user\": \"local:jgleason\"\n    }\n  }\n]\n\n\nThe same applies to REVOKE ROLE statement as well."
    ],
    "actions": [
      "Use https://docs.couchbase.com/server/current/manage/manage-security/manage-users-and-roles.html#get-user-information-with-the-rest-api \nto check the list of users present."
    ],
    "isUser": true
  },
  {
    "code": 5220,
    "ErrorCode": "E_ROLE_REQUIRES_KEYSPACE",
    "description": "Role [role-requested] requires a keyspace. ",
    "causes": [
      "Role passed as a part of GRANT/REVOKE ROLE statement, is not an unparameterized role, but a parameterized requires keyspace as these roles are defined on a keyspace\n\nexample bad query:\nGRANT query_select TO jan;\n[\n  {\n    \"code\": 5220,\n    \"msg\": \"Role query_select requires a keyspace.\",\n    \"reason\": {\n      \"role\": \"query_select\"\n    }\n  }\n]"
    ],
    "actions": [
      "following list of roles require parameterized usage as shown in the docs https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/grant.html#usage \n\n[\n    {\n        \"role\": \"bucket_admin\",\n        \"bucket_name\": \"*\",\n        \"name\": \"Bucket Admin\",\n        \"desc\": \"Can manage ALL bucket features for a given bucket (including start/stop XDCR). This user can access the web console. This user cannot read data.\"\n    },\n    {\n        \"role\": \"scope_admin\",\n        \"bucket_name\": \"*\",\n        \"scope_name\": \"*\",\n        \"name\": \"Manage Scopes\",\n        \"desc\": \"Can create/delete scopes and collections within a given bucket. This user cannot access the web console.\"\n    },\n    {\n        \"role\": \"bucket_full_access\",\n        \"bucket_name\": \"*\",\n        \"name\": \"Application Access\",\n        \"desc\": \"Full access to bucket data. This user cannot access the web console and is intended only for application access. This user can read and write data except for the _system scope which can only be read.\"\n    },\n    {\n        \"role\": \"views_admin\",\n        \"bucket_name\": \"*\",\n        \"name\": \"Views Admin\",\n        \"desc\": \"Can create and manage views of a given bucket. This user can access the web console. This user can read some data.\"\n    },\n    {\n        \"role\": \"views_reader\",\n        \"bucket_name\": \"*\",\n        \"name\": \"Views Reader\",\n        \"desc\": \"Can read data from the views of a given bucket. This user cannot access the web console and is intended only for application access. This user can read some data.\"\n    },\n    {\n        \"role\": \"data_reader\",\n        \"bucket_name\": \"*\",\n        \"scope_name\": \"*\",\n        \"collection_name\": \"*\",\n        \"name\": \"Data Reader\",\n        \"desc\": \"Can read data from a given bucket, scope or collection. This user cannot access the web console and is intended only for application access. This user can read data, but cannot write it.\"\n    },\n    {\n        \"role\": \"data_writer\",\n        \"bucket_name\": \"*\",\n        \"scope_name\": \"*\",\n        \"collection_name\": \"*\",\n        \"name\": \"Data Writer\",\n        \"desc\": \"Can write data to a given bucket, scope or collection. This user cannot access the web console and is intended only for application access. This user can write data, but cannot read it.\"\n    },\n    {\n        \"role\": \"data_dcp_reader\",\n        \"bucket_name\": \"*\",\n        \"scope_name\": \"*\",\n        \"collection_name\": \"*\",\n        \"name\": \"Data DCP Reader\",\n        \"desc\": \"Can initiate DCP streams for a given bucket, scope or collection. This user cannot access the web console and is intended only for application access. This user can read data.\"\n    },\n    {\n        \"role\": \"data_backup\",\n        \"bucket_name\": \"*\",\n        \"name\": \"Data Backup & Restore\",\n        \"desc\": \"Can backup and restore a given bucket's data. This user cannot access the web console and is intended only for application access. This user can read data.\"\n    },\n    {\n        \"role\": \"data_monitoring\",\n        \"bucket_name\": \"*\",\n        \"scope_name\": \"*\",\n        \"collection_name\": \"*\",\n        \"name\": \"Data Monitor\",\n        \"desc\": \"Can read statistics for a given bucket, scope or collection. This user cannot access the web console and is intended only for application access. This user cannot read data.\"\n    },\n    {\n        \"role\": \"fts_admin\",\n        \"bucket_name\": \"*\",\n        \"name\": \"Search Admin\",\n        \"desc\": \"Can administer all Full Text Search features. This user can access the web console. This user can read some data.\"\n    },\n    {\n        \"role\": \"fts_searcher\",\n        \"bucket_name\": \"*\",\n        \"scope_name\": \"*\",\n        \"collection_name\": \"*\",\n        \"name\": \"Search Reader\",\n        \"desc\": \"Can query Full Text Search indexes for a given bucket, scope or collection. This user can access the web console. This user can read some data.\"\n    }\n]"
    ],
    "isUser": true
  },
  {
    "code": 5230,
    "ErrorCode": "E_ROLE_TAKES_NO_KEYSPACE",
    "description": "Role [role-requested] does not take a keyspace.",
    "causes": [
      "GET /settings/rbac/roles, roles that don't have bucketname field are unparameterized roles.\n\nSo, we semantically disallow parameterization on such roles.\nExample bad query:\nGRANT query_execute_global_external_functions ON `default`._default._default TO jan;\n[\n  {\n    \"code\": 5230,\n    \"msg\": \"Role query_execute_global_external_functions does not take a keyspace.\",\n    \"reason\": {\n      \"role\": \"query_execute_global_external_functions\"\n    },\n    \"query\": \"GRANT query_execute_global_external_functions ON `default`._default._default TO jan;\"\n  }\n]"
    ],
    "actions": [
      "roles that expect unparameterized usage\n[\n    {\n        \"role\": \"admin\",\n        \"name\": \"Full Admin\",\n        \"desc\": \"Can manage all cluster features (including security). This user can access the web console. This user can read and write all data.\"\n    },\n    {\n        \"role\": \"ro_admin\",\n        \"name\": \"Read-Only Admin\",\n        \"desc\": \"Can view all cluster statistics. This user can access the web console.\"\n    },\n    {\n        \"role\": \"security_admin_local\",\n        \"name\": \"Local User Security Admin\",\n        \"desc\": \"Can view all cluster statistics and manage local user roles, but not grant Full Admin or Security Admin roles to other users or alter their own role. This user can access the web console. This user cannot read data.\"\n    },\n    {\n        \"role\": \"security_admin_external\",\n        \"name\": \"External User Security Admin\",\n        \"desc\": \"Can view all cluster statistics and manage external user roles, but not grant Full Admin or Security Admin roles to other users or alter their own role. This user can access the web console. This user cannot read data.\"\n    },\n    {\n        \"role\": \"cluster_admin\",\n        \"name\": \"Cluster Admin\",\n        \"desc\": \"Can manage all cluster features except security. This user can access the web console. This user cannot read data.\"\n    },\n    {\n        \"role\": \"eventing_admin\",\n        \"name\": \"Eventing Full Admin\",\n        \"desc\": \"Can create/manage eventing functions. This user can access the web console\"\n    },\n    {\n        \"role\": \"backup_admin\",\n        \"name\": \"Backup Full Admin\",\n        \"desc\": \"Can perform backup related tasks. This user can access the web console\"\n    },\n    {\n        \"role\": \"scope_admin\",\n        \"name\": \"Manage Scopes\",\n        \"desc\": \"Can create/delete scopes and collections within a given bucket. This user cannot access the web console.\"\n    },\n    {\n        \"role\": \"bucket_full_access\",\n        \"name\": \"Application Access\",\n        \"desc\": \"Full access to bucket data. This user cannot access the web console and is intended only for application access. This user can read and write data except for the _system scope which can only be read.\"\n    },\n    {\n        \"role\": \"views_admin\",\n        \"name\": \"Views Admin\",\n        \"desc\": \"Can create and manage views of a given bucket. This user can access the web console. This user can read some data.\"\n    },\n    {\n        \"role\": \"views_reader\",\n        \"name\": \"Views Reader\",\n        \"desc\": \"Can read data from the views of a given bucket. This user cannot access the web console and is intended only for application access. This user can read some data.\"\n    },\n    {\n        \"role\": \"replication_admin\",\n        \"name\": \"XDCR Admin\",\n        \"desc\": \"Can administer XDCR features to create cluster references and replication streams out of this cluster. This user can access the web console. This user can read some data.\"\n    },\n    {\n        \"role\": \"data_reader\",\n        \"name\": \"Data Reader\",\n        \"desc\": \"Can read data from a given bucket, scope or collection. This user cannot access the web console and is intended only for application access. This user can read data, but cannot write it.\"\n    },\n    {\n        \"role\": \"data_writer\",\n        \"name\": \"Data Writer\",\n        \"desc\": \"Can write data to a given bucket, scope or collection. This user cannot access the web console and is intended only for application access. This user can write data, but cannot read it.\"\n    },\n    {\n        \"role\": \"data_dcp_reader\",\n        \"name\": \"Data DCP Reader\",\n        \"desc\": \"Can initiate DCP streams for a given bucket, scope or collection. This user cannot access the web console and is intended only for application access. This user can read data.\"\n    },\n    {\n        \"role\": \"data_backup\",\n        \"name\": \"Data Backup & Restore\",\n        \"desc\": \"Can backup and restore a given bucket's data. This user cannot access the web console and is intended only for application access. This user can read data.\"\n    },\n    {\n        \"role\": \"data_monitoring\",\n        \"name\": \"Data Monitor\",\n        \"desc\": \"Can read statistics for a given bucket, scope or collection. This user cannot access the web console and is intended only for application access. This user cannot read data.\"\n    },\n    {\n        \"role\": \"fts_admin\",\n        \"name\": \"Search Admin\",\n        \"desc\": \"Can administer all Full Text Search features. This user can access the web console. This user can read some data.\"\n    },\n    {\n        \"role\": \"fts_searcher\",\n        \"name\": \"Search Reader\",\n        \"desc\": \"Can query Full Text Search indexes for a given bucket, scope or collection. This user can access the web console. This user can read some data.\"\n    },\n    {\n        \"role\": \"query_select\",\n        \"name\": \"Query Select\",\n        \"desc\": \"Can execute a SELECT statement on a given bucket, scope or collection to retrieve data. This user can access the web console and can read data, but not write it.\"\n    },\n    {\n        \"role\": \"query_update\",\n        \"name\": \"Query Update\",\n        \"desc\": \"Can execute an UPDATE statement on a given bucket, scope or collection to update data. This user can access the web console and write data, but cannot read it.\"\n    },\n    {\n        \"role\": \"query_insert\",\n        \"name\": \"Query Insert\",\n        \"desc\": \"Can execute an INSERT statement on a given bucket, scope or collection to add data. This user can access the web console and insert data, but cannot read it.\"\n    },\n    {\n        \"role\": \"query_delete\",\n        \"name\": \"Query Delete\",\n        \"desc\": \"Can execute a DELETE statement on a given bucket, scope or collection to delete data. This user can access the web console, but cannot read data. This user can delete data.\"\n    },\n    {\n        \"role\": \"query_manage_index\",\n        \"name\": \"Query Manage Index\",\n        \"desc\": \"Can manage indexes for a given bucket, scope or collection. This user can access the web console, can read statistics for a given bucket, scope or collection. This user cannot read data.\"\n    },\n    {\n        \"role\": \"query_system_catalog\",\n        \"name\": \"Query System Catalog\",\n        \"desc\": \"Can look up system catalog information via N1QL. This user can access the web console, but cannot read user data.\"\n    },\n    {\n        \"role\": \"query_external_access\",\n        \"name\": \"Query CURL Access\",\n        \"desc\": \"Can execute the CURL statement from within N1QL. This user can access the web console, but cannot read data (within Couchbase).\"\n    },\n    {\n        \"role\": \"query_manage_global_functions\",\n        \"name\": \"Manage Global Functions\",\n        \"desc\": \"Can manage global n1ql functions\"\n    }\n]"
    ],
    "isUser": true
  },
  {
    "code": 5240,
    "ErrorCode": "E_NO_SUCH_KEYSPACE",
    "description": "Keyspace [keyspace] is not valid. (in context of a parameterized role request)",
    "causes": [
      "The keyspace attached to the role is not present,\nwe don't have the bucket-> 'trial'. But we are trying to grant query_select on it.\n\nGRANT  query_select ON `trial` TO jan;\n[\n  {\n    \"code\": 5240,\n    \"msg\": \"Keyspace default:travel-sample.inventory.trial is not valid.\"\n  }\n]\n\nsame applies to REVOKE as well."
    ],
    "actions": [
      "GET /pools/default/bucket endpoint will tell you about valid buckets in you cluster."
    ],
    "isUser": true
  },
  {
    "code": 5241,
    "ErrorCode": "E_NO_SUCH_SCOPE",
    "description": "Scope [scope] is not valid. (in context of a parameterized role request)",
    "causes": [
      "scope_admin is the only role that requires scope parameterization.\n\nBut the scope path passed user doesn't exist. For example _myscope doesn't exist in the default bucket.\nGRANT scope_admin ON default:`default`._myscope TO jan;\n[\n  {\n    \"code\": 5241,\n    \"msg\": \"Scope default:default._myscope is not valid.\"\n  }\n]\n\nSame applies to REVOKE as well."
    ],
    "actions": [
      "GET http://127.0.0.1:9000/pools/default/buckets/{bucketname}/scopes will tell you all valid scopes in your bucket."
    ],
    "isUser": true
  },
  {
    "code": 5242,
    "ErrorCode": "E_NO_SUCH_BUCKET",
    "description": "Bucket [bucket] is not valid.",
    "causes": [
      "parameterized role request with keyspace having only 2 parts (namespace.bucket)\n1) has _default scope and _default collection, role request is for that keyspace\n2) but if no _default collection, role request for entire bucket\n\nand the bucket information can't be got from the datastore.\nTypically would not occur."
    ],
    "actions": []
  },
  {
    "code": 5250,
    "ErrorCode": "E_ROLE_NOT_FOUND",
    "description": "Role [role-requested] is not valid.",
    "causes": [
      "As a part of the logic for validating roles requested as a part of GRANT/REVOKE role statement. \nWe compare roles received with defined roles on the datastore https://docs.couchbase.com/server/current/rest-api/rbac.html#list-roles /settings/rbac/roles\nif requested role doesn't match any of the defined roles we error out with this error. \nfor eg: \nGRANT replication_supremo TO jan; \n[ { \n       \"code\": 5250, \n       \"msg\": \"Role replication_supremo is not valid.\", \n       \"query\": \"GRANT replication_supremo\\n TO jan;\" \n} ]"
    ],
    "actions": [
      "use roles defined at GET /settings/rbac/roles endpoint."
    ],
    "isUser": true
  },
  {
    "code": 5260,
    "ErrorCode": "W_ROLE_ALREADY_PRESENT",
    "description": "User %s already has role [role]([bucket])",
    "causes": [
      "GET settings/rbac/users\nalready lists the requested role for a particular user.\n\nFor eg:\nGET settings/rbac/users\n[\n    {\n        \"id\": \"jan\",\n        \"domain\": \"local\",\n        \"roles\": [\n            {\n                \"role\": \"scope_admin\",\n                \"bucket_name\": \"default\",\n                \"scope_name\": \"_default\",\n                \"origins\": [\n                    {\n                        \"type\": \"user\"\n                    }\n                ]\n            },\n            {\n                \"role\": \"replication_admin\",\n                \"origins\": [\n                    {\n                        \"type\": \"user\"\n                    }\n                ]\n            },\n            {\n                \"role\": \"query_external_access\",\n                \"origins\": [\n                    {\n                        \"type\": \"user\"\n                    }\n                ]\n            },\n            {\n                \"role\": \"query_execute_global_functions\",\n                \"origins\": [\n                    {\n                        \"type\": \"user\"\n                    }\n                ]\n            }\n        ],\n        \"groups\": [\n        ],\n        \"external_groups\": [\n        ],\n        \"name\": \"\",\n        \"uuid\": \"f3f8e9ac-94be-4a0c-aa7c-02fac6c51721\",\n        \"password_change_date\": \"2023-11-22T15:13:03.000Z\"\n    }\n]\n\nGRANT query_execute_global_functions TO jan;\ncode        msg\n5260        \"User local:jan already has role query_execute_global_functions.\"\n\nSimilar for REVOKE statement."
    ],
    "actions": [
      "You can check assigned roles for a user from ui-> https://docs.couchbase.com/server/current/manage/manage-security/manage-users-and-roles.html#manage-users-with-the-ui \n\nor Rest-api: GET settings/rbac/users"
    ],
    "isUser": true
  },
  {
    "code": 5280,
    "ErrorCode": "W_USER_WITH_NO_ROLES",
    "description": "User [user-name] has no roles. Connecting with this user may not be possible",
    "causes": [
      "REVOKE query has successfully matched roles requested to be revoked and those the user has. But after removing those roles this particular user has no roles hence we issue this warning\n\nfor eg: \nGET /settings/rbac/users\n{\n\"id\": \"tom\",\n\"domain\": \"local\",\n\"roles\":[\n{\n\"role\": \"query_execute_global_functions\",\n\"origins\":[{\"type\": \"user\" }]\n}\n],\n\"groups\":[],\n\"external_groups\":[],\n\"name\": \"tommy\",\n\"uuid\": \"add6b21e-87b7-4683-a9fd-b229097925b8\",\n\"password_change_date\": \"2023-12-01T14:25:02.000Z\"\n}\n\n> REVOKE query_execute_global_functions FROM tom;\n[\n  {\n    \"code\": 5280,\n    \"msg\": \"User local:tom has no roles. Connecting with this user may not be possible\"\n  }\n]"
    ],
    "actions": [
      "No actions to take here error just signals that REVOKE has left user roleless."
    ],
    "isUser": true
  },
  {
    "code": 5300,
    "ErrorCode": "E_HASH_TABLE_PUT",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 5310,
    "ErrorCode": "E_HASH_TABLE_GET",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 5320,
    "ErrorCode": "E_MERGE_MULTI_UPDATE",
    "description": "Multiple UPDATE/DELETE of the same document (document key [key-passed]) in a MERGE statement",
    "causes": [
      "fail-safe code, ideally would never occur\n\nWHEN MATCHED\nmerge-update , merge-delete actions must not see the same document again."
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 5330,
    "ErrorCode": "E_MERGE_MULTI_INSERT",
    "description": "Multiple INSERT of the same document (document key [key-passed]) in a MERGE statement",
    "causes": [
      "fail-safe code for LOOKUP merge insert as doesn't expect key expression for insert, look at example 7: https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/merge.html#examples \n\nfor ANSI_MERGE insert , ensure key expression generates unique key for the send-insert operator.\nbad example:\nMERGE INTO route\nUSING airport\nON route.sourceairport = airport.faa\nWHEN NOT MATCHED THEN \n    INSERT (KEY \"p1\", VALUE { \"faa\": airport.faa });\n\n[\n  {\n    \"code\": 5330,\n    \"msg\": \"Multiple INSERT of the same document (document key 'p1') in a MERGE statement\"\n  }\n]"
    ],
    "actions": [
      "Safe bet to avoid this is to have the KEY expression set as uuid() or something concatenated to uuid() to ensure unique key generation."
    ],
    "isUser": true
  },
  {
    "code": 5340,
    "ErrorCode": "E_WINDOW_EVALUATION",
    "description": "1) Error initial setup\n\n2) Error during evaluating duplicate oby value.\n\n3) Error evaluating Window partition value.\n\n4) Error evaluating Window function.",
    "causes": [
      "1) intial setup failed due to voilation in Window Frame Clause's Extents received:\n\nWindow frame extents that result in an explicit violation are:\n( ROWS | RANGE | GROUPS ) BETWEEN CURRENT ROW AND valexpr PRECEDING\n( ROWS | RANGE | GROUPS ) BETWEEN valexpr FOLLOWING AND valexpr PRECEDING\n( ROWS | RANGE | GROUPS ) BETWEEN valexpr FOLLOWING AND CURRENT ROW",
      "2) window terms orderby clause evaluation failed",
      "3) i) fail-safe code, attachment for partition by clause's filed is not set\n    ii) partition by clause's expression( maybe a field/path or any n1ql expression ) this expression's evaluation failed on an item.",
      "4) actual aggregate/window function evaluation on the item failed."
    ],
    "actions": [
      "Please ask on forums"
    ],
    "isUser": true
  },
  {
    "code": 5350,
    "ErrorCode": "E_ADVISE_INDEX",
    "description": "AdviseIndex: Error marshaling JSON.",
    "causes": [
      "During execution of Advice operator, something wen wrong in marshalling the planOperator(Advise)."
    ],
    "actions": [
      "Maybe a bug, contact support."
    ],
    "isUser": false
  },
  {
    "code": 5351,
    "ErrorCode": "E_ADVISE_INVALID_RESULTS",
    "description": "Invalid advise results",
    "causes": [
      "fail-safe code, to ensure task-entry has \"state\" field.\nRequired for processing the logic for purgeResults of a \"completed\"/\"cancelled\"/\"deleting\""
    ],
    "actions": [
      "Not a bug"
    ],
    "isUser": false
  },
  {
    "code": 5360,
    "ErrorCode": "E_UPDATE_STATISTICS",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 5370,
    "ErrorCode": "E_SUBQUERY_BUILD",
    "description": "Unable to run subquery",
    "causes": [
      "When trying to evaluate a subquery, we first check if we have the subqeryExecutionTree in saved, then we reopen it and start the execution for it.\nIf the execution tree is not found, we have to rebuild from the plan. If something goes wrong during the build we error out and wrap the causing error with this error."
    ],
    "actions": [
      "Contact support."
    ],
    "isUser": false
  },
  {
    "code": 5380,
    "ErrorCode": "E_INDEX_LEADING_KEY_MISSING_NOT_SUPPORTED",
    "description": "Indexing leading key MISSING values are not supported by indexer.",
    "causes": [
      "INCLUDE MISSING (lead-key-attribs https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/createindex.html#index-key-attrib ) is only supported for indexers that support index API 3, API 5."
    ],
    "actions": [
      "Upgrade index service to a version that supports https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/createindex.html#index-key-attrib "
    ],
    "isUser": true
  },
  {
    "code": 5390,
    "ErrorCode": "E_INDEX_NOT_IN_MEMORY",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 5400,
    "ErrorCode": "E_MISSING_SYSTEMCBO_STATS",
    "description": "UNUSED. N1QL_SYSTEM_BUCKET logic has been replaced.",
    "causes": [],
    "actions": []
  },
  {
    "code": 5410,
    "ErrorCode": "E_INVALID_INDEX_NAME",
    "description": "index name([index_name_received]) must be a string",
    "causes": [
      "1) index names passed for build index , index name https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/build-index.html#index-name must be a string\nBUILD INDEX ON default(3);\n[\n  {\n    \"code\": 5410,\n    \"msg\": \"index name(3) must be a string\"\n  }\n]",
      "2) update statistics, a) for single index expects index name to be a string https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/statistics-index.html \n                                b) for multiple indexes, expects all index names to be a string https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/statistics-indexes.html"
    ],
    "actions": [
      "1) use SELECT * FROM system:indexes WHERE state=\"deferred\"; to find out the indexes that are waiting for build to kick-off.",
      "2) SELECT * FROM system:indexes; to find out all existing indexes."
    ],
    "isUser": true
  },
  {
    "code": 5411,
    "ErrorCode": "E_INDEX_NOT_FOUND",
    "description": "index [index-name] is not found",
    "causes": [
      "1) index name doesn't exist in the indexer that we are trying to build for\nBUILD INDEX ON default(temp);\n[\n  {\n    \"code\": 5411,\n    \"msg\": \"index temp is not found - cause: Index Not Found - cause: GSI index temp not found.\"\n  }\n]",
      "2) update statistics, a) for single index, index name doesn't exist https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/statistics-index.html \n                                b) for multiple indexes, one of the index names don't exist https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/statistics-indexes.html"
    ],
    "actions": [
      "1) use SELECT * FROM system:indexes WHERE state=\"deferred\"; to find out the indexes that are waiting for build to kick-off.",
      "2) SELECT * FROM system:indexes; to find out all existing indexes."
    ],
    "isUser": true
  },
  {
    "code": 5415,
    "ErrorCode": "E_INDEX_UPD_STATS",
    "description": "Error with UPDATE STATISTICS for indexes ([index-names])",
    "causes": [
      "BUILD INDEX / CREATE INDEX / CREATE PRIMARY INDEX statements , schedule updatestats task for cbo\nThe logic for scheduling, 1) task-id generation failed, 2) actual task entry was created but couldn't get added to the schedule cache."
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 5416,
    "ErrorCode": "E_TIME_PARSE",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 5420,
    "ErrorCode": "E_JOIN_ON_PRIMARY_DOCS_EXCEEDED",
    "description": "Inner of nested-loop join ([keyspace]) cannot have more than 1000 documents without appropriate secondary index",
    "causes": [
      "Before joins needed secondary index to be defined on the right-hand side for perfomance reasons, now inorder to allow new developers to play with join queries that use NestedLoop Join(non-equality join predicates) without secondary index (using primary or sequential-scan), but we set a max limit of 1000docs on the right side of the join for this case.\n\n\nRight of join:\ncbq> SELECT COUNT(1) FROM defaul1;\n{\n    \"requestID\": \"88ce984c-bc1d-4eb1-870a-b666268659cf\",\n    \"signature\": {\n        \"$1\": \"number\"\n    },\n    \"results\": [\n    {\n        \"$1\": 1001\n    }\n    ], \n\n\nSELECT d1.a as a1, d2.a as a2 FROM default d1 JOIN defaul1 d2 ON d1.a>d2.a;\n...\n...\n...\n     \"a1\": 93,\n        \"a2\": 76\n    },\n    {\n        \"a1\": 93,\n        \"a2\": 61\n    },\n    {\n        \"a1\": 93,\n        \"a2\": 30\n    },\n    {\n        \"a1\": 93,\n        \"a2\": 39\n    }\n    ],\n    \"errors\": [\n        {\n            \"code\": 5420,\n            \"msg\": \"Inner of nested-loop join (d2) cannot have more than 1000 documents without appropriate secondary index\",\n            \"reason\": {\n                \"keyspace_alias\": \"d2\",\n                \"limit\": 1000\n            }\n        }\n    ],"
    ],
    "actions": [
      "CREATE INDEX for the right hand side-> for the example CREATE INDEX idx ON defaul1(a);"
    ],
    "isUser": true
  },
  {
    "code": 5500,
    "ErrorCode": "E_MEMORY_QUOTA_EXCEEDED",
    "description": "Request has exceeded memory quota.",
    "causes": [
      "Enforced at request level by setting memory_quota request parameter to a non-zero value https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html \n(This parameter enforces a ceiling on the memory used for the tracked documents required for processing a request. It does not take into account any other memory that might be used to process a request, such as the stack, the operators, or some intermediate values.)\n\nThe logic is that when an  item is processed by an operator in the execution tree we account for memory quota on the item's size, that is item's size is not greater than the memory quota.\nThe size over here for example if a number-> 8bytes , for a string-> 1byte per character.\n\nIn conclusion the item with new attachments and other information we pass in the execution phase has exceeded the set memory quota."
    ],
    "actions": [
      "Increase the request-level memory quota to allow the execution to continue"
    ],
    "isUser": true
  },
  {
    "code": 5501,
    "ErrorCode": "E_NIL_EVALUATE_PARAM",
    "description": "nil [param] parameter for evaluation",
    "causes": [
      "1) all aggregate functions https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/aggregatefun.html , windowfunctions https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/windowfun.html \n    fail-safe code to ensure annotedvalue with the aggregate computed by the group operators(initial , intermediate and final) has finally been passed to the actual expression call (either in PROJECTION/ LET / WHERE clause), so the expression can evaluate to the computed aggregate value by the group logic. This happens regardless of if we have GROUP BY clause in query or not, \ni.e \nEXPLAIN SELECT sourceairport,COUNTN(stops) FROM `travel-sample`.inventory.route GROUP BY sourceairport ;\n {\n          \"#operator\": \"Parallel\",\n          \"~child\": {\n            \"#operator\": \"Sequence\",\n            \"~children\": [\n              {\n                \"#operator\": \"InitialGroup\",\n                \"aggregates\": [\n                  \"countn((`route`.`stops`))\"\n                ],\n                \"flags\": 4,\n                \"group_keys\": [\n                  \"(`route`.`sourceairport`)\"\n                ],\n                \"optimizer_estimates\": {\n                  \"cardinality\": 1367.999967695319,\n                  \"cost\": 38744.559677066005,\n                  \"fr_cost\": 38744.559677066005,\n                  \"size\": 569\n                }\n              }\n            ]\n          }\n        },\n        {\n          \"#operator\": \"IntermediateGroup\",\n          \"aggregates\": [\n            \"countn((`route`.`stops`))\"\n          ],\n          \"flags\": 4,\n          \"group_keys\": [\n            \"(`route`.`sourceairport`)\"\n          ],\n          \"optimizer_estimates\": {\n            \"cardinality\": 1367.999967695319,\n            \"cost\": 38895.03967351249,\n            \"fr_cost\": 38895.03967351249,\n            \"size\": 569\n          }\n        },\n        {\n          \"#operator\": \"FinalGroup\",\n          \"aggregates\": [\n            \"countn((`route`.`stops`))\"\n          ],\n          \"flags\": 4,\n          \"group_keys\": [\n            \"(`route`.`sourceairport`)\"\n          ],\n          \"optimizer_estimates\": {\n            \"cardinality\": 1367.999967695319,\n            \"cost\": 38922.39967286639,\n            \"fr_cost\": 38922.39967286639,\n            \"size\": 569\n          }\n        },\n        {\n          \"#operator\": \"Parallel\",\n          \"~child\": {\n            \"#operator\": \"Sequence\",\n            \"~children\": [\n              {\n                \"#operator\": \"InitialProject\",\n                \"discard_original\": true,\n                \"optimizer_estimates\": {\n                  \"cardinality\": 1367.999967695319,\n                  \"cost\": 38987.66345166317,\n                  \"fr_cost\": 38922.44738030816,\n                  \"size\": 569\n                },\n                \"preserve_order\": true,\n                \"result_terms\": [\n                  {\n                    \"expr\": \"(`route`.`sourceairport`)\"\n                  },\n                  {\n                    \"expr\": \"countn((`route`.`stops`))\"\n                  }\n                ]\n              }\n            ]\n          }\n\nEXPLAIN SELECT COUNTN(stops) FROM `travel-sample`.inventory.route ;\n{\n          \"#operator\": \"Parallel\",\n          \"~child\": {\n            \"#operator\": \"Sequence\",\n            \"~children\": [\n              {\n                \"#operator\": \"InitialGroup\",\n                \"aggregates\": [\n                  \"countn((`route`.`stops`))\"\n                ],\n                \"flags\": 4,\n                \"group_keys\": [],\n                \"optimizer_estimates\": {\n                  \"cardinality\": 1,\n                  \"cost\": 33013.941771953156,\n                  \"fr_cost\": 33013.941771953156,\n                  \"size\": 569\n                }\n              }\n            ]\n          }\n        },\n        {\n          \"#operator\": \"IntermediateGroup\",\n          \"aggregates\": [\n            \"countn((`route`.`stops`))\"\n          ],\n          \"flags\": 4,\n          \"group_keys\": [],\n          \"optimizer_estimates\": {\n            \"cardinality\": 1,\n            \"cost\": 33013.95177195316,\n            \"fr_cost\": 33013.95177195316,\n            \"size\": 569\n          }\n        },\n        {\n          \"#operator\": \"FinalGroup\",\n          \"aggregates\": [\n            \"countn((`route`.`stops`))\"\n          ],\n          \"flags\": 4,\n          \"group_keys\": [],\n          \"optimizer_estimates\": {\n            \"cardinality\": 1,\n            \"cost\": 33013.96177195316,\n            \"fr_cost\": 33013.96177195316,\n            \"size\": 569\n          }\n        },\n        {\n          \"#operator\": \"Parallel\",\n          \"~child\": {\n            \"#operator\": \"Sequence\",\n            \"~children\": [\n              {\n                \"#operator\": \"InitialProject\",\n                \"discard_original\": true,\n                \"optimizer_estimates\": {\n                  \"cardinality\": 1,\n                  \"cost\": 33013.985625674046,\n                  \"fr_cost\": 33013.985625674046,\n                  \"size\": 569\n                },\n                \"preserve_order\": true,\n                \"result_terms\": [\n                  {\n                    \"expr\": \"countn((`route`.`stops`))\"\n                  }\n                ]\n              }\n            ]\n          }",
      "2) fail-safe code-> for covered-expression , after undergoing covering transformation(expression part of PROJECTION/ WHERE/ LET Clause) during planning, failsafe code to ensure the scan operator has added attachment for covers to be used in the evaluation of the covered expression.",
      "3) fail-safe-code-> for expressions that are a call to NowMillis, NowTZ, NowStr, NowUtc builtin-functions, rely on the request context to know the current time when request was issued.",
      "4) fail-safe-code-> for expressions that refer to positional/named parameter, rely on the request context to hold the parameters got in as a part of the request context.",
      "5) fail-safe-code-> for expressions that are a call to ds_version function, rely on request context, to get the information from the datastore.",
      "6) fail-safe-code-> for call to advisor() , to mark the context as advisor context to account to advisor sessions, etc.",
      "7) fail-safe-code-> for identifier expression, to ensure the item passed from scan operator has a field with same name as the identifier so we can evaluate the identifier to that value.",
      "8) ail-safe-code-> for expression that are a call to object_remove builtin function, expects the have a non-nil context to parse the string passed to identifier/fieldname expression that has to be deleted in the object passed."
    ],
    "actions": [
      "Contact support."
    ],
    "isUser": false
  },
  {
    "code": 5502,
    "ErrorCode": "E_BUCKET_ACTION",
    "description": "Unable to complete action after say N attempts",
    "causes": [
      "this is just a wrapper error for cases where DML statements fail, what is happening is that command/op is not completed due to hitting maxretries or a connection timeout"
    ],
    "actions": [
      "try again"
    ],
    "isUser": false
  },
  {
    "code": 5503,
    "ErrorCode": "W_MISSING_KEY",
    "description": "Key(s) in USE KEYS hint not found",
    "causes": [
      "When user has passed VALIDATE keyword as a part of USE KEYS/ ON KEY/ ON KEYS  clause\nservice returns the missing keys as a warning in the response to the request.\n\nPossible usage:\n1) Lookup Joins https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/join.html#lookup-join-clause , ON KEYS VALIDATE\n2) USE keys Clause https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/hints.html#use-keys-clause , USE KEYS VALIDATE\n3) Index Nest: https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/nest.html#section_rgr_rnx_1db , ON KEY VALIDATE\n4) Lookup Nest: https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/nest.html#nest , ON KEY VALIDATE\n5) Index Join: https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/join.html#index-join-clause  ,ON KEY VALIDATE\n5) Delete: delete hint: https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/delete.html#delete-hint  , USE KEYS VALIDATE"
    ],
    "actions": [
      "Not an error, just a warning so user can know which documents didn't get included as a part of their query."
    ],
    "isUser": false
  },
  {
    "code": 5600,
    "ErrorCode": "E_NODE_QUOTA_EXCEEDED",
    "description": "Query node has run out of memory",
    "causes": [
      "node-level memory quota: set by \"node-quota\" , and \"node-quota-val-percent\" setting"
    ],
    "actions": []
  },
  {
    "code": 5601,
    "ErrorCode": "E_TENANT_QUOTA_EXCEEDED",
    "description": "UNUSED.",
    "causes": [],
    "actions": []
  },
  {
    "code": 5700,
    "ErrorCode": "E_VALUE_RECONSTRUCT",
    "description": "Failed to reconstruct value",
    "causes": [
      "Spill to disk feature is enabled\n\nwhen no suitable index for ORDER BY/ GROUP BY pushdown\nfor memory-concerns we resort to spill to disk ( SpillingArray (for order by) / SpillingMap (for group by)).\n\nreading next value failed as bytes on the wire didn't match any of the spill_type(something like book-keeping), hence we error out."
    ],
    "actions": [
      "Contact support"
    ]
  },
  {
    "code": 5701,
    "ErrorCode": "E_VALUE_INVALID",
    "description": "Invalid reconstructed value",
    "causes": [
      "Spill to disk feature is enabled\n\nwhen no suitable index for ORDER BY/ GROUP BY pushdown\nfor memory-concerns we resort to spill to disk ( SpillingArray (for order by) / SpillingMap (for group by)).\n\nwhen reading spillvalues from spillfile , couldn't decode the spillvalue to a recognized annotated value to send to the next execution operator."
    ],
    "actions": [
      "Contact support"
    ]
  },
  {
    "code": 5702,
    "ErrorCode": "E_VALUE_SPILL_CREATE",
    "description": "Failed to create spill file",
    "causes": [
      "Spill to disk feature is enabled\n\nwhen no suitable index for ORDER BY/ GROUP BY pushdown\nfor memory-concerns we resort to spill to disk ( SpillingArray (for order by) / SpillingMap (for group by)).\n\nThis error is raised when the something goes wrong in call to create a tmp file to spill( stored in /ns_server/tmp ) in the documents appended soo far."
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 5703,
    "ErrorCode": "E_VALUE_SPILL_READ",
    "description": "Failed to read from spill file",
    "causes": [
      "Spill to disk feature is enabled\n\nwhen no suitable index for ORDER BY/ GROUP BY pushdown\nwith regards memory-concerns we resort to spill to disk ( SpillingArray (for order by) / SpillingMap (for group by)).\n\nThis error is raised post the spill and sort , when we read\ni) rewind each file: seek back to the start of each spillfile\nii) read next sortedvalue(SPILL_VALUE) from the spillheap(incase of OrderBy), internally reads a value from the current spillfile, but the format received from the wire doesn't match the values we recognise\niii) similarly read next unsortedvalue"
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 5704,
    "ErrorCode": "E_VALUE_SPILL_WRITE",
    "description": "Failed to write to spill file",
    "causes": [
      "Spill to disk feature is enabled\n\nwhen no suitable index for ORDER BY/ GROUP BY pushdown\nwith regards memory-concerns we resort to spill to disk ( SpillingArray (for order by) / SpillingMap (for group by)).\n\nThis error is raised when something goes wrong in io (write the encoded spillvalue( SPILL_TYPE+SPILL_VAL from actual value)) to the spill file."
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 5705,
    "ErrorCode": "E_VALUE_SPILL_SIZE",
    "description": "Failed to determine spill file size",
    "causes": [
      "Spill to disk feature is enabled\n\nwhen no suitable index for ORDER BY/ GROUP BY pushdown\nwith regards memory-concerns we resort to spill to disk ( SpillingArray (for order by) / SpillingMap (for group by)).\n\nPost the write to the spill file, we seek to the end to account for the file size. If something goes wrong here this error is raised."
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 5706,
    "ErrorCode": "E_VALUE_SPILL_SEEK",
    "description": "UNUSED.",
    "causes": [],
    "actions": []
  },
  {
    "code": 6001,
    "ErrorCode": "E_SCHEDULER",
    "description": "The scheduler encountered an error in generating uuid for the task entry",
    "causes": [
      "1) user has issued : CREATE INDEX / BUILD INDEX / CREATE PRIMARY INDEX , updatestats task is scheduled by the service for the index being created",
      "2) user has started an advisor session, with start action\n\nlogic to generate uuid has returned an error."
    ],
    "actions": [
      "ideally would never occur"
    ],
    "isUser": true
  },
  {
    "code": 6002,
    "ErrorCode": "E_DUPLICATE_TASK",
    "description": "Task already exists [task_id]",
    "causes": [
      "1) user has issued : CREATE INDEX / BUILD INDEX /CREATE PRIMARY INDEX, updatestats task is scheduled by the service for the index being created.",
      "2) user has started an advisor session, with start action\n\nlogic for adding a task entry to the scheduled task cache, fails as entry with same taskid is already present."
    ],
    "actions": [
      "ideally would never occur as we clean the scheduled task when a task entry's state is completed/cancelled. But if this happens can be signs of a new timing issue and we have a bug on our hands. Contact support."
    ],
    "isUser": true
  },
  {
    "code": 6003,
    "ErrorCode": "E_TASK_RUNNING",
    "description": "Task [id] is currently executing and cannot be deleted",
    "causes": [
      "user has just created \nfor eg:\nGET /admin/tasks_cache HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nHost: 127.0.0.1:9499\n\nHTTP/1.1 200 OK\nContent-Type: application/json\nDate: Fri, 24 Nov 2023 06:09:03 GMT\nContent-Length: 345\n[{\"class\":\"update_statistics\",\"delay\":\"1s\",\"description\":\"default:default._default._default(defidx2)\",\"id\":\"136eedf0-ac5b-5980-a0fb-08ffa35b3c34\",\"name\":\"2465ca51-5d7d-4ef3-9dfa-a37ed7807a0e\",\"queryContext\":\"\",\"startTime\":\"2023-11-24T11:38:30.026+05:30\",\"state\":\"running\",\"subClass\":\"create_index\",\"submitTime\":\"2023-11-24T11:38:29.026+05:30\"}]\n\nand tried to delete the task entry for update statistics using 1) DELETE /admin/tasks_cache/{id} , 2) DELETE * FROM system:tasks_cache;\nbut the task is under running state, hence this error is raised"
    ],
    "actions": [
      "GET /admin/tasks_cache/{id}\nand check if the state field is \"completed\", \n\nonly then can the user issue a DELETE /admin/task_cache/{id} or DELETE statment on system:task_cache keyspace"
    ]
  },
  {
    "code": 6004,
    "ErrorCode": "E_TASK_NOT_FOUND",
    "description": "the task [id] was not found - IMPOSSIBLE TO REPRODUCE",
    "causes": [],
    "actions": []
  },
  {
    "code": 7000,
    "ErrorCode": "E_INFER_INVALID_OPTION",
    "description": "Invalid WITH clause usage in INFER statement",
    "causes": [
      "WITH CLAUSE expects:-> options to be passed as an object."
    ],
    "actions": [
      " something like this https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/infer.html#examples   "
    ],
    "isUser": true
  },
  {
    "code": 7001,
    "ErrorCode": "E_INFER_OPTION_MUST_BE_NUMERIC",
    "description": "passed option expects numeric value",
    "causes": [
      "all infer options are expected to be Numeric, except flag which can be numeric/string/array"
    ],
    "actions": [
      "reframe your options from here https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/infer.html#infer-parameters "
    ],
    "isUser": true
  },
  {
    "code": 7002,
    "ErrorCode": "E_INFER_READING_NUMBER",
    "description": "particular invalid format for flags argument in INFER keyspace statement",
    "causes": [
      "This error is raised when user passes a string as input to flags to set appropriate bits in the flags option."
    ],
    "actions": [
      "user is expected to pass a string whose value is between \"1\" and \"4294967296\" which is later parsed to set the appropriate flag bits"
    ],
    "isUser": true
  },
  {
    "code": 7003,
    "ErrorCode": "E_INFER_NO_KEYSPACE_DOCUMENTS",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 7004,
    "ErrorCode": "E_INFER_CREATE_RETRIEVER",
    "description": "Error creating document retriever.",
    "causes": [
      "user has used INFER EXPRESSION query,  the process of setting up a DocumentRetriver to start describing the expression passed: 1. Context passed is not an expression context, 2. user has passed subquery expression but failed to get execution handle to allow describing the subquery results, 3. error evaluating expression passed by user."
    ],
    "actions": [
      "for case of 2. check if subquery passed evaluates by running the SELECT statement directly, 3. check expression passed evaluates directly using SELECT {expression}"
    ],
    "isUser": true
  },
  {
    "code": 7005,
    "ErrorCode": "E_INFER_NO_RANDOM_ENTRY",
    "description": "Keyspace does not support random document retrieval.",
    "causes": [
      "error is raised if no way to do randomScan, no sequential scan, no indexes -> only way to build the retriever is with random_entry. user has not passed \"no_random_entry\" flag, datastore for the keyspace fails to perform GET_RANDOM_KEY operation hence failing to get a random entry."
    ],
    "actions": [
      "the GetRandomDoc request may have failed due to timeout , or keyspace doesn't support PrimaryIndex3 (for eg: system:indexes and all other keyspaces under systems namespace)"
    ],
    "isUser": false
  },
  {
    "code": 7006,
    "ErrorCode": "E_INFER_NO_RANDOM_DOCS",
    "description": "SAME AS E_INFER_NO_RANDOM_ENTRY",
    "causes": [],
    "actions": [],
    "isUser": false
  },
  {
    "code": 7007,
    "ErrorCode": "E_INFER_MISSING_CONTEXT",
    "description": "Missing expression context.",
    "causes": [
      "INFER {expression}, expects expression context."
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 7008,
    "ErrorCode": "E_INFER_EXPRESSION_EVAL",
    "description": "Expression evaluation failed.",
    "causes": [
      "this is a wrapper error that signals that users expression couldn't be processed to start the Describe phase. 1. Subquery expression cannot be opened to get the execution handle, 2. expression cannot be evaluated"
    ],
    "actions": [
      "user needs to rethink the subquery or expression he is using, try running the expression directly as SELECT {expr} to debug where things are going wrong step-by-step."
    ],
    "isUser": true
  },
  {
    "code": 7009,
    "ErrorCode": "E_INFER_KEYSPACE_ERROR",
    "description": "Keyspace error.",
    "causes": [
      "While building the Document Retriever, we try to fetch the document Count. The gomemcached.STAT op fails and hence we error out from building the document retriever"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 7010,
    "ErrorCode": "E_INFER_NO_SUITABLE_PRIMARY_INDEX",
    "description": "No suitable primary index found.",
    "causes": [
      "error is raised if no way to get randomEntry, no way to do randomScan, no sequential scan -> only way to build the retriever is with primary index but it isn't built."
    ],
    "actions": [
      "CREATE PRIMARY INDEX ON {keyspace}"
    ],
    "isUser": true
  },
  {
    "code": 7011,
    "ErrorCode": "E_INFER_NO_SUITABLE_SECONDARY_INDEX",
    "description": "No suitable secondary index found.",
    "causes": [
      "error is raised when no randomEntry, no randomScan, no sequential scan, no primary indexes and user hasn't passed \"no_secondary_index\" flag. But no secondary index is available then this error is raised"
    ],
    "actions": [
      "CREATE INDEX ON {keyspace}([indexkeys])"
    ],
    "isUser": true
  },
  {
    "code": 7012,
    "ErrorCode": "W_INFER_TIMEOUT",
    "description": "Stopped after exceeding infer_timeout. Schema may be incomplete.",
    "causes": [
      "Stopped after exceeding infer_timeout set by user as a part of options.  Schema may be incomplete. NOTE: default is 60seconds(Context Deadline)"
    ],
    "actions": [
      "If describing your keyspace takes more time than default time. Retry the INFER statement with {\"infer_timeout\": [something greater than 60sec]}"
    ],
    "isUser": true
  },
  {
    "code": 7013,
    "ErrorCode": "W_INFER_SIZE_LIMIT",
    "description": "Stopped after exceeding max_schema_MB. Schema may be incomplete.",
    "causes": [
      "exceeded schema size of \"max_schema_MB\" option, hence finishing the inferencing at this point. NOTE: default is 10MB."
    ],
    "actions": [
      "If your keyspace takes more than 10MB, Retry the INFER statement with {\"max_schema_MB\":[something greater than 10]}"
    ],
    "isUser": true
  },
  {
    "code": 7014,
    "ErrorCode": "E_INFER_NO_DOCUMENTS",
    "description": "No documents found, unable to infer schema.",
    "causes": [
      "The keyspace you are trying to infer schema on has no documents"
    ],
    "actions": [
      "Insert documents using cbimport https://docs.couchbase.com/server/current/tools/cbimport.html or INSERT statement or SDK https://docs.couchbase.com/go-sdk/current/howtos/kv-operations.html "
    ],
    "isUser": true
  },
  {
    "code": 7015,
    "ErrorCode": "E_INFER_CONNECT",
    "description": "FOR INFERENCER TOOL NOT cbq-engine",
    "causes": [],
    "actions": []
  },
  {
    "code": 7016,
    "ErrorCode": "E_INFER_GET_POOL",
    "description": "FOR INFERENCER TOOL NOT cbq-engine",
    "causes": [],
    "actions": []
  },
  {
    "code": 7017,
    "ErrorCode": "E_INFER_GET_BUCKET",
    "description": "FOR INFERENCER TOOL NOT cbq-engine",
    "causes": [],
    "actions": []
  },
  {
    "code": 7019,
    "ErrorCode": "E_INFER_GET_RANDOM",
    "description": "Failed to get random document.",
    "causes": [
      "Infer Statement is using Random Entry retriver on the keyspace. This requires logic of performing getRandomDoc on datastore using GET_RANDOM_KEY op"
    ],
    "actions": [
      "Failed KV op, try again after sometime "
    ],
    "isUser": false
  },
  {
    "code": 7020,
    "ErrorCode": "E_INFER_NO_RANDOM_SCAN",
    "description": "Keyspace does not support random key scans",
    "causes": [
      "error is raised if no way to get randomEntry, no sequential scan, no indexes -> only way to build the retriever is with randomScan. user has not passed \"no_random_scan\" flag, something went wrong when doing sequentialScan( KV-Range Scan)"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 7021,
    "ErrorCode": "E_INFER_NO_SEQUENTIAL_SCAN",
    "description": "Sequential scan not available.",
    "causes": [
      "error is raised when no randomEntry, no randomScan, no primary indexes or secondary indexes. \"full_scan\" flag is on. But seqscan is disabled or not available for the keyspace being used"
    ],
    "actions": [
      "Turn of n1ql-feat-ctrl flag and turn on sequential scan https://docs.couchbase.com/server/current/settings/query-settings.html#n1ql-feat-ctrl , NOTE: not recommended in production"
    ],
    "isUser": true
  },
  {
    "code": 7022,
    "ErrorCode": "E_INFER_NO_RETRIEVERS",
    "description": "No document retrievers available.",
    "causes": [
      "Wrapper error for scenarios of E_INFER_NO_SEQUENTIAL_SCAN, E_INFER_NO_SUITABLE_PRIMARY_INDEX, E_INFER_NO_RANDOM_DOCS, E_INFER_NO_RANDOM_SCAN, E_INFER_NO_RANDOM_ENTRY"
    ],
    "actions": [
      "Actions follow the actions recomended for the listed errors being wrapped"
    ],
    "isUser": true
  },
  {
    "code": 7023,
    "ErrorCode": "E_INFER_OPTIONS",
    "description": "UNUSED-> for INFER keyspace/expression/tool all pass default options -> dead code https://github.com/couchbase/query/blob/master/inferencer/describe_keyspace.go#L48 ",
    "causes": [],
    "actions": []
  },
  {
    "code": 7024,
    "ErrorCode": "E_INFER_NEXT_DOCUMENT",
    "description": "NextDocument failed",
    "causes": [
      "User has run INFER {subquery expression}. But execution handle created on subquery for Describing purpose returns error on getNextDoc()."
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 7200,
    "ErrorCode": "E_MIGRATION",
    "description": "Error occurred during [UDF/CBO_Stat] migration",
    "causes": [
      "1) You have upgraded a node(with query-service) from 7.2 to 7.6, \nThis triggers Migration of UDF and CBOStats.",
      "2) UDF Migration\n7.2: scope functions are moved from MetaKV to system scope(_system) for the bucket.\nreason: to reduce the load on KV\n\nMigration is done by all query nodes, and synchronization is done document-level atomicity(i.e for UDF the function entry). \n\nCertain errors are raised as a part of the Migration logic( that is other than the logic needed to maintain consensus among the query nodes( retry logic, etc)\n1) error in parsing function name-> parts (namespace:bucket.scope.collection) to create a system_entry\n2) error out in writing the body to system storage\n3) error out when deleting the old metaKv entry\n4) error out when checking if migration is completed but entries still exist in metastorage.",
      "3) CBOStats migration \nCBOStats are moved from N1QL_SYSTEM_BUCKET to system storage."
    ],
    "actions": [
      "The easy way out is to just recreate your library and create the function refresh."
    ],
    "isUser": false
  },
  {
    "code": 7201,
    "ErrorCode": "E_MIGRATION_INTERNAL",
    "description": "Unexpected error occurred during [UDF/CBO] migration: Unexpected error the datastore is not available",
    "causes": [
      "During Migration retry while waiting only the system scope to be created, but something went wrong and we don't have an handle on the datastore"
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 10000,
    "ErrorCode": "E_DATASTORE_AUTHORIZATION",
    "description": "Unable to authorize user.",
    "causes": [
      "for all serverless, free-tier or on-prem, when user credentials don't match the required privileges on datastore this error is thrown"
    ],
    "actions": [
      "admin has to grant user required RBAC using security tab in web console or follow https://docs.couchbase.com/server/current/rest-api/rbac.html"
    ],
    "isUser": true
  },
  {
    "code": 10003,
    "ErrorCode": "E_FTS_MISSING_PORT_ERR",
    "description": "UNUSED.",
    "causes": [],
    "actions": []
  },
  {
    "code": 10004,
    "ErrorCode": "E_NODE_INFO_ACCESS_ERR",
    "description": "UNUSED.",
    "causes": [],
    "actions": []
  },
  {
    "code": 10005,
    "ErrorCode": "E_NODE_SERVICE_ERR",
    "description": "UNUSED.",
    "causes": [],
    "actions": []
  },
  {
    "code": 10100,
    "ErrorCode": "E_FUNCTIONS_NOT_SUPPORTED",
    "description": "Functions of type Javascript are only supported in Enterprise Edition.",
    "causes": [
      "Disallow javascript user defined functions in community edition"
    ],
    "actions": [
      "switch to enterprise https://www.couchbase.com/downloads/?family=couchbase-server "
    ],
    "isUser": true
  },
  {
    "code": 10101,
    "ErrorCode": "E_MISSING_FUNCTION",
    "description": "Function [func-name] not found",
    "causes": [
      "1) DROP FUNCTION [func_name]; attempt to drop udf fails as function was never created."
    ],
    "actions": [
      "run SELECT * FROM system:functions;  to view available functions. You can add these as expressions in your query."
    ],
    "isUser": true
  },
  {
    "code": 10102,
    "ErrorCode": "E_DUPLICATE_FUNCTION",
    "description": "Function [func-name] already exists",
    "causes": [
      "CREATE FUNCTION [func_name(arg_list) LANGUAGE INLINE AS [definition];  fails as func_name already exists( systemEntry in _system scope already exits)"
    ],
    "actions": [
      "if you are trying to redefine the function, add REPLACE Clause in query , something like: CREATE OR REPLACE [func_name] LANGUAGE INLINE AS [definition]"
    ],
    "isUser": true
  },
  {
    "code": 10103,
    "ErrorCode": "E_INTERNAL_FUNCTION",
    "description": "operation on function encountered unexpected error ",
    "causes": [
      "the unexpected errors may come from 1) when calling a scope function, there is a context switch to execute the function for eg : SELECT default._default.add3(1); here we switch from current context to default._default but for some unknown reason this fails. 2) When ready function body either from cache or systementry(storage) the retrieved body is not of the expected type( say function is inline but body is from javascript library), 3) error when formalizing variable names in INLINE function's expression(i.e the body) 4)"
    ],
    "actions": [
      "Please contact support"
    ],
    "isUser": false
  },
  {
    "code": 10104,
    "ErrorCode": "E_ARGUMENTS_MISMATCH",
    "description": "Incorrect number of arguments supplied to function( the function is non-variadic)",
    "causes": [
      "either lesser or more number of arguments are passed for eg: CREATE OR REPLACE FUNCTION default:`default`.`_default`.`add4` (a,b) LANGUAGE inline AS ((a+b));  \nSELECT default._default.add4(1);  \nSELECT default._default.add4(1,2,3);"
    ],
    "actions": [
      "To solve this issue you can look up number of parameters in the definition-> either from ui \nOR using functions keyspace , taking example in the causes: SELECT len(definition.parameters) FROM system:functions WHERE identity.name=\"add4\";\n \"results\": [\n    {\n        \"$1\": 2\n    }\n    ]"
    ],
    "isUser": true
  },
  {
    "code": 10105,
    "ErrorCode": "E_INVALID_FUNCTION_NAME",
    "description": "Invalid function name ",
    "causes": [
      "As of now only default nampespace is supported,  function name in CREATE FUNCTION statement must be 1) `[func-name`] -> Global function ( expanded as default:[func_name]), 2) `[bucket]`.`[scope]`.`[func_name]` -> Scope function( explanded as default:[bucket]`.`[scope]`.`[func_name]`"
    ],
    "actions": [
      "Change the function name to follow the scheme specified in the cause"
    ],
    "isUser": true
  },
  {
    "code": 10106,
    "ErrorCode": "E_FUNCTIONS_STORAGE",
    "description": "couldn't access function definition / function change counter",
    "causes": [
      "Could not access function definition for 1) LOAD(during execution): as get operation in metaKv or storage failed. 2) SAVE(Replace): as get or set operation in metaKv or storage failed. 3) DELETE(drop): as delete operation failed. \nCould not access changecounter: change counter is maintained in metakv for functionscache(system:functioncache-> information of recently used udfs) monitoring purpose. Immediately after LOAD/SAVE/DELETE for a function entry we update its change counter, but while doing so a metakv error(bad response) has occured"
    ],
    "actions": [
      "Please contact support"
    ],
    "isUser": false
  },
  {
    "code": 10107,
    "ErrorCode": "E_FUNCTION_ENCODING",
    "description": "Could not [encode/decode] function definition for [func_name]",
    "causes": [
      "1) encode: during a SAVE, the functions body is marshalled to be stored in metakv, 2) decode: during LOAD, the function body is unmarshalled from the response body from meta/system storage. 3) the LOAD and SAVE mechanism for functions also happen during bucket backups"
    ],
    "actions": [
      "Please contact support"
    ],
    "isUser": false
  },
  {
    "code": 10108,
    "ErrorCode": "E_FUNCTIONS_DISABLED",
    "description": "internal/external javascript functions are disabled.",
    "causes": [
      "1) if either internal or external or tenant evaluator(for serverless offering) are not initialized the respective javascript function support is disabled."
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 10109,
    "ErrorCode": "E_FUNCTION_EXECUTION",
    "description": "Error executing function [inline function/javascript function]",
    "causes": [
      "when evaluating the definition of the inline function, the definition expression evalution raises error. (N1QL philosophy is if an expression doesn't make sense you don't error out but rather return null, so errors from inline function are likely to be system errors). Same goes for javascript errors like nil deference( eg: let l; let c = l.a;) , wrong type assertion are errored out."
    ],
    "actions": [
      "try debugging your definition step by step from the error message returned(which line in the definition fails). For javascript udfs look at \"details\" field. Or ask on couchbase forums"
    ]
  },
  {
    "code": 10112,
    "ErrorCode": "E_TOO_MANY_NESTED_FUNCTIONS",
    "description": "Error executing function: [func-name]: [max-level] nested calls",
    "causes": [
      "The problem here is essentially: hitting the max-level depth,i.e maximum calls from a udf . To better explain lets take this example (I call you and you call me). \n/* libA*/\nfunction funcA(a,b) {\n  var p = EXECUTE FUNCTION funcB();\n  var res = []\n  for(const doc of p) {\n      res.push(doc)\n  }\n  return res;\n}\n\n/* libB */\nfunction funcB() {\n  \n  var q = EXECUTE FUNCTION funcA(1,3);\n  var res = []\n  for(const doc of q) {\n      res.push(doc);\n  }\n  return res;\n}\n\n//\nCREATE FUNCTION funcB() LANGUAGE JAVASCRIPT AS \"funcB\" AT \"libB\";\n\n//\nCREATE FUNCTION funcA() LANGUAGE JAVASCRIPT AS \"funcB\" AT \"libB\";\n\n//\nEXECUTE FUNCTION funcA(1,2);\n[\n  {\n    \"code\": 10109,\n    \"msg\": \"Error executing function 'funcA' (libA:funcA)\",\n    \"reason\": {\n      \"details\": {\n        \"Code\": \"  var p = N1QL('EXECUTE FUNCTION funcB();', {}, true);\",\n        \"Exception\": {\n          \"_level\": \"exception\",\n          \"caller\": \"javascript:386\",\n          \"code\": 10112,\n          \"key\": \"function.nested.error\",\n          \"message\": \"Error executing function 'funcA': 129 nested javascript calls\"\n        },\n        \"Location\": \"functions/libA.js:3\",\n        \"Stack\": \"   at funcA (functions/libA.js:3:11)\"\n      },\n      \"type\": \"Exceptions from JS code\"\n    }\n  }\n]"
    ],
    "actions": [
      "in your definition ensure you aren't running into a circular callback loop"
    ]
  },
  {
    "code": 10113,
    "ErrorCode": "E_INNER_FUNCTION_EXECUTION",
    "description": "UNUSED: not show to end user, internal to js-evaluator. (Need: func A-> func B-> func C (where a query fails) ,this is propagated up by unwinding the stack and propagated to funcA level. So never actually raised to end user.",
    "causes": [],
    "actions": []
  },
  {
    "code": 10114,
    "ErrorCode": "E_LIBRARY_PATH_ERROR",
    "description": "Invalid javascript library path: [lib-path] ",
    "causes": [
      "CREATE FUNCTION [func-name](...) LANGUAGE JAVASCRIPT AS [func-in-lib] AT [lib-path].  Expected libpath to be 1) for global libraries the library name as is (for eg: \"Add\" or relative path \"./Add\") 2) for scope libraries , need to pass [bucket]/[scope]/[libraryname](eg: default/_default/[lib-name] or relative-path ./default/_default/[lib-name] )"
    ],
    "actions": [
      "Please change the path to library to expected format explained in the cause"
    ],
    "isUser": true
  },
  {
    "code": 10115,
    "ErrorCode": "E_FUNCTION_LOADING",
    "description": "Error loading function",
    "causes": [
      "Function Loading error\n1) when using internalJS CREATE FUNCTION [func-name](..) lANGUAGE AS JAVASCRIPT AS \"[js-code]\"; , couldn't transpile code. 2) using external evaluator-> either failed to get the evaluator or load the library function from library ( the function exists but something went wrong in evaluator logic in eventing service.\n\nEvaluator Loading error\n1) \n\nEvaluator Inflating error\n1)"
    ],
    "actions": [
      "// find out where to look for eventing logs etc"
    ],
    "isUser": false
  },
  {
    "code": 10118,
    "ErrorCode": "E_FUNCTIONS_UNSUPPORTED_ACTION",
    "description": "NEVER RAISED outside , only for dummy runner",
    "causes": [],
    "actions": []
  },
  {
    "code": 10119,
    "ErrorCode": "E_FUNCTION_STATEMENTS",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 10200,
    "ErrorCode": "E_DATASTORE_INVALID_BUCKET_PARTS",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 10201,
    "ErrorCode": "E_QUERY_CONTEXT",
    "description": "invalid argument to query-context in request",
    "causes": [
      "perhaps missing backtick/ invalid namespace(currently only support default)"
    ],
    "actions": [
      "you can look over here for more clarity https://docs.couchbase.com/server/current/n1ql/n1ql-rest-api/index.html#_request_parameters "
    ],
    "isUser": true
  },
  {
    "code": 10202,
    "ErrorCode": "E_BUCKET_NO_DEFAULT_COLLECTION",
    "description": "Bucket [name] does not have a default collection",
    "causes": [
      "1) if selecting on the bucket, we are actually selecting _default scope, _default collection, but this may be missing.",
      "2) GRANT/REVOKE role on the bucket, but no _default scope, _default collection.",
      "3) Similarly if INSERT/UPDATE on bucket."
    ],
    "actions": [
      "look for specific collection and specify path as bucket.scope.collection."
    ],
    "isUser": false
  },
  {
    "code": 10203,
    "ErrorCode": "E_NO_DATASTORE",
    "description": "No datastore is available",
    "causes": [
      "1) when doing bucket backup using POST req to api/v1/bucket/{bucket}/backup and have cbo=on, and try to get _system collection, but datastore instance is not set we raise this error.",
      "2) In a similar fashion when JS udf library are stored under bucket.scope When try to \"get\" function on editing body, or \"save\" on adding a new udf , or \"Load\" i.e if storage counter is changed we re-\"get\" in case of execution of the function/explain function, or \"delete\"  when we delete the function from storage or during migration of functions to n1ql_system_bucket from _system_collection. So for \"get\",\"save\",\"load\", \"delete\" scenarios but datastore is not set."
    ],
    "actions": [
      "Possible that the node where memory/storage is, is down but another node where query is up."
    ],
    "isUser": true
  },
  {
    "code": 10300,
    "ErrorCode": "E_BUCKET_UPDATER_MAX_ERRORS",
    "description": "Max failures reached.",
    "causes": [
      "During Query Planning when, we go from Algebra node of the keyspace (for eg: a simpleFromTerm(`default`) in SELECT * FROM default;) to the actual datastore keyspace abstraction. This involves GET request from streamingUrl-> /pools/default/bucketsStreaming/{:bucket} to load in bucket/keyspace information and stored in namespace's keyspace cache. But when the bucket is updated for eg: adding a KV node and rebalance-> the updater's streaming callback is called to reset the bucket's updater. During this process we hit MAX_RETRIES LIMIT for request to streamingUrl( /pools/default/bucketsStreaming/{:bucket} )."
    ],
    "actions": [
      "This is problem with NsServer possibly, contact support."
    ],
    "isUser": false
  },
  {
    "code": 10301,
    "ErrorCode": "E_BUCKET_UPDATER_NO_HEALTHY_NODES",
    "description": "No healthy nodes found.",
    "causes": [
      "When running the updater to get latest bucket info, no nodes where the bucket resides where found to be healthy"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 10302,
    "ErrorCode": "E_BUCKET_UPDATER_STREAM_ERROR",
    "description": "Streaming error",
    "causes": [
      "Error while creating http request using go's http package to the streamUrl-> /pools/default/bucketsStreaming/{:bucket}"
    ],
    "actions": [
      "Contact Support"
    ],
    "isUser": false
  },
  {
    "code": 10303,
    "ErrorCode": "E_BUCKET_UPDATER_AUTH_ERROR",
    "description": "Authentication error",
    "causes": [
      "Error while getting auth user & password from the authentication handler(either from cbauth or from auth header in the client request)"
    ],
    "actions": [
      "Contact Support"
    ],
    "isUser": false
  },
  {
    "code": 10304,
    "ErrorCode": "E_BUCKET_UPDATER_CONNECTION_FAILED",
    "description": "Failed to connect to host.",
    "causes": [
      "GET request to /pools/default/bucketsStreaming/{:bucket} endpoint got a response status of 5XX or 408 Request Timeout"
    ],
    "actions": [
      "Contact Support"
    ],
    "isUser": false
  },
  {
    "code": 10305,
    "ErrorCode": "E_BUCKET_UPDATER_ERROR_MAPPING",
    "description": "Mapping error: from Kv-TCP to Kv-TLS",
    "causes": [
      "While running doing bucket updater logic and client expects tls, if KV service is distributed across nodes. We take host:tcp-port and map to host:kv-ssl port"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 10306,
    "ErrorCode": "E_BUCKET_UPDATER_EP_NOT_FOUND",
    "description": "Streaming endpoint not found",
    "causes": [
      "GET request to /pools/default/bucketsStreaming/{:bucket} endpoint got a response status of 404 Not Found"
    ],
    "actions": [
      "Some problem with NsServer(Orchestrator process), Contact Support"
    ]
  },
  {
    "code": 10500,
    "ErrorCode": "E_ADVISOR_SESSION_NOT_FOUND",
    "description": "Advisor: Session not found",
    "causes": [
      "user has run Advisor function with stop_object https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html#advisor-session-stop .  But session id passed does not exist in the task_cache."
    ],
    "actions": [
      "run SELECT * FROM system:tasks_cache;"
    ],
    "isUser": true
  },
  {
    "code": 10501,
    "ErrorCode": "E_ADVISOR_INVALID_ACTION",
    "description": "Advisor: Invalid value for 'action",
    "causes": [
      "invalid value for \"actions\" field."
    ],
    "actions": [
      "Allowed values for \"actions\"-> \"get\", \"purge\", \"abort\", \"list\", \"stop\", link to advisor function documentation : https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html "
    ],
    "isUser": true
  },
  {
    "code": 10502,
    "ErrorCode": "E_ADVISOR_ACTION_MISSING",
    "description": "Advisor: missing argument for 'action",
    "causes": [
      "input object to advisor must always have an \"action\" field."
    ],
    "actions": [
      "Allowed values for \"actions\"-> \"get\", \"purge\", \"abort\", \"list\", \"stop\", link to advisor function documentation : https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html   "
    ],
    "isUser": true
  },
  {
    "code": 10503,
    "ErrorCode": "E_ADVISOR_INVALID_ARGS",
    "description": "Advisor: Invalid arguments.",
    "causes": [
      "some fields in the advisor object are not valid. Example bad query:  SELECT ADVISOR({\"act\": \"start\", \"novalid\": \"cd040b30-59a2-4b3c-81fa-6ab748\"});\n{\n    \"requestID\": \"acdf5d13-fad2-461f-b817-f26c13b41dd6\",\n    \"signature\": {\n        \"$1\": \"object\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"func_advisor:399\",\n                \"cause\": {\n                    \"args\": [\n                        \"act\",\n                        \"novalid\"\n                    ]\n                },\n                \"code\": 10503,\n                \"key\": \"function.advisor.invalid_arguments\",\n                \"message\": \"Advisor: Invalid arguments.\"\n            }\n        }\n    ],"
    ],
    "actions": [
      "allowed fieldnames-> for startobject https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html#arguments-3 \nfor listobject https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html#arguments-4 \nfor stopobject https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html#advisor-session-stop \nfor abortobject https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html#arguments-6 \nfor getobject https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html#arguments-7 \nfor purgeoject https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/advisor.html#arguments-8 "
    ],
    "isUser": true
  },
  {
    "code": 11000,
    "ErrorCode": "E_SYSTEM_DATASTORE",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 11002,
    "ErrorCode": "E_SYSTEM_KEYSPACE_NOT_FOUND",
    "description": "Keyspace not found in system namespace",
    "causes": [
      "keyspace provided by user doesn't exist in system namespace"
    ],
    "actions": [
      "look over here https://docs.couchbase.com/server/current/n1ql/n1ql-intro/sysinfo.html , to see keyspaces in system namespace"
    ],
    "isUser": true
  },
  {
    "code": 11003,
    "ErrorCode": "E_SYSTEM_NOT_IMPLEMENTED",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 11004,
    "ErrorCode": "E_SYSTEM_NOT_SUPPORTED",
    "description": "System datastore : Not supported",
    "causes": [
      "Cannot CREATE PRIMARY INDEX / CREATE INDEX / BUILD INDEX on system catalog keyspaces"
    ],
    "actions": [
      "Can query on system datastore without creating index."
    ],
    "isUser": true
  },
  {
    "code": 11005,
    "ErrorCode": "E_SYSTEM_IDX_NOT_FOUND",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 11006,
    "ErrorCode": "E_SYSTEM_IDX_NO_DROP",
    "description": "System datastore : This index cannot be dropped ",
    "causes": [],
    "actions": []
  },
  {
    "code": 11007,
    "ErrorCode": "E_SYSTEM_STMT_NOT_FOUND",
    "description": "System datastore : Statement not found",
    "causes": [],
    "actions": []
  },
  {
    "code": 11008,
    "ErrorCode": "W_SYSTEM_REMOTE",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 11009,
    "ErrorCode": "E_SYSTEM_UNABLE_TO_RETRIEVE",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 11010,
    "ErrorCode": "E_SYSTEM_UNABLE_TO_UPDATE",
    "description": "System datastore : unable to update user information in server",
    "causes": [
      "Your query to GRANT or REVOKE set roles using GRANT/REVOKE has not been handled by \"/settings/rbac/users/[local]/{user}\" and returns bad response"
    ],
    "actions": [
      "try again"
    ],
    "isUser": false
  },
  {
    "code": 11011,
    "ErrorCode": "W_SYSTEM_FILTERED_ROWS",
    "description": "One or more documents were excluded from the system bucket because of insufficient user permissions,",
    "causes": [
      "User is COUNTING or querying on system collections but doesn't have query_system_catalog role, eg: 1) SELECT COUNT(*) FROM system:indexes -> but user doesn't have query_system_catalog role."
    ],
    "actions": [
      "Not an error just a warning, ask Admin to grant query _system_catalog role if required by the user"
    ],
    "isUser": true
  },
  {
    "code": 11012,
    "ErrorCode": "E_SYSTEM_MALFORMED_KEY",
    "description": "System datastore : key is not of the correct format for keyspace",
    "causes": [
      "Expected key format from index:-> 1) {namespace}/{bucket}/{index_id} or 2) {namespace}/{bucket}/{scope}/{collection}/{index_id} for Fetch Call to dataservice"
    ],
    "actions": [
      "DROP INDEX and recreate as document keys are malformed, possibly contact the support team"
    ],
    "isUser": false
  },
  {
    "code": 11013,
    "ErrorCode": "E_SYSTEM_NO_BUCKETS",
    "description": "The system namespace contains no buckets that contain scopes.",
    "causes": [
      "the system namespace buckets don't have bucket.scope.collection format, i.e no scopes or collection only bucket. For eg: system:indexes."
    ],
    "actions": [
      "Please figure out which system bucket you want to query on from https://docs.couchbase.com/server/current/n1ql/n1ql-intro/sysinfo.html "
    ]
  },
  {
    "code": 11015,
    "ErrorCode": "W_SYSTEM_REMOTE_NODE_NOT_FOUND",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 12000,
    "ErrorCode": "E_CB_CONNECTION",
    "description": "cbq-engine cannot connect to the cluster on for the provided URL (default- http://127.0.0.1:8091)",
    "causes": [
      "on startup cbq-engine creates a datastore instance which gives access to various information about all buckets & services across the cluster. This involves creating couchbase client which when cbauth database is not initialized proceeds with a basic URL based authorization, on failure here this error is thrown"
    ],
    "actions": []
  },
  {
    "code": 12002,
    "ErrorCode": "E_CB_NAMESPACE_NOT_FOUND",
    "description": "Namespace not found in CB datastore",
    "causes": [
      "typically this means server failed to get the default pool"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 12003,
    "ErrorCode": "E_CB_KEYSPACE_NOT_FOUND",
    "description": "Keyspace not found in CB datastore",
    "causes": [
      "couldn't find a bucket or collection of the provided name by the user"
    ],
    "actions": [
      "use \"SELECT * FROM system:keyspaces\" and check the fields bucket & name to see all existing keyspaces in the cluster"
    ],
    "isUser": true
  },
  {
    "code": 12004,
    "ErrorCode": "E_CB_PRIMARY_INDEX_NOT_FOUND",
    "description": "NOT in 7.6",
    "causes": [],
    "actions": []
  },
  {
    "code": 12005,
    "ErrorCode": "E_CB_INDEXER_NOT_IMPLEMENTED",
    "description": "Indexer not implemented ",
    "causes": [
      "when indexing service(GSI) is not enabled or similarly if using FTS index in a query but FTS service is not enabled"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 12006,
    "ErrorCode": "E_CB_KEYSPACE_COUNT",
    "description": "Failed to get count for keyspace ",
    "causes": [
      "when selecting on system:keyspaces_info to to get count of number of documents from bucket API, but we get an error while doing so"
    ],
    "actions": [
      "try again after sometime"
    ],
    "isUser": false
  },
  {
    "code": 12008,
    "ErrorCode": "E_CB_BULK_GET",
    "description": "Error performing bulk get operation ",
    "causes": [
      "when fetching documents from a bucket if has more than one document we issue bulkget operation, this error is raised when max number of retries is hit or default timeout is hit"
    ],
    "actions": [
      "might be the kv is overwhelmed and your request was throttled you would have to just retry"
    ],
    "isUser": false
  },
  {
    "code": 12009,
    "ErrorCode": "E_CB_DML",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 12009,
    "ErrorCode": "E_CB_DML",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 12011,
    "ErrorCode": "E_CB_DELETE_FAILED",
    "description": "delete request failed",
    "causes": [
      "regardless of parallelised mututaion ops or single mutation op, for a particular key the delete operation has got a bad response, thats when this error is raised"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 12011,
    "ErrorCode": "E_CB_DELETE_FAILED",
    "description": "Error performing delete on datastore",
    "causes": [
      "Delete is internally just a set op with value as nil and this operation fails, the client request for delete fails and we get an response indicating error"
    ],
    "actions": [
      "retry after sometime"
    ],
    "isUser": false
  },
  {
    "code": 12012,
    "ErrorCode": "E_CB_LOAD_INDEXES",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 12012,
    "ErrorCode": "E_CB_LOAD_INDEXES",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 12013,
    "ErrorCode": "E_CB_BUCKET_TYPE_NOT_SUPPORTED",
    "description": "This bucket type is not supported",
    "causes": [
      "as 7.6 only memcached buckets are deprecated and are not supported to query on, couchbase and ephimeral buckets are allowed"
    ],
    "actions": [
      "migrate all your documents to a couchbase bucket "
    ],
    "isUser": true
  },
  {
    "code": 12013,
    "ErrorCode": "E_CB_BUCKET_TYPE_NOT_SUPPORTED",
    "description": "Error this bucket type is not supported",
    "causes": [
      "DML statements on the current bucket type is not supported: possible cause is that you are querying on memcached buckets which are deprecated"
    ],
    "actions": [
      "ensure how have backup for the memcached bucket and now migrate documents to a couchbase bucket"
    ],
    "isUser": true
  },
  {
    "code": 12015,
    "ErrorCode": "E_CB_INDEX_SCAN_TIMEOUT",
    "description": "Index scan timed out",
    "causes": [
      "particular for primaryscan, if the indexer cannot find a snapshot that satisfies the consistency guarantee of the query within the timeout limit, it will timeout without returning any primary keys. Query service will resort to chunk based scanning,i.e successive scans until all primary keys are returned. But when query has Offset/Aggregates/Order is when this error is raised, as for the earlier mentioned clauses we require results to be exact."
    ],
    "actions": [
      "please create appropriate secondary index."
    ],
    "isUser": false
  },
  {
    "code": 12015,
    "ErrorCode": "E_CB_INDEX_SCAN_TIMEOUT",
    "description": "Index scan timed out",
    "causes": [
      "When using GSI Primary index, query service creates a connection to indexer service and scan performed where documents are sent over the connection from indexer. But indexer can raise a connection timeout for long running primary scan op thats when this error is raised"
    ],
    "actions": [
      "The only and best approach is to use suitable index in production instead of a primary index. Do consider taking the help of index-advisor if unsure of how to go about creating the appropriate index,  https://docs.couchbase.com/cloud/guides/index-advisor.html "
    ],
    "isUser": false
  },
  {
    "code": 12016,
    "ErrorCode": "E_CB_INDEX_NOT_FOUND",
    "description": "Index Not Found",
    "causes": [
      "while using ALTER or DROP INDEX statements the name of index in query doesn't exist"
    ],
    "actions": [
      "check available indexes on the cluster using system:indexes "
    ],
    "isUser": true
  },
  {
    "code": 12016,
    "ErrorCode": "E_CB_INDEX_NOT_FOUND",
    "description": "Index Not Found",
    "causes": [
      "Running DROP/ALTER INDEX"
    ],
    "actions": []
  },
  {
    "code": 12017,
    "ErrorCode": "E_CB_GET_RANDOM_ENTRY",
    "description": "Error getting random entry from keyspace",
    "causes": [
      "when using INFER statement ,underhood request to kv is getrandomdoc op for which on receiving a bad response we raise this error"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 12018,
    "ErrorCode": "E_UNABLE_TO_INIT_CB_AUTH",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 12019,
    "ErrorCode": "E_AUDIT_STREAM_HANDLER_FAILED",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 12020,
    "ErrorCode": "E_CB_BUCKET_NOT_FOUND",
    "description": "Scope not found in CB datastore",
    "causes": [
      "Only raised when dropping a non-existing scope,"
    ],
    "actions": [
      "verify existing scopes using \"SELECT `scope` FROM system:keyspaces WHERE `bucket`=[BUCKETNAME];"
    ],
    "isUser": true
  },
  {
    "code": 12022,
    "ErrorCode": "E_CB_KEYSPACE_SIZE",
    "description": "Failed to get size for keyspace",
    "causes": [
      "when querying on system:keyspace_info, we get a bad response from the bucket stats api"
    ],
    "actions": [
      "try again after sometime"
    ],
    "isUser": false
  },
  {
    "code": 12023,
    "ErrorCode": "E_CB_SECURITY_CONFIG_NOT_PROVIDED",
    "description": "Connection security config not provided. Unable to load bucket",
    "causes": [
      "TLS settings and node to node security settings if not passed to datastore, it refuses to startup buckets"
    ],
    "actions": [
      "check if cbauth is initialized"
    ],
    "isUser": false
  },
  {
    "code": 12024,
    "ErrorCode": "E_CB_CREATE_SYSTEM_BUCKET",
    "description": "Error while creating system bucket",
    "causes": [
      "onprem - N1QL_SYSTEM_BUCKET is created for cbo purposes. This errors is raised when the bucket is not created."
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 12025,
    "ErrorCode": "E_CB_BUCKET_CREATE_SCOPE",
    "description": "Error while creating scope",
    "causes": [
      "1. CREATE SCOPE [bucket].[scope] may result in error being raised if [scope] already exists",
      "2. failed to created _N1QL_SYSTEM_SCOPE on _N1QL_SYSTEM_BUCKET for update statistics"
    ],
    "actions": []
  },
  {
    "code": 12026,
    "ErrorCode": "E_CB_BUCKET_DROP_SCOPE",
    "description": "Error while dropping scope",
    "causes": [
      "DROP SCOPE [bucket].[scope] , scope doesn't exist"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 12027,
    "ErrorCode": "E_CB_BUCKET_CREATE_COLLECTION",
    "description": "Error while creating collection",
    "causes": [
      "1. option is not \"maxTTL\", 2. maxTTL option value is not a number, 3. post request to the api for create collection returned error"
    ],
    "actions": []
  },
  {
    "code": 12028,
    "ErrorCode": "E_CB_BUCKET_DROP_COLLECTION",
    "description": "Error while dropping collection ",
    "causes": [
      "DROP COLLECTION [bucket].[scope].[collection] , post request to the api for drop collection returns error as it is not successful."
    ],
    "actions": [
      "Maybe check if collection/scope/bucket exists"
    ],
    "isUser": false
  },
  {
    "code": 12029,
    "ErrorCode": "E_CB_BUCKET_FLUSH_COLLECTION",
    "description": "Error while flushing collection",
    "causes": [
      "FLUSH COLLECT [keyspace], post request to bucket api /pools/default/buckets/default/controller/doFlush is not successful, as 1. bucket may not have flushEnabled, 2. keyspace doesn't exist"
    ],
    "actions": [
      "follow https://docs.couchbase.com/server/current/rest-api/rest-bucket-create.html#flushenabled to create flush enabled bucket or edit existing bucket to allow flushing"
    ],
    "isUser": true
  },
  {
    "code": 12030,
    "ErrorCode": "E_BINARY_DOCUMENT_MUTATION",
    "description": "Mutation of binary document is not supported",
    "causes": [
      "non-JSON serialization will prevent the document from being accessible via Query, for INSERT/UPDATE/UPSERT, but is allowed for DELETE."
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 12031,
    "ErrorCode": "E_DURABILITY_NOT_SUPPORTED",
    "description": "Durability is not supported in the SDK being used",
    "causes": [
      "to query on buckets that have durability enforced https://docs.couchbase.com/server/current/learn/data/durability.html , sdk must pass a client context without which the DML statement will not passthrough"
    ],
    "actions": [
      "upgrade to a newer version of SDK "
    ],
    "isUser": true
  },
  {
    "code": 12032,
    "ErrorCode": "E_PRESERVE_EXPIRY_NOT_SUPPORTED",
    "description": "Preserve expiration is not supported.",
    "causes": [
      "SDK version doesn't support preservexpiry"
    ],
    "actions": [
      "upgrade to a newer version of SDK "
    ],
    "isUser": true
  },
  {
    "code": 12033,
    "ErrorCode": "E_CAS_MISMATCH",
    "description": "Error performing bulk get operation, CAS mismatch-> only emebedded in E_CB_DML",
    "causes": [],
    "actions": []
  },
  {
    "code": 12034,
    "ErrorCode": "E_DML_MC",
    "description": "MC(data service) error, usually wrapped in DMLerror / BulkGetError",
    "causes": [
      "Data service operation failed, fatal memcached response is received maybe during fetch or when performing mutation"
    ],
    "actions": [
      "try again"
    ],
    "isUser": false
  },
  {
    "code": 12035,
    "ErrorCode": "E_CB_NOT_PRIMARY_INDEX",
    "description": "Index you are trying to drop is not a primary index",
    "causes": [
      "DROP PRIMARY INDEX statement but index specified is not a primary index"
    ],
    "actions": [
      "look up provider for the index using system:indexes keyspace. If gsi: use DROP INDEX statement instead, incase of fts please use ui to drop the index"
    ],
    "isUser": true
  },
  {
    "code": 12036,
    "ErrorCode": "E_DML_INSERT",
    "description": "Error in INSERT of a particular key-value pair",
    "causes": [
      "INSERT statement issues Add op per document to dataservice, if receiving a fatal response this error is raised"
    ],
    "actions": [
      "try again"
    ],
    "isUser": false
  },
  {
    "code": 12037,
    "ErrorCode": "E_ACCESS_DENIED",
    "description": "User doesn't have access to the particular keyspace in serverless",
    "causes": [
      "similar to insufficient datastore credentials but for security reasons in serverless a more generic error is raised"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 12038,
    "ErrorCode": "E_WITH_INVALID_OPTION",
    "description": "Invalid option is passed by user",
    "causes": [
      "When passing options using WITH construct for CREATE COLLECTION/ CREATE SEQUENCE/ ALTER SEQUENCE"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 12039,
    "ErrorCode": "E_WITH_INVALID_TYPE",
    "description": "Invalid value for option that expects a particular type",
    "causes": [
      "for example: in CREATE SEQUENCE option \"cycle\" expects bool(true/false) but user has passed non-bool"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 12040,
    "ErrorCode": "E_INVALID_COMPRESSED_VALUE",
    "description": "Invalid compressed document received from datastore",
    "causes": [
      "Expects snappy compression encoded data"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 12041,
    "ErrorCode": "E_CB_BUCKET_CLOSED",
    "description": "Bucket is closed",
    "causes": [],
    "actions": []
  },
  {
    "code": 12042,
    "ErrorCode": "E_CB_SUBDOC_GET",
    "description": "UNUSED",
    "causes": [],
    "actions": []
  },
  {
    "code": 12043,
    "ErrorCode": "E_CB_SUBDOC_SET",
    "description": "Sub-doc set operation failed, when using sequences",
    "causes": [],
    "actions": []
  },
  {
    "code": 12044,
    "ErrorCode": "E_CB_DROP_SYSTEM_BUCKET",
    "description": "Error while dropping system bucket ",
    "causes": [
      "onprem - at the end of migration N1QL_SYSTEM_BUCKET is dropped, but if request to drop is erronrous we raise this error"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 13012,
    "ErrorCode": "E_DATASTORE_CLUSTER",
    "description": "Error retrieving cluster information ",
    "causes": [
      "user has run query on system:nodes keyspace, which internally checks the response from the nsserver endpoints: /pools/default/ , /pools/default/nodeServices, but has got a bad response. Or query service is interested in topology of the cluster."
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 13013,
    "ErrorCode": "E_DATASTORE_UNABLE_TO_RETRIEVE_ROLES",
    "description": "Unable to retrieve roles from server.",
    "causes": [
      "request to http://{ip-address-or-domain-name}:8091/settings/rbac/roles endpoint fails"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 13014,
    "ErrorCode": "E_DATASTORE_INSUFFICIENT_CREDENTIALS",
    "description": "\"User doesn't have either QuerySelect/QueryUpdate/QueryInsert/QueryDelete",
    "causes": [
      "User doesn't have either QuerySelect/QueryUpdate/QueryInsert/QueryDelete"
    ],
    "actions": [
      "admin has to grant user required RBAC using security tab in web console or follow https://docs.couchbase.com/server/current/rest-api/rbac.html"
    ],
    "isUser": true
  },
  {
    "code": 13015,
    "ErrorCode": "E_DATASTORE_UNABLE_TO_RETRIEVE_BUCKETS",
    "description": "is not directly returned and is usually the cause for SystemDatastoreError:E_SYSTEM_DATASTORE",
    "causes": [
      "Occurs when doing COUNT on buckets in system catalog, when cbauth is stale or empty crendential list"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 13016,
    "ErrorCode": "E_DATASTORE_NO_ADMIN",
    "description": "Unable to determine admin credentials",
    "causes": [
      "When running index advisor on serverless, we get Admin Credentials to use Admin context for Advisor session queries. But we fail to get back Admin credentials for that particular datastore"
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 13017,
    "ErrorCode": "E_DATASTORE_NOT_SET",
    "description": "Datastore not set",
    "causes": [
      "trying to get bucket / keyspace / scope information in the execution flow but datastore is not set"
    ],
    "actions": []
  },
  {
    "code": 13018,
    "ErrorCode": "E_DATASTORE_INVALID_URI",
    "description": "Invalid datastore URI",
    "causes": [
      "if you are trying to build cbserver on your own, cbq-engine requires -> URI to have either http, dir, file, mock as protocol or file path but none of the following was received"
    ],
    "actions": [
      "standard --datastore argument is -datastore=http://127.0.0.1:8091"
    ],
    "isUser": true
  },
  {
    "code": 14000,
    "ErrorCode": "E_INDEX_SCAN_SIZE",
    "description": "when index connection buffer size is requested is less than 0 - NOT SURE IF THIS EVER HAPPENS",
    "causes": [],
    "actions": []
  },
  {
    "code": 16050,
    "ErrorCode": "E_SS_IDX_NOT_FOUND",
    "description": "Index not found",
    "causes": [],
    "actions": []
  },
  {
    "code": 16051,
    "ErrorCode": "E_SS_NOT_SUPPORTED",
    "description": "[Operation/Statement] not supported for scan",
    "causes": [
      "1) CREATE PRIMARY - Fail Safe code, algebra tree for CREATE PRIMARY doesn't allow sequential scan as input for USING Clause",
      "2) CREATE INDEX  - Fail Safe code, again algebra tree for CREATE INDEX doesn't allow sequential scan as input for USING Clause",
      "3) BUILD INDEX - Fail Safe code, again algebra tree for BUILD INDEX doesn't allow sequential scan as input for USING Clause",
      "4) DROP INDEX - Fail Safe code, again algebra tree for DROP INDEX doesn't allow sequential scan as input for USING Clause",
      "5) ALTER INDEX - Fail Safe code, again algebra tree for ALTER INDEX doesn't allow sequential scan as input for USING Clause",
      "6) Datastore doesn't implement the interface required for KV-range scans ( used by Sequential Scan under the hood)."
    ],
    "actions": [
      "For 6) upgrade dataservice to a version that supports KV-range scans"
    ],
    "isUser": false
  },
  {
    "code": 16052,
    "ErrorCode": "E_SS_INACTIVE",
    "description": "Inactive scan in Fetch",
    "causes": [
      "The scan coordinator go routine has left the scan object inactive possibly due to a cancel on timeout or error, thus the fetch procedure cannot use the scan identifier to get keys."
    ],
    "actions": [
      "Contact Support."
    ],
    "isUser": false
  },
  {
    "code": 16053,
    "ErrorCode": "E_SS_INVALID",
    "description": "Invalid scan in [stop/fetch]",
    "causes": [
      "1) Fetch-> fail-safe code, to ensure scan received is of sequential-scan",
      "2) Stop-> fail-safe code, to ensure scan received is of sequential-scan"
    ],
    "actions": [
      "Contact Support."
    ],
    "isUser": false
  },
  {
    "code": 16054,
    "ErrorCode": "E_SS_CONTINUE",
    "description": "Scan continuation failed",
    "causes": [
      "1) kv doc https://github.com/couchbase/kv_engine/blob/abbf3412cad1fa8399b6e99bcb68bbfdad67ef4d/docs/range_scans/range_scan_continue.md \n1) data service responds with WOULD_THROTTLE / NOT_MY_VBUCKET / KEY_ENOENT response status on Range-scan-continue command, so we requeue the vbucket-scan handle, but the scan state was not the expected _WORKING, or queue assigned to the scan is higher than that of the number of queues predefined in the rangescanworkerController.",
      "2) Range-scan-continue command request returned with a response with status other than WOULD_THROTTLE / NOT_MY_VBUCKET/ KEY_ENOENT , we report the error",
      "3) On WOULD_THROTTLE response, we try to requeue the vbucket-scan handle so a worker can pick it up, after a brief suspend. But the requeue failed.",
      "4) Similarly if we receive  NOT_MY_VBUCKET/ KEY_ENOENT response status  , we requeue the vbucket-scan handle but the requeue failed.",
      "5) error from Range-scan-continue command has neither WOULD_THROTTLE / NOT_MY_VBUCKET/ KEY_ENOENT response status , hence we report the error and proceed to cancel the scan"
    ],
    "actions": [
      "Contact Support."
    ],
    "isUser": false
  },
  {
    "code": 16055,
    "ErrorCode": "E_SS_CREATE",
    "description": "Scan creation failed",
    "causes": [
      "1) kv doc https://github.com/couchbase/kv_engine/blob/abbf3412cad1fa8399b6e99bcb68bbfdad67ef4d/docs/range_scans/range_scan_create.md \n1) Create Range Scan failed with response status of WOULD_THROTTLE , so we try to requeue the scan after a suspend, but the requeue failed. Hence we report the error.",
      "2) Response for Range-scan-create is not WOULD_THROTTLE/KEY_ENOENT, we report the error and setup a retry and close the connection."
    ],
    "actions": []
  },
  {
    "code": 16056,
    "ErrorCode": "E_SS_CANCEL",
    "description": "UNUSED.",
    "causes": [],
    "actions": []
  },
  {
    "code": 16057,
    "ErrorCode": "E_SS_TIMEOUT",
    "description": "Scan exceeded permitted duration",
    "causes": [
      "1) Hit timeout when trying to send the keys(for ordered or unordered scan request) got by the coordinator goroutine to the fetchkeys goroutine, hence we error out and cancel all the scheduled vbucket-scans",
      "2) When trying queue a vbscan across the servers, we timedout."
    ],
    "actions": [
      "Increase KVTimeout"
    ]
  },
  {
    "code": 16058,
    "ErrorCode": "E_SS_CID_GET",
    "description": "Failed to get collection ID for scan",
    "causes": [
      "Memcached Op: COLLECTIONS_GET_CID, failed , but collection id is needed for CREATE_RANGE_SCAN op as a key."
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 16059,
    "ErrorCode": "E_SS_CONN",
    "description": "Failed to get connection for scan",
    "causes": [
      "1) Worker failed to get a vbucket connection-> vbmap smaller than vbucket list / invalid vbmap entry for vb [vb-id] /  No master for vbucket / failed to get connection for the pool\n2) vbucket range scan connection failed, so we try to  requeue as we still have retries allowed for it so another worker can pick it up"
    ],
    "actions": []
  },
  {
    "code": 16060,
    "ErrorCode": "E_SS_FETCH_WAIT_TIMEOUT",
    "description": "Timed out polling scan for data",
    "causes": [
      "Hit scanpoll timeout before we could get a key from the scan-coordinator goroutine on the channel."
    ],
    "actions": [
      "Increase KVTimeout"
    ],
    "isUser": false
  },
  {
    "code": 16061,
    "ErrorCode": "E_SS_WORKER_ABORT",
    "description": "A fatal error occurred in scan processing",
    "causes": [
      "When a worker goes through the runScan logic (Create then Continue for a Vbucket) if we panic during the steps the scan is not completed and thus we add all the scans we have to cancel queue to ensure we abort the request for sequential scan and not take up anymore resources."
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 16062,
    "ErrorCode": "E_SS_FAILED",
    "description": "Scan failed",
    "causes": [
      "1) When request timeout is set in /admin/settings , we ensure the timeout hasn't expired before scan using Sequential Scan indexer.",
      "2) When tring to start key scan on a collection-> if something goes wrong in getting the collectionid using COLLECTIONS_GET_CID memcached Command, we error out.",
      "3) After starting the scan coordinator (i.e perform RANGE_SCAN_CREATE (& RANGE_SCAN_CONTINUE) ), but we hit the request timeout so, error out on the deadline and signal that the connection timed out.",
      "4) Fetching keys got from the range_scan_continue command, has internally returned a error response, thus the worker reports error over the channel instead of keys. This renders the scan as failed",
      "5) Timeout when sending the keys got from range_scan downstream"
    ],
    "actions": [
      "Contact Support, possible bug."
    ],
    "isUser": false
  },
  {
    "code": 16063,
    "ErrorCode": "E_SS_SPILL",
    "description": "Operation failed on scan spill file",
    "causes": [
      "1) The threshold before spilling is currently 10 KiB of keys, meaning for a full scan of all v-buckets, the key memory is limited to 10 MiB per sequential scan.",
      "2) in the processing of CREATE_RANGE_SCAN op , if reponse status returned is KEY_ENOENT (key doesn't exist). We truncate any resources used for the vbscan keys slice, buffer slice and spill file. To trucate the spill file we call Ftrucate syscall but if this fails we raise this error.",
      "3) similar release procedure is followed once all the vbscan are processed and nothing remains in the queue, again if Ftruncate syscall fails we raise this error.",
      "4) When reading in keys from countine_range_scan op, we add keys to in memory buffer first but if the buffer capacity is exhaused, we spill\n  i. spill file creation failed.\n  ii. when flushing buffer to spill file something went wrong in the write"
    ],
    "actions": [
      "Contact support"
    ],
    "isUser": false
  },
  {
    "code": 16064,
    "ErrorCode": "E_SS_VALIDATE",
    "description": "Failed to validate document key",
    "causes": [
      "If the scan range is detected to be for a single key value then a single key-validation operation - instead of a scan - for one v-bucket is all that is generated.\n\nwe issue a REPLACE op for the key , and if response status is KEY_ENOENT. We raise this error and the kv-connection is discarded."
    ],
    "actions": [
      "Contact Support"
    ],
    "isUser": false
  },
  {
    "code": 17001,
    "ErrorCode": "E_TRAN_DATASTORE_NOT_SUPPORTED",
    "description": "UNUSED- only for mock/file based datastore",
    "causes": [],
    "actions": []
  },
  {
    "code": 17002,
    "ErrorCode": "E_TRAN_STATEMENT_NOT_SUPPORTED",
    "description": "statement is not supported",
    "causes": [
      "1) START_TRANSACTION statement is not supported within the transaction, i.e cannot run START TRANSACTION statement when we have already issued the same statement before within the transaction timeout",
      "2) COMMIT / ROLLBACK / ROLLBACK_SAVEPOINT / SET_TRANSACTION_ISOLATION / SAVEPOINT are not allowed outside a transaction(i.e need to issue START TRANSACTION before)"
    ],
    "actions": [
      "documentation reference for transactions https://docs.couchbase.com/server/current/n1ql/n1ql-language-reference/transactions.html , also flow this blog if you don't like documentation:) https://www.couchbase.com/blog/transactions-n1ql-couchbase-distributed-nosql/ "
    ],
    "isUser": true
  },
  {
    "code": 17003,
    "ErrorCode": "E_TRAN_FUNCTION_NOT_SUPPORTED",
    "description": "advisor function is not supported within the transaction",
    "causes": [
      "Advisor Function is not allowed within a transaction, as it doesn't make sense semantically."
    ],
    "actions": [
      "Call Advisor outside of a transaction."
    ],
    "isUser": true
  },
  {
    "code": 17004,
    "ErrorCode": "E_TRANSACTION_CONTEXT",
    "description": "Transaction context error",
    "causes": [
      "The transcation id passed by client(either workbench/cbqshell/rest-api) is not present in the transaction cache on the node you are querying on. That is, failed to get the transaction context for that particular transaction id. Maybe, transaction timedout and there was a cleanup, or memory quota was hit. Other reasons tximplicit parameter is used and under the hood \"START TRANSACTION\" was issued before serving any requests,which failed for some reason, hence couldn't retrieve the transaction context."
    ],
    "actions": [
      "Contact support."
    ],
    "isUser": false
  },
  {
    "code": 17005,
    "ErrorCode": "E_TRAN_STATEMENT_OUT_OF_ORDER",
    "description": "Transaction statement is out of order",
    "causes": [
      "User is not using tximplicit parameter , has started a transaction by issuing BEGIN WORK/START TRANSACTION. But has passed txstmtnum parameter in the request while executing following statements for the duration of the transaction. The scenario here is that previous request had a stmtnum> current request which is not allowed so we error out. Example-> cbq> START TRANSACTION;\n{\n    \"requestID\": \"9741b6f4-0e7a-49fa-900a-74840cc522e3\",\n    \"signature\": \"json\",\n    \"results\": [\n    {\n        \"nodeUUID\": \"444892295e0eb3a1cf180dad6104955a\",\n        \"txid\": \"cc55d22d-25ec-477f-9101-3c757f020f3e\"\n    }\n    ],\n    \"status\": \"success\",\n    \"metrics\": {\n        \"elapsedTime\": \"896.459\u00b5s\",\n        \"executionTime\": \"789.167\u00b5s\",\n        \"resultCount\": 1,\n        \"resultSize\": 118,\n        \"serviceLoad\": 2,\n        \"transactionElapsedTime\": \"458.792\u00b5s\",\n        \"transactionRemainingTime\": \"1m59.999537208s\"\n    }\n}\ncbq> \\set -txstmtnum 3;\ncbq> UPDATE customer SET balance = balance - 100 WHERE cid = 1924;\n{\n    \"requestID\": \"b7d8e634-7fe1-4a6c-9dbf-c4005881b2d3\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"status\": \"success\",\n    \"metrics\": {\n        \"elapsedTime\": \"42.013958ms\",\n        \"executionTime\": \"41.685375ms\",\n        \"resultCount\": 0,\n        \"resultSize\": 0,\n        \"serviceLoad\": 0,\n        \"mutationCount\": 1,\n        \"transactionElapsedTime\": \"10.865749833s\",\n        \"transactionRemainingTime\": \"1m49.134244917s\"\n    }\n}\ncbq> \\set -txstmtnum 1;\ncbq> UPDATE customer SET balance = balance - 100 WHERE cid = 1924;\n{\n    \"requestID\": \"567b67d2-5c4d-4594-8d70-6b670cb90f80\",\n    \"errors\": [\n        {\n            \"code\": 17005,\n            \"msg\": \"Transaction statement is out of order (3, 1) \"\n        }\n    ],\n    \"status\": \"fatal\",\n    \"metrics\": {\n        \"elapsedTime\": \"291.459\u00b5s\",\n        \"executionTime\": \"74.709\u00b5s\",\n        \"resultCount\": 0,\n        \"resultSize\": 0,\n        \"serviceLoad\": 0,\n        \"errorCount\": 1\n    }\n}"
    ],
    "actions": [
      "Correct your stmtnum parameter to always be incremental"
    ],
    "isUser": true
  },
  {
    "code": 17006,
    "ErrorCode": "E_START_TRANSACTION",
    "description": "Wrapper error for all error paths during START TRANSACTION / BEGIN WORK statement",
    "causes": [
      "1) failed to create transcation context, 2)"
    ],
    "actions": []
  },
  {
    "code": 17007,
    "ErrorCode": "E_COMMIT_TRANSACTION",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17008,
    "ErrorCode": "E_ROLLBACK_TRANSACTION",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17009,
    "ErrorCode": "E_NO_SAVEPOINT",
    "description": "savepoint is not defined",
    "causes": [
      "User has run ROLLBACK TRAN TO SAVEPOINT [savepoint-name];  But the savepoint [savepoint-name] was not defined"
    ],
    "actions": [
      "Rerun with the correct savepoint-name"
    ],
    "isUser": true
  },
  {
    "code": 17010,
    "ErrorCode": "E_TRANSACTION_EXPIRED",
    "description": "Transaction timeout",
    "causes": [
      "When setting transaction info for the request under transaction. We check if the transaction context for the transactionid has not expired, if it has we raised this error. All mutations done under this transaction are cleaned without commiting. Another place for raising this error user has issued DELETE FROM system:transactions; which renders all ongoing transactions as expired, the same for a DELETE request to admin/transactions/{transaction_id}"
    ],
    "actions": [
      "default timeout cbq file = 15sec, for cbqshell interactive session/work-bench/rest-api = 2min. You can increase the timeout by setting txtimeout parameter https://docs.couchbase.com/server/current/settings/query-settings.html#txtimeout_req "
    ],
    "isUser": true
  },
  {
    "code": 17011,
    "ErrorCode": "E_TRANSACTION_RELEASED",
    "description": "Transaction is released",
    "causes": [
      "During the transaction , user ran START TRANSACTION / COMMIT / ROLLBACK / SET_TRANSACTION_ISOLATION / SAVEPOINT / ROLLBACK_SAVEPOINT statement but the statement completes with errors, then we Delete the transaction entry in system:transactions also mark the transaction status as RELEASED so any further queries coming in with the same transaction id don't go through."
    ],
    "actions": [
      "Look at why the  START TRANSACTION / COMMIT / ROLLBACK / SET_TRANSACTION_ISOLATION / SAVEPOINT / ROLLBACK_SAVEPOINT statement failed."
    ]
  },
  {
    "code": 17012,
    "ErrorCode": "E_DUPLICATE_KEY",
    "description": "Duplicate Key",
    "causes": [
      "Particular key passed in the INSERT statement is already present in the transaction mutations(delta keyspace) or at commit time we found that same key is already present in datastore and commit is unsucessful, and transaction is released."
    ],
    "actions": [
      "Ensure you are inserting documents with unique keys"
    ],
    "isUser": true
  },
  {
    "code": 17013,
    "ErrorCode": "E_TRANSACTION_INUSE",
    "description": "Parallel execution of the statements are not allowed within the transaction",
    "causes": [
      "Parallel requests are not allowed when using transactions"
    ],
    "actions": [
      "ensure you are sending your requests in a blocking way(i.e new request only after receiving the response for the previous request)."
    ],
    "isUser": true
  },
  {
    "code": 17014,
    "ErrorCode": "E_KEY_NOT_FOUND",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17015,
    "ErrorCode": "E_SCAS_MISMATCH",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17016,
    "ErrorCode": "E_TRANSACTION_MEMORY_QUOTA_EXCEEDED",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17017,
    "ErrorCode": "E_TRANSACTION_FETCH",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17018,
    "ErrorCode": "E_POST_COMMIT_TRANSACTION",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17019,
    "ErrorCode": "E_AMBIGUOUS_COMMIT_TRANSACTION",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17020,
    "ErrorCode": "E_TRANSACTION_STAGING",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17021,
    "ErrorCode": "E_TRANSACTION_QUEUE_FULL",
    "description": "Transaction queue is full",
    "causes": [
      "The number of on going requests for a particular transactionid in the queue hit the max limit allowed which is 16."
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 17022,
    "ErrorCode": "W_POST_COMMIT_TRANSACTION",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17096,
    "ErrorCode": "E_GC_AGENT",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 17097,
    "ErrorCode": "E_TRANCE_NOTSUPPORTED",
    "description": "Transactions are not supported in Community Edition",
    "causes": [
      "transcation requires enterprise edition"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 17098,
    "ErrorCode": "E_MEMORY_ALLOCATION",
    "description": "Memory allocation error",
    "causes": [
      "query service uses pools to reduce the load on garbage collector by reusing structures that are accessed by multiple goroutines, but when we go out of memory, or when memory allocation fails this error is raised. The pools maintained are for 1) transaction_mutation, 2) mutation_value_map, 3) savepoints_map_pool, 4) deltakeyspace_map_pool, 5) transactionlogvalue_pool"
    ],
    "actions": [
      "Consider scaling up the node on which you have query service running. Or contact support."
    ],
    "isUser": false
  },
  {
    "code": 17099,
    "ErrorCode": "E_TRANSACTION",
    "description": "",
    "causes": [],
    "actions": []
  },
  {
    "code": 19100,
    "ErrorCode": "E_SEQUENCE_NOT_ENABLED",
    "description": "Sequence support is not enabled for [bucket]",
    "causes": [
      "1) Sequences are only enabled for a bucket once the _system scope and _query collection are available for it.",
      "2) CREATE SEQUENCE statement failed, as we failed to get/create _system scope , _query collection.\n2) backup restore endpoint: /api/v1/bucket/{bucket}/backup is when request is to restore Sequences again we look for _system scope but couldn't find it.\n3) DROP SEQUENCE statement failed, as we failed to get _system scope.\n4) ALTER SEQUENCE statement failed, as we failed to get _system scope.\n5) NEXT VALUE FOR <sequence>/ PREV VALUE FOR <sequence> failed as we could not get _system scope.\n6) On exhausing current cache block incase of NEXT VALUE FOR / PREV VALUE FOR, to know the next block we try to read \"block\" from system storage but fail to do so.\n7) When trying to query system:all_sequences keyspace, if a sequence key is not present in cache we go to storage to read it in, but we fail to do so as getting _system scope failed."
    ],
    "actions": [
      "Contact Support"
    ],
    "isUser": false
  },
  {
    "code": 19101,
    "ErrorCode": "E_SEQUENCE_CREATE",
    "description": "Create failed for sequence [sequnce name]",
    "causes": [
      "1) pre-creation, we validate the scope path for the sequence given by the user ( namespace:bucket.scope.sequencename ) \n    i) system namespace, is not permitted\n    ii) datastore is unset, hence scope validation fails\n    iii) bucket not found, i.e bucket not found in default namespace\n    iv) scope not found, i.e scope is not created",
      "2) Insert operation failed for the storage of the sequence being created, i) could be dml memcached error( cas-mismatch) (unlikely here though), ii) Duplicate Key (unlikely here)",
      "3) CREATE SEQUENCE [IF NOT EXISTS] <name> [IF NOT EXISTS] WITH <options>, \n    We validate options passed to see if they are one of [start cache increment min max cycle], if not we error out on invalid option for create sequence\n     \nCREATE SEQUENCE `default`.`_default`.test3 WITH {\"notmelel\":3};\n{\n    \"requestID\": \"c053a0b2-f9fa-4d04-b096-7920e551ce9e\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 19101,\n            \"msg\": \"Create failed for sequence 'default:default._default.test3'\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"sequences:1090\",\n                \"cause\": {\n                    \"option\": \"notmelel\"\n                },\n                \"code\": 12038,\n                \"key\": \"datastore.with.invalid_option\",\n                \"message\": \"Invalid option 'notmelel'\"\n            }\n        }\n    ]",
      "4) when reading [start cache increment min max ] options , expected value is an integer but didn't get an integer\n    TBNt: we catch this right from the parser , so technically dead code. Also error doesn't indicate which option has received invalid input which would be more helpful than line,col \n\n     CREATE SEQUENCE `default`.`_default`.test6 START WITH \"6\";\n{\n    \"requestID\": \"e6b06c7e-2c43-4dd4-9f55-2b9097e72a9b\",\n    \"errors\": [\n        {\n            \"code\": 3000,\n            \"column\": 44,\n            \"line\": 1,\n            \"msg\": \"syntax error - invalid option value (near line 1, column 44)\"\n        }\n    ],\n\n   Similarly, cycle option expects boolean, but got non-boolean value.",
      "5) cache options ,expects a positive integer value\n\n CREATE SEQUENCE `default`.`_default`.test6 CACHE -6;\n{\n    \"requestID\": \"83e273ad-418c-473b-bb01-dc31009c5390\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 19101,\n            \"msg\": \"Create failed for sequence 'default:default._default.test6'\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"sequences:199\",\n                \"code\": 19105,\n                \"key\": \"datastore.sequence.cache\",\n                \"message\": \"Invalid cache value -6\"\n            }\n        }\n    ],",
      "6) When specifying the sequence range, always have max>=min. Else we error out\n\n CREATE SEQUENCE `default`.`_default`.test7 MINVALUE 10 MAXVALUE 1;\n{\n    \"requestID\": \"9dcc43e1-eb3c-4556-a194-950fe82ea51f\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 19101,\n            \"msg\": \"Create failed for sequence 'default:default._default.test7'\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"sequences:224\",\n                \"code\": 19104,\n                \"key\": \"datastore.sequence.range\",\n                \"message\": \"Invalid range 10 to 1\"\n            }\n        }\n    ]"
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 19102,
    "ErrorCode": "E_SEQUENCE_ALTER",
    "description": "Alter failed for sequence [seq-name]",
    "causes": [
      "1) ALTER SEQUENCE <name> WITH <options>\n   Validating with options failed, unexpected option other than [restart cache increment min max cycle]. Hence we error out",
      "2) cycle expects boolean, restart- boolean or an integer, cache increment min max - an integer, we raise error if we don't receive expected value type for the option.\n\n ALTER SEQUENCE `default`._default.testseq WITH {\"restart\":\"s\"};\n{\n    \"requestID\": \"ab992c28-3ded-4dab-8faf-047e8094e1ea\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 19102,\n            \"msg\": \"Alter failed for sequence 'default:default._default.testseq'\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"sequences:1102\",\n                \"cause\": {\n                    \"option\": \"restart\"\n                },\n                \"code\": 12039,\n                \"key\": \"datastore.with.invalid_value\",\n                \"message\": \"Invalid value for 'restart'\"\n            }\n        }\n    ],",
      "3) cache expects a positive integer, else we error out on INVALID_CACHE",
      "4) newly set min and max options, but min>max , error out on INVALID_RANGE",
      "5) newly set min, but now min> max(old) , error out on INVALID_RANGE",
      "6) newly set max , but now min(old) > max, error out on INVALID_RANGE",
      "7) Before going to stoarge to update the sequence document, we check if _system scope is accessible on the bucket path given in the sequence name.\n i) system namespace, is not permitted\n    ii) datastore is unset, hence scope validation fails\n    iii) bucket not found, i.e bucket not found in default namespace\n    iv) scope not found, i.e scope is not created",
      "8) alter logic,\n      fetch the document using sequence key-> but GET op has returned a bad response,\n\n      then write in new option fields too the annotated value,\n      update , store (set with CAS) op failed  , if due to CAS mismatch or SYNC_WRITE_IN_PROGRESS we retry else we error out."
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 19103,
    "ErrorCode": "E_SEQUENCE_DROP",
    "description": "Drop failed for sequence [seq-name]",
    "causes": [
      "1) DELETE memcached command failed for the sequence document stored under system scope"
    ],
    "actions": [
      "Possibly external activity has already deleted the sequence document. "
    ],
    "isUser": false
  },
  {
    "code": 19104,
    "ErrorCode": "E_SEQUENCE_INVALID_RANGE",
    "description": "Invalid range [min]-[max]",
    "causes": [
      "CREATE / ALTER SEQUENCE has received min and max options , but min>max. Hence we raised this error."
    ],
    "actions": [
      "When using with options, \"min\" field & \"max\" field must be passed such that min<=max.\nSimilar case for when using MINVALUE <num> and MAXVALUE <num> construct."
    ],
    "isUser": true
  },
  {
    "code": 19105,
    "ErrorCode": "E_SEQUENCE_INVALID_CACHE",
    "description": "Invalid cache value [cache-option-argument]",
    "causes": [
      "CREATE / ALTER SEQUENCE statement has received, negative integer so we terminate the logic for create/alter with the cause as invalid cache."
    ],
    "actions": [
      "When using with options, \"cache\" field must have value as a positive integer.\nSimilar case for when using CACHE <num> construct."
    ],
    "isUser": true
  },
  {
    "code": 19106,
    "ErrorCode": "E_SEQUENCE_NOT_FOUND",
    "description": "Sequence [sequence name] not found",
    "causes": [],
    "actions": []
  },
  {
    "code": 19107,
    "ErrorCode": "E_SEQUENCE",
    "description": "Error accessing sequence",
    "causes": [
      "Fail-safe code( as we disallow sequence name with less than 3 elements at the parser)\nWhen we a sequence instance is not found in cache, we load it in from system scope. But there was an error in parsing the path from sequence name(namespace:bucket.scope.seq_name). Ideally would never occur"
    ],
    "actions": []
  },
  {
    "code": 19108,
    "ErrorCode": "E_SEQUENCE_ALREADY_EXISTS",
    "description": "Sequence [seq-name] already exists ",
    "causes": [
      "1) CREATE SEQUENCE ( without IF NOT EXISTS ) , if sequence with same name(namespace:bucket.scope.name) already exists we raise this error.",
      "2) when doing backup restore of a bucket, if the sequence from the restoration index already exists, we raise this error."
    ],
    "actions": [
      "SELECT * FROM system:all_sequences;\n\nwill tell you all the defined sequence on the cluster, when creating name your new sequence something else:)"
    ],
    "isUser": true
  },
  {
    "code": 19109,
    "ErrorCode": "E_SEQUENCE_METAKV",
    "description": "Error accessing sequences cache monitor data",
    "causes": [
      "When an ALTER is issued, the cache revision is updated and monitored by all query nodes using MetaKV.\nSo, on startup we initialize cacherevision kvpair using key as cache-revison path: /query/sequences_cache/, and value as [{node-ip-addr}]+cacherevision\nBut the add failed due to a revmismatch hence log this error as a warning, indicating the sequence cache monitoring rountine couldn't be started as the kv-entry failed to be added."
    ],
    "actions": [
      "Find out why Add failed, something is wrong with cbauth?\n1) possible revmismatch, same key(/query/sequences_cache/revision/) already exists"
    ],
    "isUser": false
  },
  {
    "code": 19110,
    "ErrorCode": "E_SEQUENCE_INVALID_DATA",
    "description": "Invalid sequence data",
    "causes": [
      "1) missing data,\n     ALTER SEQUENCE [sequence_name] WITH {\"restart\":4};\n     But [sequence_name] is not defined, i.e no sequence document in _system._query collection has its key as [sequence_name]. Hence the alter fails.\n\n    ALTER SEQUENCE `default`._default.testseq WITH {\"restart\":4};\n{\n    \"requestID\": \"952b80e2-433f-44a9-895f-cead92426846\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 19110,\n            \"msg\": \"Invalid sequence data\",\n            \"reason\": \"missing data\"\n        }\n    ],",
      "2) ALTER SEQUENCE `default`._default.test5 WITH {\"restart\":true};\n\nBut externally someone has changed the string value assigned to \"initial\" to something else\nFor eg:\nWhat we expected KV return\n{\n  \"base\": \"4\",\n  \"block\": 2,\n  \"cache\": \"50\",\n  \"cycle\": false,\n  \"increment\": \"1\",\n  \"initial\": \"4\",\n  \"max\": \"9223372036854775807\",\n  \"min\": \"-9223372036854775808\",\n  \"version\": 1\n}\n\nBut we got\n{\n  \"base\": \"4\",\n  \"block\": 2,\n  \"cache\": \"50\",\n  \"cycle\": false,\n  \"increment\": \"1\",\n  \"initial\": 4,\n  \"max\": \"9223372036854775807\",\n  \"min\": \"-9223372036854775808\",\n  \"version\": 1\n}\n\nNotice that \"initial\" field has a non - string value\nHence the parsing logic for restart failed.\n ALTER SEQUENCE `default`._default.test5 WITH {\"restart\":true};\n{\n    \"requestID\": \"1c601dcf-1507-4e16-b903-d8156fcc2da9\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 19110,\n            \"msg\": \"Invalid sequence data\",\n            \"reason\": \"{\\\"base\\\":\\\"4\\\",\\\"block\\\":2,\\\"cache\\\":\\\"50\\\",\\\"cycle\\\":false,\\\"increment\\\":\\\"1\\\",\\\"initial\\\":4,\\\"max\\\":\\\"9223372036854775807\\\",\\\"min\\\":\\\"-9223372036854775808\\\",\\\"version\\\":1}\"\n        }\n    ],\n\n\nSimilar error would be raised if the string value assigned to \"initial\" in the document is a string but can't be parsed as an integer.",
      "3) When user wants to ALTER a sequences' increment or cache value.\n    We reseed the sequence with current value as the new base, and set block to 0. After this update either cache or increment  or both to the new user passed value.\n    But will running logic for the new base value ( block*cache*incr + base_old) but we may have failed to read \"block\", \"cache\", \"increment\", \"base\" as the value got from KV is of unexpected type(string) or couldn't be parsed as an integer.\n   \n    For eg:\n    ALTER SEQUENCE `default`._default.test5 WITH {\"cache\":100};\n{\n    \"requestID\": \"39cd1355-efea-48b4-915e-879e8b733009\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 19110,\n            \"msg\": \"Invalid sequence data\",\n            \"reason\": \"{\\\"base\\\":\\\"4\\\",\\\"block\\\":2,\\\"cache\\\":\\\"50\\\",\\\"cycle\\\":false,\\\"increment\\\":1,\\\"initial\\\":4,\\\"max\\\":\\\"9223372036854775807\\\",\\\"min\\\":\\\"-9223372036854775808\\\",\\\"version\\\":1}\"\n        }\n    ],\n \nHere we see that \\\"increment\\\":1 is a non-string value. Hence the ALTER fails",
      "4) On ALTER we increment the \"version\" of a sequence\n  But sequence document got from KV has a \"version\" as a non-integer value.\n\nALTER SEQUENCE `default`._default.test5 WITH {\"cache\":100};\n{\n    \"requestID\": \"27541f94-cce4-4336-8b83-b81bab10ce96\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 19110,\n            \"msg\": \"Invalid sequence data\",\n            \"reason\": \"{\\\"base\\\":\\\"104\\\",\\\"block\\\":0,\\\"cache\\\":\\\"100\\\",\\\"cycle\\\":false,\\\"increment\\\":\\\"1\\\",\\\"initial\\\":4,\\\"max\\\":\\\"9223372036854775807\\\",\\\"min\\\":\\\"-9223372036854775808\\\",\\\"version\\\":\\\"1\\\"}\"\n        }\n    ],",
      "5) For NEXT VALUE FOR [seq] or PREV VALUE FOR [seq] expression evaluation\n\nif sequence is not available in cache we load it in from KV (_system scope, _query collection)\n\nIn the logic for loading we expect\n\"version\" -> to be a number\n\"cache\" -> to be a string that can be parsed as an integer\n\"base\" -> to be a string that can be parsed as an integer\n\"min\" -> to be a string that can be parsed as an integer\n\"max\" ->  to be a string that can be parsed as an integer \n\"increment\" -> to be a string that can be parsed as an integer \n\"cycle\" -> to be a boolean\n\nBut we didn't get the desired value type for field(s) from KV, hence we raise this error.",
      "6) When issuing NEXT VALUE FOR [seq] expression, (sequence doesn't have a valid cycle range)\n\nfailsafe code\nwe use subdocAPI for getting a next-block when current block is completed for a node, to do so we issue SUBDOC_MULTI_MUTATION command,\nparticularly here we increment the path=\"block\" for the sequence document , if the path('block\") doesn't match the results field name-> something is wrong. That is someone external has changed the sequence document.",
      "7) When issuing NEXT VALUE FOR [seq] expression, (sequence has valid cycle range, i.e min and max are defined with cycle set as true)\n\nfailsafe code\nOn the last remaining increment for a block, we check if we have to cycle or goto the next block\nif we have to cycle, we increment the version signalling to all other nodes that their cache revision is invalid and also set block back to 0. To do this we use  subdocAPI using SUBDOC_MULTI_MUTATION command.\nwe check if path passed \"version\" is same as results field name, if not something is wrong. And we error out."
    ],
    "actions": [
      "1) SELECT * FROM system:all_sequences;\nwill tell you all the defined sequence on the cluster, only these can be altered.\n\nInvalid data may come from mismatch type at the document.\nEnsure the sequence document's \n\"base\":  is a string (that can be parsed as an integer)\n\"block\": integer\n\"cache\": is a string (that can be parsed as an integer) \n\"cycle\": boolean\n\"increment\": is a string (that can be parsed as an integer) \n\"initial\": is a string (that can be parsed as an integer) \n\"max\": is a string (that can be parsed as an integer) \n\"min\": is a string (that can be parsed as an integer) \n\"version\": integer"
    ],
    "isUser": true
  },
  {
    "code": 19111,
    "ErrorCode": "E_SEQUENCE_EXHAUSTED",
    "description": "Sequence [seq-name] has reached its limit",
    "causes": [
      "1) non cycle sequence with min and max set , NEXT VALUE FOR [seq] expression evaluation fails when.\n   i) increment<0, currvalue <min : range exhausted\n   ii) increment>0, currvalue > max : range exhausted\n    \n  For eg:\n  CREATE SEQUENCE default._default.testseq5 WITH {\"cache\":10,\"min\":0, \"max\":10};\n   \n   run following statement 10 times:\n   SELECT NEXT VALUE FOR default._default.testseq5;\n   \n  next run:\n   to history file for the shell : /Users/gauravj/.cbq_history \ncbq> SELECT NEXT VALUE FOR default._default.testseq5;\n{\n    \"requestID\": \"c29e7399-02e1-4033-84c8-4840566081a2\",\n    \"signature\": {\n        \"$1\": \"number\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"sequences:1015\",\n                \"code\": 19111,\n                \"key\": \"datastore.sequence.exhausted\",\n                \"message\": \"Sequence 'default:default._default.testseq5' has reached its limit\"\n            }\n        }\n    ],",
      "2) non cycle sequence , reaches int64 limit\n\nFor eg:\nCREATE SEQUENCE default._default.testseq7 START WITH 9223372036854775808;\n\nNow running next val would exhausts the sequence, as the value will under go int64 wrapping.\nSELECT NEXT VALUE FOR default._default.testseq7;\n{\n    \"requestID\": \"d6f8a9d4-2b16-48db-a840-a860f9f2da3f\",\n    \"signature\": {\n        \"$1\": \"number\"\n    },\n    \"results\": [\n    ],\n    \"errors\": [\n        {\n            \"code\": 5010,\n            \"msg\": \"Error evaluating projection\",\n            \"reason\": {\n                \"_level\": \"exception\",\n                \"caller\": \"sequences:1015\",\n                \"code\": 19111,\n                \"key\": \"datastore.sequence.exhausted\",\n                \"message\": \"Sequence 'default:default._default.testseq7' has reached its limit\"\n            }\n        }\n    ]"
    ],
    "actions": [
      "1) Alter the sequence , if increment>0, "
    ]
  },
  {
    "code": 19112,
    "ErrorCode": "E_SEQUENCE_CYCLE",
    "description": "UNUSED - couchbase trinty , Cycle failed for sequence [seq-name]",
    "causes": [],
    "actions": []
  },
  {
    "code": 19113,
    "ErrorCode": "E_SEQUENCE_INVALID_NAME",
    "description": "UNUSED - couchbase trinty ( all invalid naming are caught by the parser) , Invalid sequence name [seq-name]",
    "causes": [
      "1) when using sequence operations, sequence name must be - namespace:bucket.scope.sequence_name ( 3 part name-> bucket, scope, sequencename)\n    sample incorrect usage:\n   \n     SELECT NEXT VALUE FOR default._default.test2.notallowed;\n{\n    \"requestID\": \"c643f531-42de-4f19-8638-85ce3d8e2a98\",\n    \"errors\": [\n        {\n            \"code\": 3000,\n            \"column\": 8,\n            \"line\": 1,\n            \"msg\": \"Invalid sequence name (near line 1, column 8)\"\n        }\n    ],",
      "2) CREATE SEQUENCE [sequence-name]\n    expects scope in the path for sequence-name\n    sample incorrect usage:\n   \n      CREATE SEQUENCE test;\n{\n    \"requestID\": \"2ba7979b-f887-4752-b8bc-0a0fa1ae66a6\",\n    \"errors\": [\n        {\n            \"code\": 3000,\n            \"column\": 17,\n            \"line\": 1,\n            \"msg\": \"Invalid sequence name (near line 1, column 17)\"\n        }\n    ],"
    ],
    "actions": []
  },
  {
    "code": 19114,
    "ErrorCode": "E_SEQUENCE_READ_ONLY_REQ",
    "description": "Sequences cannot be used in read-only requests",
    "causes": [
      "Cannot do sequence operations on GET request\n\nGET /query/service?statement=SELECT%20NEXT%20VALUE%20FOR%20default._default.test4 HTTP/1.1\nAuthorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==\nHost: 127.0.0.1:9499\n\nHTTP/1.1 200 OK\nContent-Length: 488\nContent-Type: application/json; version=7.6.0-N1QL\nDate: Mon, 08 Jan 2024 06:40:13 GMT\n{\n\"requestID\": \"ca3790ea-f2e1-4ae8-a1d5-bb7512addf4b\",\n\"signature\": {\"$1\":\"number\"},\n\"results\": [\n],\n\"errors\": [{\"code\":5010,\"msg\":\"Error evaluating projection\",\"reason\":{\"_level\":\"exception\",\"caller\":\"sequence:111\",\"code\":19114,\"key\":\"datastore.sequence.read_only\",\"message\":\"Sequences cannot be used in read-only requests\"}}],\n\"status\": \"fatal\",\n\"metrics\": {\"elapsedTime\": \"29.807792ms\",\"executionTime\": \"501.542\u00b5s\",\"resultCount\": 0,\"resultSize\": 0,\"serviceLoad\": 2,\"errorCount\": 1}\n}"
    ],
    "actions": [
      "switch request method to POST \nthe request is no longer readonly"
    ],
    "isUser": true
  },
  {
    "code": 19115,
    "ErrorCode": "W_SEQUENCE_CACHE_SIZE",
    "description": "Cache size (CACHE-size passed) below recommended minimum",
    "causes": [
      "When setting cache option using CREATE SEQUENCE / ALTER SEQUENCE\n\nThe recommended cache size is above 10, for performance reasons. To avoid cache block validation and allocation frequently.\nNOTE: this error is only a warning."
    ],
    "actions": [],
    "isUser": true
  },
  {
    "code": 19116,
    "ErrorCode": "E_SEQUENCE_NAME_PARTS",
    "description": "Sequence name resolves to [sequence-full-name] - check query_context?( [line] [column])",
    "causes": [
      "failsafe code\nTo semantically disallow a sequence name not having scope, from being evaluated for it's NEXT VAL/PREV VAL expressions."
    ],
    "actions": []
  },
  {
    "code": 19117,
    "ErrorCode": "E_SEQUENCE_DROP_ALL",
    "description": "Drop failed for sequences [list of sequence names]",
    "causes": [
      "When Dropping a scope that has sequences\n\nWe cleanup by doing a refresh(bucket update) to clear old sequence cache ( just as for dictionaries and functions) \nIn the logic to delete the sequence document from the system scope, we get back error response on DELETE command, that is when we raise this error."
    ],
    "actions": [],
    "isUser": false
  },
  {
    "code": 19118,
    "ErrorCode": "W_SEQUENCE_NO_PREV_VALUE",
    "description": "Sequence previous value cannot be accessed before next value generation.",
    "causes": [
      "A newly CREATED sequence's previous value cannot be accessed without running NEXT VALUE FOR / NEXTVAL FOR expression atleast once.\n\n CREATE SEQUENCE `default`._default.trial2;\n{\n    \"requestID\": \"dfaa93a0-5b20-41b2-9476-8e7cc04f7368\",\n    \"signature\": null,\n    \"results\": [\n    ],\n    \"status\": \"success\",\n    \"metrics\": {\n        \"elapsedTime\": \"19.984166ms\",\n        \"executionTime\": \"19.831208ms\",\n        \"resultCount\": 0,\n        \"resultSize\": 0,\n        \"serviceLoad\": 2\n    }\n}\n\n\nSELECT PREVVAL FOR default._default.trial2;\n{\n    \"requestID\": \"f4b61573-8751-44ca-b24d-d510b5b1adb4\",\n    \"signature\": {\n        \"$1\": \"number\"\n    },\n    \"results\": [\n    {}\n    ],\n    \"warnings\": [\n        {\n            \"code\": 19118,\n            \"msg\": \"Sequence previous value cannot be accessed before next value generation.\"\n        }\n    ],"
    ],
    "actions": [],
    "isUser": true
  }
]